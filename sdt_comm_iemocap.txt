--- 1 ---
loss_mask: [True, True, True, True]
Namespace(no_cuda=False, lr=0.0001, l2=1e-05, dropout=0.5, batch_size=64, hidden_dim=1024, n_head=8, epochs=150, temp=2, tensorboard=False, class_weight=True, Dataset='IEMOCAP', loss_mask='1111')
Running on GPU
temp 2
total parameters: 97535000
training parameters: 97535000
epoch: 1, train_loss: 12.354700088500977, train_acc: 20.42, train_fscore: 20.1, valid_loss: 10.385299682617188, valid_acc: 29.37, valid_fscore: 27.17, test_loss: 11.275199890136719, test_acc: 28.16, test_fscore: 25.31, time: 5.65 sec
epoch: 2, train_loss: 11.603699684143066, train_acc: 33.64, train_fscore: 33.18, valid_loss: 9.723199844360352, valid_acc: 45.93, valid_fscore: 42.96, test_loss: 10.747200012207031, test_acc: 39.0, test_fscore: 37.7, time: 4.64 sec
epoch: 3, train_loss: 11.118499755859375, train_acc: 46.37, train_fscore: 43.82, valid_loss: 9.18019962310791, valid_acc: 57.08, valid_fscore: 55.68, test_loss: 10.297699928283691, test_acc: 52.19, test_fscore: 50.39, time: 4.55 sec
epoch: 4, train_loss: 10.690199851989746, train_acc: 52.95, train_fscore: 50.92, valid_loss: 8.933600425720215, valid_acc: 49.7, valid_fscore: 51.0, test_loss: 10.023799896240234, test_acc: 49.48, test_fscore: 48.55, time: 4.25 sec
epoch: 5, train_loss: 10.357500076293945, train_acc: 54.31, train_fscore: 52.67, valid_loss: 8.794400215148926, valid_acc: 59.49, valid_fscore: 60.78, test_loss: 9.903499603271484, test_acc: 56.75, test_fscore: 56.67, time: 4.4 sec
epoch: 6, train_loss: 10.09939956665039, train_acc: 61.17, train_fscore: 60.68, valid_loss: 8.645600318908691, valid_acc: 64.76, valid_fscore: 65.32, test_loss: 9.791299819946289, test_acc: 57.98, test_fscore: 58.47, time: 3.93 sec
epoch: 7, train_loss: 9.804499626159668, train_acc: 62.88, train_fscore: 62.67, valid_loss: 8.262299537658691, valid_acc: 63.4, valid_fscore: 65.24, test_loss: 9.461099624633789, test_acc: 57.49, test_fscore: 58.24, time: 3.92 sec
epoch: 8, train_loss: 9.482999801635742, train_acc: 63.6, train_fscore: 63.54, valid_loss: 7.781400203704834, valid_acc: 64.31, valid_fscore: 66.34, test_loss: 9.043999671936035, test_acc: 60.2, test_fscore: 60.72, time: 4.58 sec
epoch: 9, train_loss: 9.161800384521484, train_acc: 66.4, train_fscore: 66.19, valid_loss: 7.49399995803833, valid_acc: 69.28, valid_fscore: 69.42, test_loss: 8.77649974822998, test_acc: 63.65, test_fscore: 63.89, time: 4.67 sec
epoch: 10, train_loss: 8.972999572753906, train_acc: 67.35, train_fscore: 66.75, valid_loss: 7.374599933624268, valid_acc: 67.47, valid_fscore: 69.29, test_loss: 8.6697998046875, test_acc: 62.35, test_fscore: 63.33, time: 4.66 sec
              precision    recall  f1-score   support

           0     0.3228    0.6389    0.4289     144.0
           1     0.7917    0.6980    0.7419     245.0
           2     0.6589    0.5182    0.5802     384.0
           3     0.6062    0.6882    0.6446     170.0
           4     0.8117    0.6054    0.6935     299.0
           5     0.6238    0.6614    0.6420     381.0

    accuracy                         0.6235    1623.0
   macro avg     0.6358    0.6350    0.6218    1623.0
weighted avg     0.6635    0.6235    0.6333    1623.0

[[ 92.   6.   9.   2.  33.   2.]
 [ 14. 171.  29.   2.   0.  29.]
 [ 65.  26. 199.  19.   3.  72.]
 [  0.   0.   6. 117.   0.  47.]
 [104.   0.  10.   2. 181.   2.]
 [ 10.  13.  49.  51.   6. 252.]]
epoch: 11, train_loss: 8.879899978637695, train_acc: 66.98, train_fscore: 66.7, valid_loss: 7.401199817657471, valid_acc: 65.51, valid_fscore: 68.04, test_loss: 8.689399719238281, test_acc: 61.06, test_fscore: 62.26, time: 4.54 sec
epoch: 12, train_loss: 8.80679988861084, train_acc: 67.59, train_fscore: 67.36, valid_loss: 7.313799858093262, valid_acc: 68.52, valid_fscore: 68.88, test_loss: 8.583100318908691, test_acc: 64.82, test_fscore: 65.45, time: 3.93 sec
epoch: 13, train_loss: 8.68179988861084, train_acc: 69.24, train_fscore: 68.89, valid_loss: 7.066400051116943, valid_acc: 67.17, valid_fscore: 68.63, test_loss: 8.343999862670898, test_acc: 63.22, test_fscore: 64.18, time: 4.68 sec
epoch: 14, train_loss: 8.601400375366211, train_acc: 69.57, train_fscore: 69.48, valid_loss: 6.950699806213379, valid_acc: 68.22, valid_fscore: 69.48, test_loss: 8.22599983215332, test_acc: 64.02, test_fscore: 64.78, time: 4.6 sec
epoch: 15, train_loss: 8.517900466918945, train_acc: 69.49, train_fscore: 68.97, valid_loss: 6.85290002822876, valid_acc: 71.08, valid_fscore: 71.21, test_loss: 8.142399787902832, test_acc: 66.42, test_fscore: 66.68, time: 4.65 sec
epoch: 16, train_loss: 8.443900108337402, train_acc: 69.88, train_fscore: 69.33, valid_loss: 6.900899887084961, valid_acc: 67.62, valid_fscore: 69.72, test_loss: 8.174599647521973, test_acc: 62.6, test_fscore: 63.57, time: 3.87 sec
epoch: 17, train_loss: 8.389300346374512, train_acc: 69.18, train_fscore: 68.75, valid_loss: 6.876699924468994, valid_acc: 67.47, valid_fscore: 69.59, test_loss: 8.16819953918457, test_acc: 62.97, test_fscore: 63.88, time: 4.59 sec
epoch: 18, train_loss: 8.309000015258789, train_acc: 71.63, train_fscore: 71.28, valid_loss: 6.804100036621094, valid_acc: 70.18, valid_fscore: 70.76, test_loss: 8.126700401306152, test_acc: 65.68, test_fscore: 66.22, time: 3.88 sec
epoch: 19, train_loss: 8.23900032043457, train_acc: 72.6, train_fscore: 72.28, valid_loss: 6.752200126647949, valid_acc: 68.52, valid_fscore: 69.83, test_loss: 8.101900100708008, test_acc: 64.82, test_fscore: 65.6, time: 4.6 sec
epoch: 20, train_loss: 8.167900085449219, train_acc: 72.97, train_fscore: 72.76, valid_loss: 6.757500171661377, valid_acc: 67.02, valid_fscore: 68.57, test_loss: 8.053299903869629, test_acc: 64.39, test_fscore: 65.33, time: 4.6 sec
              precision    recall  f1-score   support

           0     0.3586    0.7222    0.4793     144.0
           1     0.7727    0.6939    0.7312     245.0
           2     0.6706    0.5938    0.6298     384.0
           3     0.6237    0.7118    0.6648     170.0
           4     0.8782    0.5786    0.6976     299.0
           5     0.6518    0.6535    0.6527     381.0

    accuracy                         0.6439    1623.0
   macro avg     0.6593    0.6590    0.6426    1623.0
weighted avg     0.6873    0.6439    0.6533    1623.0

[[104.   6.  11.   3.  18.   2.]
 [  7. 170.  35.   2.   0.  31.]
 [ 59.  24. 228.  17.   2.  54.]
 [  0.   0.   5. 121.   0.  44.]
 [114.   0.  10.   0. 173.   2.]
 [  6.  20.  51.  51.   4. 249.]]
epoch: 21, train_loss: 8.140600204467773, train_acc: 72.6, train_fscore: 72.3, valid_loss: 6.706500053405762, valid_acc: 69.43, valid_fscore: 70.43, test_loss: 8.021499633789062, test_acc: 65.99, test_fscore: 66.57, time: 4.52 sec
epoch: 22, train_loss: 8.080900192260742, train_acc: 72.87, train_fscore: 72.43, valid_loss: 6.690800189971924, valid_acc: 70.48, valid_fscore: 71.45, test_loss: 8.01609992980957, test_acc: 66.11, test_fscore: 66.74, time: 4.02 sec
epoch: 23, train_loss: 8.024800300598145, train_acc: 73.9, train_fscore: 73.64, valid_loss: 6.6859002113342285, valid_acc: 69.43, valid_fscore: 70.9, test_loss: 8.007599830627441, test_acc: 65.56, test_fscore: 66.33, time: 4.46 sec
epoch: 24, train_loss: 7.963200092315674, train_acc: 73.96, train_fscore: 73.71, valid_loss: 6.636899948120117, valid_acc: 69.88, valid_fscore: 70.92, test_loss: 7.961699962615967, test_acc: 66.79, test_fscore: 67.39, time: 4.41 sec
epoch: 25, train_loss: 7.938199996948242, train_acc: 74.29, train_fscore: 74.02, valid_loss: 6.6118998527526855, valid_acc: 70.63, valid_fscore: 71.65, test_loss: 7.954800128936768, test_acc: 67.47, test_fscore: 68.07, time: 4.46 sec
epoch: 26, train_loss: 7.859399795532227, train_acc: 75.11, train_fscore: 74.87, valid_loss: 6.65339994430542, valid_acc: 69.28, valid_fscore: 70.75, test_loss: 7.9918999671936035, test_acc: 65.87, test_fscore: 66.58, time: 4.54 sec
epoch: 27, train_loss: 7.85260009765625, train_acc: 74.99, train_fscore: 74.82, valid_loss: 6.6209001541137695, valid_acc: 70.78, valid_fscore: 72.13, test_loss: 7.933199882507324, test_acc: 66.42, test_fscore: 67.04, time: 4.45 sec
epoch: 28, train_loss: 7.793700218200684, train_acc: 75.55, train_fscore: 75.37, valid_loss: 6.555699825286865, valid_acc: 71.54, valid_fscore: 72.35, test_loss: 7.849999904632568, test_acc: 67.84, test_fscore: 68.32, time: 4.53 sec
epoch: 29, train_loss: 7.735400199890137, train_acc: 76.04, train_fscore: 75.81, valid_loss: 6.53000020980835, valid_acc: 70.93, valid_fscore: 71.93, test_loss: 7.80709981918335, test_acc: 68.21, test_fscore: 68.75, time: 4.54 sec
epoch: 30, train_loss: 7.725900173187256, train_acc: 76.47, train_fscore: 76.27, valid_loss: 6.5432000160217285, valid_acc: 70.48, valid_fscore: 71.76, test_loss: 7.804999828338623, test_acc: 67.1, test_fscore: 67.72, time: 4.64 sec
              precision    recall  f1-score   support

           0     0.4208    0.7014    0.5260     144.0
           1     0.7911    0.7265    0.7574     245.0
           2     0.6935    0.6068    0.6472     384.0
           3     0.6269    0.7118    0.6667     170.0
           4     0.8673    0.6555    0.7467     299.0
           5     0.6452    0.6824    0.6633     381.0

    accuracy                         0.6710    1623.0
   macro avg     0.6741    0.6807    0.6679    1623.0
weighted avg     0.6977    0.6710    0.6772    1623.0

[[101.   7.  11.   3.  19.   3.]
 [  5. 178.  24.   1.   0.  37.]
 [ 45.  24. 233.  21.   6.  55.]
 [  0.   0.   3. 121.   0.  46.]
 [ 88.   0.  13.   0. 196.   2.]
 [  1.  16.  52.  47.   5. 260.]]
epoch: 31, train_loss: 7.689300060272217, train_acc: 76.66, train_fscore: 76.46, valid_loss: 6.553199768066406, valid_acc: 71.69, valid_fscore: 72.83, test_loss: 7.831200122833252, test_acc: 66.85, test_fscore: 67.48, time: 4.28 sec
epoch: 32, train_loss: 7.631700038909912, train_acc: 76.58, train_fscore: 76.4, valid_loss: 6.554599761962891, valid_acc: 71.08, valid_fscore: 72.1, test_loss: 7.839200019836426, test_acc: 66.61, test_fscore: 67.19, time: 4.55 sec
epoch: 33, train_loss: 7.620800018310547, train_acc: 77.07, train_fscore: 76.88, valid_loss: 6.538599967956543, valid_acc: 71.99, valid_fscore: 73.02, test_loss: 7.771399974822998, test_acc: 66.97, test_fscore: 67.6, time: 4.47 sec
epoch: 34, train_loss: 7.591000080108643, train_acc: 77.19, train_fscore: 77.01, valid_loss: 6.501100063323975, valid_acc: 72.44, valid_fscore: 73.21, test_loss: 7.735599994659424, test_acc: 67.47, test_fscore: 68.05, time: 4.29 sec
epoch: 35, train_loss: 7.5391998291015625, train_acc: 77.54, train_fscore: 77.35, valid_loss: 6.531300067901611, valid_acc: 71.69, valid_fscore: 72.7, test_loss: 7.720399856567383, test_acc: 67.78, test_fscore: 68.34, time: 3.84 sec
epoch: 36, train_loss: 7.496699810028076, train_acc: 77.98, train_fscore: 77.8, valid_loss: 6.583600044250488, valid_acc: 70.63, valid_fscore: 72.08, test_loss: 7.761499881744385, test_acc: 66.73, test_fscore: 67.39, time: 4.5 sec
epoch: 37, train_loss: 7.511499881744385, train_acc: 77.73, train_fscore: 77.56, valid_loss: 6.526700019836426, valid_acc: 71.84, valid_fscore: 72.71, test_loss: 7.752799987792969, test_acc: 66.79, test_fscore: 67.4, time: 4.41 sec
epoch: 38, train_loss: 7.457399845123291, train_acc: 79.38, train_fscore: 79.21, valid_loss: 6.48330020904541, valid_acc: 72.59, valid_fscore: 73.36, test_loss: 7.751399993896484, test_acc: 66.3, test_fscore: 66.93, time: 4.46 sec
epoch: 39, train_loss: 7.42609977722168, train_acc: 79.34, train_fscore: 79.26, valid_loss: 6.523799896240234, valid_acc: 71.84, valid_fscore: 72.97, test_loss: 7.690400123596191, test_acc: 66.85, test_fscore: 67.48, time: 4.44 sec
epoch: 40, train_loss: 7.409900188446045, train_acc: 79.19, train_fscore: 79.08, valid_loss: 6.526100158691406, valid_acc: 72.44, valid_fscore: 73.39, test_loss: 7.649600028991699, test_acc: 67.84, test_fscore: 68.45, time: 4.57 sec
              precision    recall  f1-score   support

           0     0.4298    0.7222    0.5389     144.0
           1     0.7922    0.7469    0.7689     245.0
           2     0.6684    0.6667    0.6675     384.0
           3     0.6629    0.6941    0.6782     170.0
           4     0.8773    0.6455    0.7437     299.0
           5     0.6694    0.6483    0.6587     381.0

    accuracy                         0.6784    1623.0
   macro avg     0.6833    0.6873    0.6760    1623.0
weighted avg     0.7041    0.6784    0.6845    1623.0

[[104.   7.  15.   0.  16.   2.]
 [  3. 183.  28.   1.   0.  30.]
 [ 43.  24. 256.  13.   5.  43.]
 [  0.   0.   6. 118.   0.  46.]
 [ 92.   0.  13.   0. 193.   1.]
 [  0.  17.  65.  46.   6. 247.]]
epoch: 41, train_loss: 7.380300045013428, train_acc: 79.95, train_fscore: 79.8, valid_loss: 6.515100002288818, valid_acc: 72.89, valid_fscore: 73.7, test_loss: 7.683199882507324, test_acc: 67.53, test_fscore: 68.15, time: 4.05 sec
epoch: 42, train_loss: 7.373499870300293, train_acc: 79.71, train_fscore: 79.59, valid_loss: 6.46560001373291, valid_acc: 72.74, valid_fscore: 73.61, test_loss: 7.665599822998047, test_acc: 66.97, test_fscore: 67.57, time: 1.98 sec
epoch: 43, train_loss: 7.333499908447266, train_acc: 79.87, train_fscore: 79.69, valid_loss: 6.498799800872803, valid_acc: 71.39, valid_fscore: 72.6, test_loss: 7.683899879455566, test_acc: 66.67, test_fscore: 67.28, time: 1.99 sec
epoch: 44, train_loss: 7.305799961090088, train_acc: 79.79, train_fscore: 79.68, valid_loss: 6.494500160217285, valid_acc: 72.89, valid_fscore: 73.68, test_loss: 7.6184000968933105, test_acc: 67.78, test_fscore: 68.34, time: 1.99 sec
epoch: 45, train_loss: 7.284900188446045, train_acc: 81.03, train_fscore: 80.9, valid_loss: 6.508800029754639, valid_acc: 73.34, valid_fscore: 74.27, test_loss: 7.629899978637695, test_acc: 66.91, test_fscore: 67.55, time: 2.0 sec
epoch: 46, train_loss: 7.286499977111816, train_acc: 80.1, train_fscore: 79.99, valid_loss: 6.46750020980835, valid_acc: 73.04, valid_fscore: 73.93, test_loss: 7.6381001472473145, test_acc: 67.34, test_fscore: 68.0, time: 1.98 sec
epoch: 47, train_loss: 7.244500160217285, train_acc: 81.58, train_fscore: 81.47, valid_loss: 6.452899932861328, valid_acc: 73.04, valid_fscore: 73.65, test_loss: 7.627900123596191, test_acc: 67.65, test_fscore: 68.26, time: 2.01 sec
epoch: 48, train_loss: 7.213699817657471, train_acc: 81.58, train_fscore: 81.45, valid_loss: 6.53249979019165, valid_acc: 71.23, valid_fscore: 72.54, test_loss: 7.6605000495910645, test_acc: 66.67, test_fscore: 67.32, time: 2.0 sec
epoch: 49, train_loss: 7.18310022354126, train_acc: 81.64, train_fscore: 81.55, valid_loss: 6.4781999588012695, valid_acc: 73.64, valid_fscore: 74.48, test_loss: 7.6128997802734375, test_acc: 67.59, test_fscore: 68.18, time: 1.94 sec
epoch: 50, train_loss: 7.185299873352051, train_acc: 81.95, train_fscore: 81.8, valid_loss: 6.4664998054504395, valid_acc: 73.04, valid_fscore: 73.76, test_loss: 7.593299865722656, test_acc: 68.27, test_fscore: 68.86, time: 2.03 sec
              precision    recall  f1-score   support

           0     0.4385    0.7431    0.5515     144.0
           1     0.8125    0.7429    0.7761     245.0
           2     0.6781    0.6693    0.6737     384.0
           3     0.6595    0.7176    0.6873     170.0
           4     0.8791    0.6321    0.7354     299.0
           5     0.6676    0.6588    0.6631     381.0

    accuracy                         0.6827    1623.0
   macro avg     0.6892    0.6940    0.6812    1623.0
weighted avg     0.7097    0.6827    0.6886    1623.0

[[107.   5.  15.   0.  15.   2.]
 [  2. 182.  27.   2.   0.  32.]
 [ 43.  21. 257.  12.   5.  46.]
 [  0.   0.   5. 122.   0.  43.]
 [ 91.   1.  16.   0. 189.   2.]
 [  1.  15.  59.  49.   6. 251.]]
epoch: 51, train_loss: 7.17609977722168, train_acc: 81.62, train_fscore: 81.51, valid_loss: 6.499000072479248, valid_acc: 72.44, valid_fscore: 73.42, test_loss: 7.6128997802734375, test_acc: 67.28, test_fscore: 67.91, time: 1.98 sec
epoch: 52, train_loss: 7.13700008392334, train_acc: 82.24, train_fscore: 82.14, valid_loss: 6.439199924468994, valid_acc: 74.1, valid_fscore: 74.76, test_loss: 7.605000019073486, test_acc: 67.41, test_fscore: 67.96, time: 1.91 sec
epoch: 53, train_loss: 7.125899791717529, train_acc: 81.85, train_fscore: 81.73, valid_loss: 6.442500114440918, valid_acc: 73.95, valid_fscore: 74.64, test_loss: 7.570400238037109, test_acc: 68.58, test_fscore: 69.15, time: 1.97 sec
epoch: 54, train_loss: 7.1265997886657715, train_acc: 82.28, train_fscore: 82.15, valid_loss: 6.5157999992370605, valid_acc: 72.44, valid_fscore: 73.31, test_loss: 7.561999797821045, test_acc: 68.21, test_fscore: 68.82, time: 1.97 sec
epoch: 55, train_loss: 7.084199905395508, train_acc: 82.36, train_fscore: 82.23, valid_loss: 6.480000019073486, valid_acc: 73.34, valid_fscore: 74.12, test_loss: 7.5782999992370605, test_acc: 69.07, test_fscore: 69.61, time: 1.95 sec
epoch: 56, train_loss: 7.0528998374938965, train_acc: 83.11, train_fscore: 83.01, valid_loss: 6.473700046539307, valid_acc: 73.49, valid_fscore: 74.36, test_loss: 7.610799789428711, test_acc: 68.7, test_fscore: 69.24, time: 1.94 sec
epoch: 57, train_loss: 7.024400234222412, train_acc: 83.17, train_fscore: 83.07, valid_loss: 6.513299942016602, valid_acc: 72.74, valid_fscore: 73.72, test_loss: 7.610199928283691, test_acc: 67.16, test_fscore: 67.68, time: 2.07 sec
epoch: 58, train_loss: 7.01800012588501, train_acc: 82.49, train_fscore: 82.33, valid_loss: 6.483099937438965, valid_acc: 73.64, valid_fscore: 74.39, test_loss: 7.587200164794922, test_acc: 68.58, test_fscore: 69.13, time: 1.98 sec
epoch: 59, train_loss: 7.005099773406982, train_acc: 83.95, train_fscore: 83.85, valid_loss: 6.506999969482422, valid_acc: 73.8, valid_fscore: 74.58, test_loss: 7.618199825286865, test_acc: 68.21, test_fscore: 68.75, time: 1.94 sec
epoch: 60, train_loss: 6.997499942779541, train_acc: 84.18, train_fscore: 84.07, valid_loss: 6.567500114440918, valid_acc: 72.74, valid_fscore: 73.77, test_loss: 7.623199939727783, test_acc: 68.76, test_fscore: 69.27, time: 1.97 sec
              precision    recall  f1-score   support

           0     0.4488    0.7917    0.5729     144.0
           1     0.8288    0.7510    0.7880     245.0
           2     0.6904    0.7083    0.6992     384.0
           3     0.6350    0.7471    0.6865     170.0
           4     0.8861    0.5987    0.7146     299.0
           5     0.6838    0.6299    0.6557     381.0

    accuracy                         0.6876    1623.0
   macro avg     0.6955    0.7044    0.6861    1623.0
weighted avg     0.7186    0.6876    0.6927    1623.0

[[114.   4.  12.   0.  12.   2.]
 [  3. 184.  25.   2.   0.  31.]
 [ 39.  20. 272.  10.   4.  39.]
 [  0.   0.   5. 127.   0.  38.]
 [ 97.   0.  22.   0. 179.   1.]
 [  1.  14.  58.  61.   7. 240.]]
epoch: 61, train_loss: 6.9822998046875, train_acc: 84.24, train_fscore: 84.15, valid_loss: 6.540800094604492, valid_acc: 74.1, valid_fscore: 74.81, test_loss: 7.597700119018555, test_acc: 69.07, test_fscore: 69.57, time: 2.02 sec
epoch: 62, train_loss: 6.979599952697754, train_acc: 84.43, train_fscore: 84.37, valid_loss: 6.581699848175049, valid_acc: 72.89, valid_fscore: 73.76, test_loss: 7.647600173950195, test_acc: 67.96, test_fscore: 68.51, time: 2.0 sec
epoch: 63, train_loss: 6.942399978637695, train_acc: 84.28, train_fscore: 84.16, valid_loss: 6.529399871826172, valid_acc: 73.49, valid_fscore: 74.09, test_loss: 7.570400238037109, test_acc: 68.82, test_fscore: 69.26, time: 1.99 sec
epoch: 64, train_loss: 6.941800117492676, train_acc: 84.82, train_fscore: 84.7, valid_loss: 6.512400150299072, valid_acc: 73.95, valid_fscore: 74.76, test_loss: 7.602799892425537, test_acc: 68.21, test_fscore: 68.73, time: 1.97 sec
epoch: 65, train_loss: 6.919300079345703, train_acc: 84.61, train_fscore: 84.54, valid_loss: 6.609799861907959, valid_acc: 73.19, valid_fscore: 74.02, test_loss: 7.645500183105469, test_acc: 68.64, test_fscore: 69.23, time: 1.99 sec
epoch: 66, train_loss: 6.900199890136719, train_acc: 84.14, train_fscore: 84.01, valid_loss: 6.5493998527526855, valid_acc: 74.7, valid_fscore: 75.3, test_loss: 7.61329984664917, test_acc: 68.33, test_fscore: 68.85, time: 2.59 sec
epoch: 67, train_loss: 6.8730998039245605, train_acc: 85.64, train_fscore: 85.57, valid_loss: 6.551199913024902, valid_acc: 73.64, valid_fscore: 74.49, test_loss: 7.61899995803833, test_acc: 68.76, test_fscore: 69.27, time: 1.98 sec
epoch: 68, train_loss: 6.873899936676025, train_acc: 85.31, train_fscore: 85.25, valid_loss: 6.536300182342529, valid_acc: 73.34, valid_fscore: 74.18, test_loss: 7.60860013961792, test_acc: 68.58, test_fscore: 69.15, time: 1.98 sec
epoch: 69, train_loss: 6.832699775695801, train_acc: 85.25, train_fscore: 85.15, valid_loss: 6.500500202178955, valid_acc: 75.6, valid_fscore: 75.93, test_loss: 7.59630012512207, test_acc: 69.13, test_fscore: 69.61, time: 1.9 sec
epoch: 70, train_loss: 6.834099769592285, train_acc: 85.72, train_fscore: 85.62, valid_loss: 6.55079984664917, valid_acc: 73.49, valid_fscore: 74.19, test_loss: 7.587200164794922, test_acc: 69.38, test_fscore: 69.9, time: 2.08 sec
              precision    recall  f1-score   support

           0     0.4560    0.7917    0.5787     144.0
           1     0.8333    0.7551    0.7923     245.0
           2     0.6941    0.7031    0.6986     384.0
           3     0.6474    0.7235    0.6833     170.0
           4     0.8878    0.6087    0.7222     299.0
           5     0.6866    0.6614    0.6738     381.0

    accuracy                         0.6938    1623.0
   macro avg     0.7009    0.7073    0.6915    1623.0
weighted avg     0.7230    0.6938    0.6990    1623.0

[[114.   4.  13.   0.  12.   1.]
 [  3. 185.  24.   3.   0.  30.]
 [ 40.  19. 270.   9.   4.  42.]
 [  0.   0.   6. 123.   0.  41.]
 [ 93.   1.  22.   0. 182.   1.]
 [  0.  13.  54.  55.   7. 252.]]
epoch: 71, train_loss: 6.829899787902832, train_acc: 85.93, train_fscore: 85.83, valid_loss: 6.606200218200684, valid_acc: 72.59, valid_fscore: 73.52, test_loss: 7.571000099182129, test_acc: 68.88, test_fscore: 69.44, time: 2.01 sec
epoch: 72, train_loss: 6.811699867248535, train_acc: 85.95, train_fscore: 85.84, valid_loss: 6.561500072479248, valid_acc: 74.55, valid_fscore: 75.24, test_loss: 7.621699810028076, test_acc: 68.82, test_fscore: 69.29, time: 2.05 sec
epoch: 73, train_loss: 6.788400173187256, train_acc: 86.71, train_fscore: 86.64, valid_loss: 6.576700210571289, valid_acc: 73.64, valid_fscore: 74.37, test_loss: 7.68720006942749, test_acc: 68.45, test_fscore: 68.99, time: 1.97 sec
epoch: 74, train_loss: 6.8069000244140625, train_acc: 86.36, train_fscore: 86.28, valid_loss: 6.595600128173828, valid_acc: 72.29, valid_fscore: 73.02, test_loss: 7.571499824523926, test_acc: 70.24, test_fscore: 70.8, time: 2.03 sec
epoch: 75, train_loss: 6.765399932861328, train_acc: 86.47, train_fscore: 86.35, valid_loss: 6.586599826812744, valid_acc: 73.04, valid_fscore: 73.74, test_loss: 7.580699920654297, test_acc: 68.95, test_fscore: 69.42, time: 1.98 sec
epoch: 76, train_loss: 6.750400066375732, train_acc: 86.81, train_fscore: 86.72, valid_loss: 6.6092000007629395, valid_acc: 73.95, valid_fscore: 74.58, test_loss: 7.728700160980225, test_acc: 67.96, test_fscore: 68.44, time: 1.97 sec
epoch: 77, train_loss: 6.739799976348877, train_acc: 86.51, train_fscore: 86.45, valid_loss: 6.587900161743164, valid_acc: 73.19, valid_fscore: 73.99, test_loss: 7.725299835205078, test_acc: 69.25, test_fscore: 69.73, time: 1.98 sec
epoch: 78, train_loss: 6.7515997886657715, train_acc: 86.51, train_fscore: 86.4, valid_loss: 6.559100151062012, valid_acc: 73.95, valid_fscore: 74.54, test_loss: 7.638400077819824, test_acc: 69.81, test_fscore: 70.27, time: 1.95 sec
epoch: 79, train_loss: 6.732800006866455, train_acc: 86.71, train_fscore: 86.6, valid_loss: 6.608699798583984, valid_acc: 74.4, valid_fscore: 75.01, test_loss: 7.651299953460693, test_acc: 69.07, test_fscore: 69.59, time: 2.02 sec
epoch: 80, train_loss: 6.711699962615967, train_acc: 87.17, train_fscore: 87.12, valid_loss: 6.630899906158447, valid_acc: 74.25, valid_fscore: 74.86, test_loss: 7.6427998542785645, test_acc: 69.62, test_fscore: 70.1, time: 1.99 sec
              precision    recall  f1-score   support

           0     0.4762    0.7639    0.5867     144.0
           1     0.8479    0.7510    0.7965     245.0
           2     0.6964    0.7109    0.7036     384.0
           3     0.6421    0.7176    0.6778     170.0
           4     0.8810    0.6187    0.7269     299.0
           5     0.6684    0.6719    0.6702     381.0

    accuracy                         0.6962    1623.0
   macro avg     0.7020    0.7057    0.6936    1623.0
weighted avg     0.7215    0.6962    0.7010    1623.0

[[110.   4.  15.   0.  14.   1.]
 [  2. 184.  25.   1.   0.  33.]
 [ 33.  17. 273.   8.   4.  49.]
 [  0.   0.   5. 122.   0.  43.]
 [ 86.   1.  26.   0. 185.   1.]
 [  0.  11.  48.  59.   7. 256.]]
epoch: 81, train_loss: 6.698500156402588, train_acc: 87.37, train_fscore: 87.29, valid_loss: 6.6132001876831055, valid_acc: 74.25, valid_fscore: 74.72, test_loss: 7.587699890136719, test_acc: 70.06, test_fscore: 70.48, time: 1.99 sec
epoch: 82, train_loss: 6.6819000244140625, train_acc: 87.21, train_fscore: 87.09, valid_loss: 6.608699798583984, valid_acc: 74.55, valid_fscore: 75.23, test_loss: 7.665500164031982, test_acc: 69.19, test_fscore: 69.66, time: 1.98 sec
epoch: 83, train_loss: 6.671000003814697, train_acc: 87.47, train_fscore: 87.39, valid_loss: 6.620699882507324, valid_acc: 75.0, valid_fscore: 75.43, test_loss: 7.660200119018555, test_acc: 69.62, test_fscore: 70.07, time: 1.94 sec
epoch: 84, train_loss: 6.649799823760986, train_acc: 87.82, train_fscore: 87.75, valid_loss: 6.631499767303467, valid_acc: 74.55, valid_fscore: 75.1, test_loss: 7.652599811553955, test_acc: 70.3, test_fscore: 70.8, time: 1.98 sec
epoch: 85, train_loss: 6.648200035095215, train_acc: 88.67, train_fscore: 88.61, valid_loss: 6.624599933624268, valid_acc: 73.64, valid_fscore: 74.34, test_loss: 7.650899887084961, test_acc: 69.99, test_fscore: 70.43, time: 1.97 sec
epoch: 86, train_loss: 6.605500221252441, train_acc: 88.22, train_fscore: 88.12, valid_loss: 6.632500171661377, valid_acc: 75.0, valid_fscore: 75.4, test_loss: 7.60099983215332, test_acc: 70.3, test_fscore: 70.67, time: 2.01 sec
epoch: 87, train_loss: 6.615900039672852, train_acc: 88.4, train_fscore: 88.3, valid_loss: 6.679200172424316, valid_acc: 74.25, valid_fscore: 74.81, test_loss: 7.666100025177002, test_acc: 70.12, test_fscore: 70.58, time: 2.02 sec
epoch: 88, train_loss: 6.5777997970581055, train_acc: 88.09, train_fscore: 88.03, valid_loss: 6.681700229644775, valid_acc: 74.25, valid_fscore: 74.83, test_loss: 7.707499980926514, test_acc: 69.5, test_fscore: 69.93, time: 1.93 sec
epoch: 89, train_loss: 6.584099769592285, train_acc: 88.48, train_fscore: 88.4, valid_loss: 6.646999835968018, valid_acc: 74.85, valid_fscore: 75.19, test_loss: 7.651700019836426, test_acc: 71.23, test_fscore: 71.59, time: 1.93 sec
epoch: 90, train_loss: 6.576399803161621, train_acc: 88.77, train_fscore: 88.68, valid_loss: 6.70989990234375, valid_acc: 74.7, valid_fscore: 75.28, test_loss: 7.670499801635742, test_acc: 69.25, test_fscore: 69.68, time: 1.94 sec
              precision    recall  f1-score   support

           0     0.4752    0.7986    0.5959     144.0
           1     0.8465    0.7429    0.7913     245.0
           2     0.6763    0.7344    0.7041     384.0
           3     0.6724    0.6882    0.6802     170.0
           4     0.8856    0.5953    0.7120     299.0
           5     0.6684    0.6562    0.6623     381.0

    accuracy                         0.6925    1623.0
   macro avg     0.7041    0.7026    0.6910    1623.0
weighted avg     0.7204    0.6925    0.6968    1623.0

[[115.   4.  13.   0.  11.   1.]
 [  2. 182.  26.   1.   0.  34.]
 [ 33.  17. 282.   6.   4.  42.]
 [  0.   0.   7. 117.   0.  46.]
 [ 92.   0.  28.   0. 178.   1.]
 [  0.  12.  61.  50.   8. 250.]]
epoch: 91, train_loss: 6.583399772644043, train_acc: 88.22, train_fscore: 88.14, valid_loss: 6.720399856567383, valid_acc: 74.55, valid_fscore: 75.02, test_loss: 7.676700115203857, test_acc: 70.06, test_fscore: 70.45, time: 1.99 sec
epoch: 92, train_loss: 6.553599834442139, train_acc: 89.0, train_fscore: 88.92, valid_loss: 6.716100215911865, valid_acc: 74.25, valid_fscore: 74.71, test_loss: 7.7083001136779785, test_acc: 70.61, test_fscore: 71.04, time: 2.0 sec
epoch: 93, train_loss: 6.526199817657471, train_acc: 89.37, train_fscore: 89.31, valid_loss: 6.677299976348877, valid_acc: 74.25, valid_fscore: 74.62, test_loss: 7.725399971008301, test_acc: 70.49, test_fscore: 70.88, time: 2.02 sec
epoch: 94, train_loss: 6.542300224304199, train_acc: 88.85, train_fscore: 88.74, valid_loss: 6.704800128936768, valid_acc: 74.7, valid_fscore: 75.07, test_loss: 7.727399826049805, test_acc: 69.69, test_fscore: 70.07, time: 2.0 sec
epoch: 95, train_loss: 6.539599895477295, train_acc: 89.35, train_fscore: 89.29, valid_loss: 6.691800117492676, valid_acc: 74.7, valid_fscore: 75.09, test_loss: 7.663099765777588, test_acc: 71.04, test_fscore: 71.43, time: 1.98 sec
epoch: 96, train_loss: 6.529300212860107, train_acc: 89.35, train_fscore: 89.29, valid_loss: 6.681000232696533, valid_acc: 74.55, valid_fscore: 74.99, test_loss: 7.6717000007629395, test_acc: 71.41, test_fscore: 71.82, time: 1.95 sec
epoch: 97, train_loss: 6.51230001449585, train_acc: 89.39, train_fscore: 89.31, valid_loss: 6.6844000816345215, valid_acc: 73.49, valid_fscore: 74.03, test_loss: 7.747799873352051, test_acc: 69.56, test_fscore: 69.99, time: 1.94 sec
epoch: 98, train_loss: 6.495999813079834, train_acc: 89.56, train_fscore: 89.52, valid_loss: 6.6819000244140625, valid_acc: 74.7, valid_fscore: 74.98, test_loss: 7.657899856567383, test_acc: 71.16, test_fscore: 71.51, time: 1.99 sec
epoch: 99, train_loss: 6.469399929046631, train_acc: 89.93, train_fscore: 89.86, valid_loss: 6.717199802398682, valid_acc: 73.04, valid_fscore: 73.86, test_loss: 7.707300186157227, test_acc: 70.24, test_fscore: 70.69, time: 2.0 sec
epoch: 100, train_loss: 6.464399814605713, train_acc: 89.56, train_fscore: 89.49, valid_loss: 6.701300144195557, valid_acc: 75.0, valid_fscore: 75.28, test_loss: 7.758800029754639, test_acc: 70.67, test_fscore: 71.06, time: 2.0 sec
              precision    recall  f1-score   support

           0     0.5090    0.7847    0.6175     144.0
           1     0.8558    0.7510    0.8000     245.0
           2     0.6762    0.7396    0.7065     384.0
           3     0.6526    0.7294    0.6889     170.0
           4     0.8889    0.6421    0.7456     299.0
           5     0.6944    0.6562    0.6748     381.0

    accuracy                         0.7067    1623.0
   macro avg     0.7128    0.7172    0.7055    1623.0
weighted avg     0.7295    0.7067    0.7106    1623.0

[[113.   4.  13.   0.  13.   1.]
 [  2. 184.  26.   3.   0.  30.]
 [ 32.  17. 284.   7.   5.  39.]
 [  0.   0.   7. 124.   0.  39.]
 [ 75.   0.  31.   0. 192.   1.]
 [  0.  10.  59.  56.   6. 250.]]
epoch: 101, train_loss: 6.455699920654297, train_acc: 90.69, train_fscore: 90.63, valid_loss: 6.739099979400635, valid_acc: 74.55, valid_fscore: 74.8, test_loss: 7.737500190734863, test_acc: 70.73, test_fscore: 71.14, time: 2.03 sec
epoch: 102, train_loss: 6.460899829864502, train_acc: 90.63, train_fscore: 90.58, valid_loss: 6.779099941253662, valid_acc: 73.95, valid_fscore: 74.42, test_loss: 7.746099948883057, test_acc: 69.13, test_fscore: 69.57, time: 1.94 sec
epoch: 103, train_loss: 6.4471001625061035, train_acc: 90.01, train_fscore: 89.94, valid_loss: 6.729499816894531, valid_acc: 74.1, valid_fscore: 74.39, test_loss: 7.675600051879883, test_acc: 71.29, test_fscore: 71.69, time: 1.96 sec
epoch: 104, train_loss: 6.428699970245361, train_acc: 90.19, train_fscore: 90.1, valid_loss: 6.726399898529053, valid_acc: 74.25, valid_fscore: 74.5, test_loss: 7.724999904632568, test_acc: 70.67, test_fscore: 71.06, time: 1.98 sec
epoch: 105, train_loss: 6.42519998550415, train_acc: 90.3, train_fscore: 90.24, valid_loss: 6.762499809265137, valid_acc: 73.19, valid_fscore: 73.73, test_loss: 7.839799880981445, test_acc: 69.01, test_fscore: 69.39, time: 2.03 sec
epoch: 106, train_loss: 6.418399810791016, train_acc: 90.81, train_fscore: 90.77, valid_loss: 6.776199817657471, valid_acc: 74.25, valid_fscore: 74.55, test_loss: 7.763299942016602, test_acc: 70.43, test_fscore: 70.79, time: 1.97 sec
epoch: 107, train_loss: 6.40339994430542, train_acc: 90.58, train_fscore: 90.51, valid_loss: 6.78879976272583, valid_acc: 74.7, valid_fscore: 75.12, test_loss: 7.789599895477295, test_acc: 70.12, test_fscore: 70.53, time: 2.0 sec
epoch: 108, train_loss: 6.389800071716309, train_acc: 90.59, train_fscore: 90.53, valid_loss: 6.791500091552734, valid_acc: 73.64, valid_fscore: 74.06, test_loss: 7.827600002288818, test_acc: 69.62, test_fscore: 70.02, time: 1.99 sec
epoch: 109, train_loss: 6.38040018081665, train_acc: 90.63, train_fscore: 90.58, valid_loss: 6.805600166320801, valid_acc: 73.64, valid_fscore: 74.05, test_loss: 7.7692999839782715, test_acc: 70.67, test_fscore: 71.07, time: 1.99 sec
epoch: 110, train_loss: 6.364299774169922, train_acc: 91.33, train_fscore: 91.29, valid_loss: 6.831699848175049, valid_acc: 74.1, valid_fscore: 74.3, test_loss: 7.735199928283691, test_acc: 71.72, test_fscore: 72.02, time: 2.05 sec
              precision    recall  f1-score   support

           0     0.5330    0.7292    0.6158     144.0
           1     0.8498    0.7388    0.7904     245.0
           2     0.6868    0.7708    0.7264     384.0
           3     0.6703    0.7294    0.6986     170.0
           4     0.8636    0.6990    0.7726     299.0
           5     0.7014    0.6535    0.6766     381.0

    accuracy                         0.7172    1623.0
   macro avg     0.7175    0.7201    0.7134    1623.0
weighted avg     0.7320    0.7172    0.7202    1623.0

[[105.   4.  13.   0.  21.   1.]
 [  3. 181.  28.   1.   0.  32.]
 [ 27.  17. 296.   5.   6.  33.]
 [  0.   0.   7. 124.   0.  39.]
 [ 62.   0.  27.   0. 209.   1.]
 [  0.  11.  60.  55.   6. 249.]]
epoch: 111, train_loss: 6.372000217437744, train_acc: 90.85, train_fscore: 90.79, valid_loss: 6.817999839782715, valid_acc: 74.25, valid_fscore: 74.6, test_loss: 7.765600204467773, test_acc: 70.86, test_fscore: 71.25, time: 1.99 sec
epoch: 112, train_loss: 6.3491997718811035, train_acc: 91.2, train_fscore: 91.15, valid_loss: 6.832699775695801, valid_acc: 73.04, valid_fscore: 73.46, test_loss: 7.821899890899658, test_acc: 70.3, test_fscore: 70.69, time: 1.95 sec
epoch: 113, train_loss: 6.342299938201904, train_acc: 90.96, train_fscore: 90.91, valid_loss: 6.866300106048584, valid_acc: 74.1, valid_fscore: 74.22, test_loss: 7.76800012588501, test_acc: 71.47, test_fscore: 71.8, time: 2.02 sec
epoch: 114, train_loss: 6.326000213623047, train_acc: 91.43, train_fscore: 91.38, valid_loss: 6.861100196838379, valid_acc: 73.64, valid_fscore: 74.08, test_loss: 7.816999912261963, test_acc: 70.79, test_fscore: 71.21, time: 2.0 sec
epoch: 115, train_loss: 6.339799880981445, train_acc: 91.45, train_fscore: 91.39, valid_loss: 6.7982001304626465, valid_acc: 74.1, valid_fscore: 74.59, test_loss: 7.898200035095215, test_acc: 70.18, test_fscore: 70.57, time: 2.02 sec
epoch: 116, train_loss: 6.326700210571289, train_acc: 91.9, train_fscore: 91.85, valid_loss: 6.85860013961792, valid_acc: 75.45, valid_fscore: 75.49, test_loss: 7.867099761962891, test_acc: 71.1, test_fscore: 71.39, time: 2.07 sec
epoch: 117, train_loss: 6.3206000328063965, train_acc: 92.07, train_fscore: 92.02, valid_loss: 6.856500148773193, valid_acc: 74.7, valid_fscore: 74.99, test_loss: 7.789999961853027, test_acc: 71.41, test_fscore: 71.75, time: 1.96 sec
epoch: 118, train_loss: 6.286900043487549, train_acc: 91.26, train_fscore: 91.2, valid_loss: 6.850100040435791, valid_acc: 73.95, valid_fscore: 74.31, test_loss: 7.847499847412109, test_acc: 70.98, test_fscore: 71.32, time: 2.0 sec
epoch: 119, train_loss: 6.292699813842773, train_acc: 91.99, train_fscore: 91.95, valid_loss: 6.869900226593018, valid_acc: 74.7, valid_fscore: 74.87, test_loss: 7.8572998046875, test_acc: 71.04, test_fscore: 71.34, time: 2.01 sec
epoch: 120, train_loss: 6.302000045776367, train_acc: 91.92, train_fscore: 91.88, valid_loss: 6.844900131225586, valid_acc: 74.25, valid_fscore: 74.41, test_loss: 7.821400165557861, test_acc: 70.98, test_fscore: 71.3, time: 1.99 sec
              precision    recall  f1-score   support

           0     0.5215    0.7569    0.6176     144.0
           1     0.8274    0.7633    0.7941     245.0
           2     0.6835    0.7422    0.7116     384.0
           3     0.6458    0.7294    0.6851     170.0
           4     0.8745    0.6756    0.7623     299.0
           5     0.7040    0.6430    0.6722     381.0

    accuracy                         0.7098    1623.0
   macro avg     0.7095    0.7184    0.7071    1623.0
weighted avg     0.7269    0.7098    0.7130    1623.0

[[109.   4.  13.   0.  17.   1.]
 [  2. 187.  27.   3.   0.  26.]
 [ 30.  20. 285.   7.   6.  36.]
 [  0.   0.   7. 124.   0.  39.]
 [ 68.   0.  28.   0. 202.   1.]
 [  0.  15.  57.  58.   6. 245.]]
epoch: 121, train_loss: 6.254799842834473, train_acc: 92.07, train_fscore: 92.0, valid_loss: 6.855500221252441, valid_acc: 73.64, valid_fscore: 73.98, test_loss: 7.808199882507324, test_acc: 70.79, test_fscore: 71.13, time: 2.05 sec
epoch: 122, train_loss: 6.263700008392334, train_acc: 92.4, train_fscore: 92.35, valid_loss: 6.889400005340576, valid_acc: 74.25, valid_fscore: 74.61, test_loss: 7.931700229644775, test_acc: 70.12, test_fscore: 70.44, time: 2.03 sec
epoch: 123, train_loss: 6.248499870300293, train_acc: 92.56, train_fscore: 92.51, valid_loss: 6.885300159454346, valid_acc: 73.95, valid_fscore: 74.1, test_loss: 7.900000095367432, test_acc: 70.79, test_fscore: 71.11, time: 2.01 sec
epoch: 124, train_loss: 6.25, train_acc: 92.09, train_fscore: 92.04, valid_loss: 6.856100082397461, valid_acc: 74.1, valid_fscore: 74.27, test_loss: 7.838399887084961, test_acc: 71.53, test_fscore: 71.89, time: 1.99 sec
epoch: 125, train_loss: 6.262899875640869, train_acc: 91.92, train_fscore: 91.87, valid_loss: 6.873000144958496, valid_acc: 74.55, valid_fscore: 74.86, test_loss: 7.9079999923706055, test_acc: 70.06, test_fscore: 70.33, time: 1.98 sec
epoch: 126, train_loss: 6.2484002113342285, train_acc: 92.27, train_fscore: 92.19, valid_loss: 6.931000232696533, valid_acc: 75.45, valid_fscore: 75.62, test_loss: 7.939899921417236, test_acc: 70.43, test_fscore: 70.73, time: 1.99 sec
epoch: 127, train_loss: 6.224299907684326, train_acc: 92.62, train_fscore: 92.58, valid_loss: 6.933499813079834, valid_acc: 74.25, valid_fscore: 74.44, test_loss: 7.974100112915039, test_acc: 70.67, test_fscore: 71.02, time: 1.96 sec
epoch: 128, train_loss: 6.196499824523926, train_acc: 92.77, train_fscore: 92.73, valid_loss: 6.8979997634887695, valid_acc: 74.4, valid_fscore: 74.7, test_loss: 7.911099910736084, test_acc: 70.3, test_fscore: 70.62, time: 1.97 sec
epoch: 129, train_loss: 6.217400074005127, train_acc: 92.79, train_fscore: 92.75, valid_loss: 6.931300163269043, valid_acc: 74.25, valid_fscore: 74.47, test_loss: 7.897500038146973, test_acc: 71.04, test_fscore: 71.39, time: 1.97 sec
epoch: 130, train_loss: 6.207499980926514, train_acc: 92.75, train_fscore: 92.7, valid_loss: 6.907899856567383, valid_acc: 74.7, valid_fscore: 74.82, test_loss: 7.853400230407715, test_acc: 71.1, test_fscore: 71.43, time: 1.95 sec
              precision    recall  f1-score   support

           0     0.5343    0.7569    0.6264     144.0
           1     0.8479    0.7510    0.7965     245.0
           2     0.6792    0.7500    0.7129     384.0
           3     0.6561    0.7294    0.6908     170.0
           4     0.8850    0.6689    0.7619     299.0
           5     0.6860    0.6535    0.6694     381.0

    accuracy                         0.7110    1623.0
   macro avg     0.7147    0.7183    0.7097    1623.0
weighted avg     0.7289    0.7110    0.7143    1623.0

[[109.   4.  14.   0.  16.   1.]
 [  2. 184.  27.   3.   0.  29.]
 [ 25.  17. 288.   6.   5.  43.]
 [  0.   0.   6. 124.   0.  40.]
 [ 68.   0.  30.   0. 200.   1.]
 [  0.  12.  59.  56.   5. 249.]]
epoch: 131, train_loss: 6.19920015335083, train_acc: 93.04, train_fscore: 93.01, valid_loss: 6.946499824523926, valid_acc: 74.25, valid_fscore: 74.48, test_loss: 7.913700103759766, test_acc: 71.72, test_fscore: 72.06, time: 1.99 sec
epoch: 132, train_loss: 6.18209981918335, train_acc: 93.14, train_fscore: 93.1, valid_loss: 6.909599781036377, valid_acc: 75.15, valid_fscore: 75.31, test_loss: 7.9629998207092285, test_acc: 70.79, test_fscore: 71.06, time: 1.95 sec
epoch: 133, train_loss: 6.166800022125244, train_acc: 93.22, train_fscore: 93.18, valid_loss: 6.9197998046875, valid_acc: 74.85, valid_fscore: 74.97, test_loss: 7.925000190734863, test_acc: 70.92, test_fscore: 71.23, time: 2.04 sec
epoch: 134, train_loss: 6.189300060272217, train_acc: 92.95, train_fscore: 92.89, valid_loss: 6.941199779510498, valid_acc: 74.4, valid_fscore: 74.69, test_loss: 7.962100028991699, test_acc: 71.23, test_fscore: 71.62, time: 2.04 sec
epoch: 135, train_loss: 6.175600051879883, train_acc: 93.32, train_fscore: 93.27, valid_loss: 6.985599994659424, valid_acc: 74.25, valid_fscore: 74.5, test_loss: 7.92140007019043, test_acc: 71.16, test_fscore: 71.45, time: 1.93 sec
epoch: 136, train_loss: 6.155200004577637, train_acc: 93.57, train_fscore: 93.53, valid_loss: 6.996399879455566, valid_acc: 75.0, valid_fscore: 75.16, test_loss: 7.905900001525879, test_acc: 71.78, test_fscore: 72.06, time: 1.97 sec
epoch: 137, train_loss: 6.173699855804443, train_acc: 93.14, train_fscore: 93.1, valid_loss: 6.926400184631348, valid_acc: 74.55, valid_fscore: 74.74, test_loss: 7.938300132751465, test_acc: 71.23, test_fscore: 71.52, time: 1.97 sec
epoch: 138, train_loss: 6.160799980163574, train_acc: 93.57, train_fscore: 93.53, valid_loss: 6.976900100708008, valid_acc: 74.25, valid_fscore: 74.39, test_loss: 7.940999984741211, test_acc: 71.53, test_fscore: 71.83, time: 2.01 sec
epoch: 139, train_loss: 6.116700172424316, train_acc: 93.55, train_fscore: 93.51, valid_loss: 7.019499778747559, valid_acc: 74.7, valid_fscore: 74.96, test_loss: 7.993199825286865, test_acc: 71.1, test_fscore: 71.42, time: 2.0 sec
epoch: 140, train_loss: 6.141300201416016, train_acc: 93.47, train_fscore: 93.44, valid_loss: 7.008500099182129, valid_acc: 74.7, valid_fscore: 74.86, test_loss: 7.976399898529053, test_acc: 70.61, test_fscore: 70.86, time: 1.97 sec
              precision    recall  f1-score   support

           0     0.5189    0.7639    0.6180     144.0
           1     0.8341    0.7796    0.8059     245.0
           2     0.6743    0.7708    0.7193     384.0
           3     0.6522    0.7059    0.6780     170.0
           4     0.8826    0.6288    0.7344     299.0
           5     0.6965    0.6325    0.6630     381.0

    accuracy                         0.7061    1623.0
   macro avg     0.7098    0.7136    0.7031    1623.0
weighted avg     0.7259    0.7061    0.7086    1623.0

[[110.   4.  14.   0.  15.   1.]
 [  2. 191.  24.   2.   0.  26.]
 [ 24.  20. 296.   4.   5.  35.]
 [  0.   0.   8. 120.   0.  42.]
 [ 76.   0.  34.   0. 188.   1.]
 [  0.  14.  63.  58.   5. 241.]]
epoch: 141, train_loss: 6.131400108337402, train_acc: 93.49, train_fscore: 93.44, valid_loss: 7.083899974822998, valid_acc: 74.85, valid_fscore: 74.98, test_loss: 8.00160026550293, test_acc: 71.04, test_fscore: 71.36, time: 1.92 sec
epoch: 142, train_loss: 6.124199867248535, train_acc: 94.05, train_fscore: 94.03, valid_loss: 7.033599853515625, valid_acc: 74.85, valid_fscore: 75.12, test_loss: 8.096500396728516, test_acc: 70.12, test_fscore: 70.47, time: 2.03 sec
epoch: 143, train_loss: 6.1132001876831055, train_acc: 94.25, train_fscore: 94.22, valid_loss: 6.984899997711182, valid_acc: 74.7, valid_fscore: 74.95, test_loss: 8.074199676513672, test_acc: 70.24, test_fscore: 70.58, time: 2.16 sec
epoch: 144, train_loss: 6.13070011138916, train_acc: 93.66, train_fscore: 93.63, valid_loss: 7.048999786376953, valid_acc: 75.0, valid_fscore: 75.06, test_loss: 7.932300090789795, test_acc: 71.47, test_fscore: 71.74, time: 2.31 sec
epoch: 145, train_loss: 6.1072001457214355, train_acc: 94.01, train_fscore: 93.98, valid_loss: 7.079899787902832, valid_acc: 74.55, valid_fscore: 74.65, test_loss: 7.968999862670898, test_acc: 71.47, test_fscore: 71.77, time: 2.28 sec
epoch: 146, train_loss: 6.099299907684326, train_acc: 94.4, train_fscore: 94.38, valid_loss: 7.035099983215332, valid_acc: 74.85, valid_fscore: 75.03, test_loss: 7.991600036621094, test_acc: 70.92, test_fscore: 71.18, time: 2.3 sec
epoch: 147, train_loss: 6.0833001136779785, train_acc: 94.46, train_fscore: 94.43, valid_loss: 7.041100025177002, valid_acc: 75.3, valid_fscore: 75.26, test_loss: 7.991700172424316, test_acc: 70.67, test_fscore: 70.88, time: 2.0 sec
epoch: 148, train_loss: 6.082399845123291, train_acc: 94.21, train_fscore: 94.17, valid_loss: 7.102099895477295, valid_acc: 74.85, valid_fscore: 75.04, test_loss: 8.040900230407715, test_acc: 71.6, test_fscore: 71.94, time: 1.96 sec
epoch: 149, train_loss: 6.066800117492676, train_acc: 94.87, train_fscore: 94.85, valid_loss: 7.085599899291992, valid_acc: 74.25, valid_fscore: 74.31, test_loss: 8.017399787902832, test_acc: 70.92, test_fscore: 71.18, time: 3.69 sec
epoch: 150, train_loss: 6.052299976348877, train_acc: 94.05, train_fscore: 94.01, valid_loss: 7.067299842834473, valid_acc: 74.7, valid_fscore: 74.86, test_loss: 8.029500007629395, test_acc: 70.86, test_fscore: 71.06, time: 4.53 sec
              precision    recall  f1-score   support

           0     0.5385    0.7292    0.6195     144.0
           1     0.8147    0.7714    0.7925     245.0
           2     0.6667    0.7812    0.7194     384.0
           3     0.6559    0.7176    0.6854     170.0
           4     0.8789    0.6555    0.7510     299.0
           5     0.7062    0.6247    0.6630     381.0

    accuracy                         0.7086    1623.0
   macro avg     0.7101    0.7133    0.7051    1623.0
weighted avg     0.7249    0.7086    0.7106    1623.0

[[105.   4.  17.   0.  17.   1.]
 [  2. 189.  26.   3.   0.  25.]
 [ 23.  20. 300.   4.   5.  32.]
 [  0.   0.   8. 122.   0.  40.]
 [ 65.   1.  36.   0. 196.   1.]
 [  0.  18.  63.  57.   5. 238.]]
Best validation F-Score: 71.06
Test performance..
F-Score: 71.06
Accuracy: 70.86
Loss: 8.029500007629395
--- 2 ---
loss_mask: [True, True, True, True]
Namespace(no_cuda=False, lr=0.0001, l2=1e-05, dropout=0.5, batch_size=64, hidden_dim=1024, n_head=8, epochs=150, temp=2, tensorboard=False, class_weight=True, Dataset='IEMOCAP', loss_mask='1111')
Running on GPU
temp 2
total parameters: 97535000
training parameters: 97535000
epoch: 1, train_loss: 12.334600448608398, train_acc: 22.13, train_fscore: 22.25, valid_loss: 10.2701997756958, valid_acc: 27.26, valid_fscore: 23.88, test_loss: 11.284199714660645, test_acc: 32.47, test_fscore: 27.36, time: 5.28 sec
epoch: 2, train_loss: 11.617899894714355, train_acc: 37.85, train_fscore: 37.32, valid_loss: 9.75220012664795, valid_acc: 39.31, valid_fscore: 32.46, test_loss: 10.809599876403809, test_acc: 33.83, test_fscore: 28.92, time: 4.37 sec
epoch: 3, train_loss: 11.143400192260742, train_acc: 43.43, train_fscore: 39.85, valid_loss: 9.255200386047363, valid_acc: 54.07, valid_fscore: 55.65, test_loss: 10.374099731445312, test_acc: 48.37, test_fscore: 48.11, time: 4.46 sec
epoch: 4, train_loss: 10.715399742126465, train_acc: 53.46, train_fscore: 52.43, valid_loss: 8.930000305175781, valid_acc: 54.22, valid_fscore: 54.43, test_loss: 10.054400444030762, test_acc: 54.16, test_fscore: 53.41, time: 4.03 sec
epoch: 5, train_loss: 10.410900115966797, train_acc: 57.33, train_fscore: 56.08, valid_loss: 8.735099792480469, valid_acc: 62.2, valid_fscore: 63.01, test_loss: 9.929900169372559, test_acc: 54.96, test_fscore: 55.09, time: 4.52 sec
epoch: 6, train_loss: 10.150099754333496, train_acc: 59.99, train_fscore: 58.98, valid_loss: 8.545999526977539, valid_acc: 63.55, valid_fscore: 64.4, test_loss: 9.767900466918945, test_acc: 58.16, test_fscore: 58.44, time: 4.58 sec
epoch: 7, train_loss: 9.870499610900879, train_acc: 63.62, train_fscore: 63.18, valid_loss: 8.274399757385254, valid_acc: 64.91, valid_fscore: 66.52, test_loss: 9.50629997253418, test_acc: 58.96, test_fscore: 59.65, time: 4.35 sec
epoch: 8, train_loss: 9.561699867248535, train_acc: 63.82, train_fscore: 63.63, valid_loss: 7.8130998611450195, valid_acc: 65.21, valid_fscore: 66.84, test_loss: 9.093299865722656, test_acc: 59.33, test_fscore: 60.06, time: 4.28 sec
epoch: 9, train_loss: 9.190899848937988, train_acc: 67.04, train_fscore: 66.91, valid_loss: 7.468999862670898, valid_acc: 65.51, valid_fscore: 66.97, test_loss: 8.7677001953125, test_acc: 61.8, test_fscore: 62.53, time: 4.59 sec
epoch: 10, train_loss: 8.989800453186035, train_acc: 67.53, train_fscore: 67.04, valid_loss: 7.428800106048584, valid_acc: 64.01, valid_fscore: 66.36, test_loss: 8.703200340270996, test_acc: 61.24, test_fscore: 62.17, time: 4.53 sec
              precision    recall  f1-score   support

           0     0.3179    0.6667    0.4305     144.0
           1     0.7696    0.7224    0.7453     245.0
           2     0.6526    0.5234    0.5809     384.0
           3     0.5747    0.7471    0.6496     170.0
           4     0.8030    0.5452    0.6494     299.0
           5     0.6407    0.6037    0.6216     381.0

    accuracy                         0.6124    1623.0
   macro avg     0.6264    0.6347    0.6129    1623.0
weighted avg     0.6573    0.6124    0.6217    1623.0

[[ 96.   8.   7.   2.  30.   1.]
 [ 10. 177.  26.   4.   0.  28.]
 [ 67.  27. 201.  25.   3.  61.]
 [  0.   0.   5. 127.   0.  38.]
 [119.   0.  14.   2. 163.   1.]
 [ 10.  18.  55.  61.   7. 230.]]
epoch: 11, train_loss: 8.888099670410156, train_acc: 67.47, train_fscore: 67.12, valid_loss: 7.335899829864502, valid_acc: 66.42, valid_fscore: 67.79, test_loss: 8.630900382995605, test_acc: 63.22, test_fscore: 64.21, time: 4.57 sec
epoch: 12, train_loss: 8.777000427246094, train_acc: 68.97, train_fscore: 68.64, valid_loss: 7.25439977645874, valid_acc: 65.81, valid_fscore: 67.09, test_loss: 8.535699844360352, test_acc: 62.91, test_fscore: 63.99, time: 4.59 sec
epoch: 13, train_loss: 8.702400207519531, train_acc: 68.71, train_fscore: 68.52, valid_loss: 7.132699966430664, valid_acc: 66.11, valid_fscore: 67.7, test_loss: 8.395500183105469, test_acc: 63.65, test_fscore: 64.67, time: 4.35 sec
epoch: 14, train_loss: 8.604299545288086, train_acc: 69.53, train_fscore: 69.21, valid_loss: 6.957600116729736, valid_acc: 70.33, valid_fscore: 70.78, test_loss: 8.222200393676758, test_acc: 65.37, test_fscore: 66.02, time: 4.43 sec
epoch: 15, train_loss: 8.506199836730957, train_acc: 70.48, train_fscore: 70.06, valid_loss: 6.914700031280518, valid_acc: 68.98, valid_fscore: 70.69, test_loss: 8.13759994506836, test_acc: 63.09, test_fscore: 64.03, time: 4.54 sec
epoch: 16, train_loss: 8.409799575805664, train_acc: 70.97, train_fscore: 70.64, valid_loss: 6.946899890899658, valid_acc: 68.37, valid_fscore: 69.79, test_loss: 8.14430046081543, test_acc: 64.94, test_fscore: 65.72, time: 4.46 sec
epoch: 17, train_loss: 8.388899803161621, train_acc: 70.21, train_fscore: 69.83, valid_loss: 6.91480016708374, valid_acc: 68.22, valid_fscore: 69.54, test_loss: 8.161100387573242, test_acc: 64.88, test_fscore: 65.64, time: 4.09 sec
epoch: 18, train_loss: 8.32919979095459, train_acc: 70.83, train_fscore: 70.37, valid_loss: 6.774400234222412, valid_acc: 69.43, valid_fscore: 71.21, test_loss: 8.093400001525879, test_acc: 64.26, test_fscore: 65.1, time: 4.38 sec
epoch: 19, train_loss: 8.23740005493164, train_acc: 72.19, train_fscore: 71.85, valid_loss: 6.71019983291626, valid_acc: 69.73, valid_fscore: 71.6, test_loss: 8.013999938964844, test_acc: 64.76, test_fscore: 65.6, time: 3.56 sec
epoch: 20, train_loss: 8.160200119018555, train_acc: 73.16, train_fscore: 72.95, valid_loss: 6.737599849700928, valid_acc: 70.18, valid_fscore: 71.08, test_loss: 8.019599914550781, test_acc: 66.91, test_fscore: 67.44, time: 4.38 sec
              precision    recall  f1-score   support

           0     0.4147    0.6250    0.4986     144.0
           1     0.7619    0.7184    0.7395     245.0
           2     0.6742    0.6250    0.6486     384.0
           3     0.6173    0.7118    0.6612     170.0
           4     0.8385    0.7291    0.7800     299.0
           5     0.6639    0.6325    0.6478     381.0

    accuracy                         0.6691    1623.0
   macro avg     0.6618    0.6736    0.6626    1623.0
weighted avg     0.6863    0.6691    0.6744    1623.0

[[ 90.   8.  11.   3.  30.   2.]
 [  5. 176.  33.   2.   0.  29.]
 [ 49.  27. 240.  17.   6.  45.]
 [  0.   0.   5. 121.   0.  44.]
 [ 68.   0.  11.   0. 218.   2.]
 [  5.  20.  56.  53.   6. 241.]]
epoch: 21, train_loss: 8.11460018157959, train_acc: 73.44, train_fscore: 73.07, valid_loss: 6.726500034332275, valid_acc: 70.03, valid_fscore: 71.71, test_loss: 8.052499771118164, test_acc: 65.13, test_fscore: 65.81, time: 3.56 sec
epoch: 22, train_loss: 8.077099800109863, train_acc: 72.77, train_fscore: 72.47, valid_loss: 6.710299968719482, valid_acc: 70.18, valid_fscore: 72.01, test_loss: 8.02280044555664, test_acc: 64.94, test_fscore: 65.69, time: 3.75 sec
epoch: 23, train_loss: 8.04520034790039, train_acc: 73.69, train_fscore: 73.47, valid_loss: 6.674699783325195, valid_acc: 70.93, valid_fscore: 71.34, test_loss: 7.954800128936768, test_acc: 67.78, test_fscore: 68.11, time: 3.51 sec
epoch: 24, train_loss: 7.956999778747559, train_acc: 74.49, train_fscore: 74.19, valid_loss: 6.654600143432617, valid_acc: 70.18, valid_fscore: 72.05, test_loss: 7.939300060272217, test_acc: 65.87, test_fscore: 66.67, time: 4.34 sec
epoch: 25, train_loss: 7.916299819946289, train_acc: 74.02, train_fscore: 73.81, valid_loss: 6.625199794769287, valid_acc: 71.39, valid_fscore: 72.75, test_loss: 7.914599895477295, test_acc: 66.17, test_fscore: 66.84, time: 4.21 sec
epoch: 26, train_loss: 7.877699851989746, train_acc: 74.87, train_fscore: 74.63, valid_loss: 6.578999996185303, valid_acc: 71.54, valid_fscore: 72.11, test_loss: 7.874599933624268, test_acc: 67.53, test_fscore: 67.91, time: 4.3 sec
epoch: 27, train_loss: 7.830999851226807, train_acc: 74.76, train_fscore: 74.4, valid_loss: 6.633900165557861, valid_acc: 69.43, valid_fscore: 71.36, test_loss: 7.914899826049805, test_acc: 64.88, test_fscore: 65.67, time: 4.53 sec
epoch: 28, train_loss: 7.7895002365112305, train_acc: 74.93, train_fscore: 74.8, valid_loss: 6.6545000076293945, valid_acc: 70.18, valid_fscore: 72.37, test_loss: 7.927700042724609, test_acc: 65.13, test_fscore: 65.87, time: 4.46 sec
epoch: 29, train_loss: 7.748700141906738, train_acc: 75.94, train_fscore: 75.85, valid_loss: 6.583799839019775, valid_acc: 71.08, valid_fscore: 71.67, test_loss: 7.83650016784668, test_acc: 68.27, test_fscore: 68.51, time: 4.56 sec
epoch: 30, train_loss: 7.712399959564209, train_acc: 76.1, train_fscore: 75.85, valid_loss: 6.558000087738037, valid_acc: 70.63, valid_fscore: 71.43, test_loss: 7.75600004196167, test_acc: 67.9, test_fscore: 68.36, time: 3.55 sec
              precision    recall  f1-score   support

           0     0.4571    0.6667    0.5424     144.0
           1     0.7822    0.7184    0.7489     245.0
           2     0.6945    0.6276    0.6594     384.0
           3     0.5917    0.7588    0.6649     170.0
           4     0.8538    0.7224    0.7826     299.0
           5     0.6595    0.6404    0.6498     381.0

    accuracy                         0.6790    1623.0
   macro avg     0.6731    0.6890    0.6747    1623.0
weighted avg     0.6970    0.6790    0.6836    1623.0

[[ 96.   7.  13.   4.  23.   1.]
 [  4. 176.  29.   2.   0.  34.]
 [ 39.  26. 241.  20.   7.  51.]
 [  0.   0.   3. 129.   0.  38.]
 [ 71.   0.  10.   0. 216.   2.]
 [  0.  16.  51.  63.   7. 244.]]
epoch: 31, train_loss: 7.6691999435424805, train_acc: 75.46, train_fscore: 75.18, valid_loss: 6.552800178527832, valid_acc: 70.93, valid_fscore: 72.59, test_loss: 7.7600998878479, test_acc: 65.68, test_fscore: 66.34, time: 4.68 sec
epoch: 32, train_loss: 7.644100189208984, train_acc: 76.35, train_fscore: 76.12, valid_loss: 6.523499965667725, valid_acc: 73.34, valid_fscore: 74.19, test_loss: 7.803100109100342, test_acc: 67.84, test_fscore: 68.28, time: 4.59 sec
epoch: 33, train_loss: 7.615200042724609, train_acc: 77.69, train_fscore: 77.48, valid_loss: 6.581299781799316, valid_acc: 71.23, valid_fscore: 72.23, test_loss: 7.771299839019775, test_acc: 67.71, test_fscore: 68.26, time: 4.42 sec
epoch: 34, train_loss: 7.5792999267578125, train_acc: 77.61, train_fscore: 77.46, valid_loss: 6.586900234222412, valid_acc: 70.03, valid_fscore: 71.68, test_loss: 7.735099792480469, test_acc: 66.3, test_fscore: 67.02, time: 3.85 sec
epoch: 35, train_loss: 7.5594000816345215, train_acc: 77.61, train_fscore: 77.51, valid_loss: 6.487599849700928, valid_acc: 71.69, valid_fscore: 72.52, test_loss: 7.689799785614014, test_acc: 68.02, test_fscore: 68.52, time: 3.95 sec
epoch: 36, train_loss: 7.549699783325195, train_acc: 78.27, train_fscore: 78.1, valid_loss: 6.509799957275391, valid_acc: 71.39, valid_fscore: 72.28, test_loss: 7.674600124359131, test_acc: 68.02, test_fscore: 68.52, time: 4.45 sec
epoch: 37, train_loss: 7.493299961090088, train_acc: 78.92, train_fscore: 78.75, valid_loss: 6.562600135803223, valid_acc: 70.03, valid_fscore: 71.29, test_loss: 7.698800086975098, test_acc: 66.36, test_fscore: 67.01, time: 4.48 sec
epoch: 38, train_loss: 7.462200164794922, train_acc: 78.16, train_fscore: 78.0, valid_loss: 6.507599830627441, valid_acc: 71.54, valid_fscore: 72.5, test_loss: 7.688899993896484, test_acc: 67.28, test_fscore: 67.87, time: 4.07 sec
epoch: 39, train_loss: 7.446400165557861, train_acc: 79.34, train_fscore: 79.25, valid_loss: 6.4770002365112305, valid_acc: 72.74, valid_fscore: 73.37, test_loss: 7.665800094604492, test_acc: 67.28, test_fscore: 67.79, time: 4.75 sec
epoch: 40, train_loss: 7.4268999099731445, train_acc: 79.11, train_fscore: 78.94, valid_loss: 6.494900226593018, valid_acc: 71.23, valid_fscore: 72.29, test_loss: 7.641300201416016, test_acc: 66.67, test_fscore: 67.26, time: 4.7 sec
              precision    recall  f1-score   support

           0     0.4194    0.7222    0.5306     144.0
           1     0.7848    0.7592    0.7718     245.0
           2     0.6971    0.6354    0.6649     384.0
           3     0.5764    0.7765    0.6617     170.0
           4     0.8710    0.6321    0.7326     299.0
           5     0.6637    0.5958    0.6279     381.0

    accuracy                         0.6667    1623.0
   macro avg     0.6687    0.6869    0.6649    1623.0
weighted avg     0.6973    0.6667    0.6726    1623.0

[[104.   6.  14.   2.  17.   1.]
 [  3. 186.  26.   2.   0.  28.]
 [ 43.  26. 244.  17.   5.  49.]
 [  0.   0.   3. 132.   0.  35.]
 [ 98.   1.   9.   0. 189.   2.]
 [  0.  18.  54.  76.   6. 227.]]
epoch: 41, train_loss: 7.406400203704834, train_acc: 79.81, train_fscore: 79.69, valid_loss: 6.534200191497803, valid_acc: 71.23, valid_fscore: 72.64, test_loss: 7.669899940490723, test_acc: 66.85, test_fscore: 67.47, time: 4.43 sec
epoch: 42, train_loss: 7.367099761962891, train_acc: 79.48, train_fscore: 79.37, valid_loss: 6.491499900817871, valid_acc: 72.74, valid_fscore: 73.67, test_loss: 7.64870023727417, test_acc: 67.53, test_fscore: 68.07, time: 4.42 sec
epoch: 43, train_loss: 7.34060001373291, train_acc: 80.04, train_fscore: 79.85, valid_loss: 6.504499912261963, valid_acc: 72.29, valid_fscore: 73.39, test_loss: 7.633500099182129, test_acc: 66.67, test_fscore: 67.29, time: 4.6 sec
epoch: 44, train_loss: 7.310500144958496, train_acc: 81.33, train_fscore: 81.24, valid_loss: 6.478000164031982, valid_acc: 72.89, valid_fscore: 74.05, test_loss: 7.6483001708984375, test_acc: 67.28, test_fscore: 67.91, time: 4.47 sec
epoch: 45, train_loss: 7.275000095367432, train_acc: 81.11, train_fscore: 81.01, valid_loss: 6.454999923706055, valid_acc: 71.54, valid_fscore: 72.56, test_loss: 7.611499786376953, test_acc: 67.9, test_fscore: 68.51, time: 4.48 sec
epoch: 46, train_loss: 7.283899784088135, train_acc: 80.76, train_fscore: 80.58, valid_loss: 6.4847002029418945, valid_acc: 71.99, valid_fscore: 72.85, test_loss: 7.612199783325195, test_acc: 67.65, test_fscore: 68.25, time: 4.51 sec
epoch: 47, train_loss: 7.264500141143799, train_acc: 81.17, train_fscore: 80.99, valid_loss: 6.541500091552734, valid_acc: 72.74, valid_fscore: 73.97, test_loss: 7.656799793243408, test_acc: 66.67, test_fscore: 67.24, time: 4.5 sec
epoch: 48, train_loss: 7.225800037384033, train_acc: 81.29, train_fscore: 81.2, valid_loss: 6.5269999504089355, valid_acc: 72.14, valid_fscore: 73.1, test_loss: 7.6057000160217285, test_acc: 68.15, test_fscore: 68.77, time: 4.48 sec
epoch: 49, train_loss: 7.2144999504089355, train_acc: 81.81, train_fscore: 81.7, valid_loss: 6.504000186920166, valid_acc: 72.29, valid_fscore: 72.92, test_loss: 7.598899841308594, test_acc: 68.39, test_fscore: 68.96, time: 4.03 sec
epoch: 50, train_loss: 7.182700157165527, train_acc: 81.73, train_fscore: 81.62, valid_loss: 6.53879976272583, valid_acc: 70.78, valid_fscore: 72.17, test_loss: 7.659999847412109, test_acc: 66.67, test_fscore: 67.24, time: 4.45 sec
              precision    recall  f1-score   support

           0     0.4054    0.8333    0.5455     144.0
           1     0.8166    0.7633    0.7890     245.0
           2     0.7022    0.6510    0.6757     384.0
           3     0.6263    0.7294    0.6739     170.0
           4     0.9000    0.5117    0.6525     299.0
           5     0.6631    0.6509    0.6570     381.0

    accuracy                         0.6667    1623.0
   macro avg     0.6856    0.6899    0.6656    1623.0
weighted avg     0.7125    0.6667    0.6724    1623.0

[[120.   4.  10.   0.   8.   2.]
 [  2. 187.  22.   2.   0.  32.]
 [ 45.  23. 250.  14.   4.  48.]
 [  0.   0.   4. 124.   0.  42.]
 [128.   1.  15.   0. 153.   2.]
 [  1.  14.  55.  58.   5. 248.]]
epoch: 51, train_loss: 7.183700084686279, train_acc: 82.47, train_fscore: 82.39, valid_loss: 6.508299827575684, valid_acc: 72.89, valid_fscore: 73.8, test_loss: 7.616099834442139, test_acc: 68.08, test_fscore: 68.59, time: 4.13 sec
epoch: 52, train_loss: 7.158899784088135, train_acc: 82.71, train_fscore: 82.56, valid_loss: 6.5142998695373535, valid_acc: 72.44, valid_fscore: 73.28, test_loss: 7.586999893188477, test_acc: 69.13, test_fscore: 69.64, time: 3.74 sec
epoch: 53, train_loss: 7.123199939727783, train_acc: 82.02, train_fscore: 81.89, valid_loss: 6.50570011138916, valid_acc: 73.04, valid_fscore: 74.09, test_loss: 7.6234002113342285, test_acc: 67.59, test_fscore: 68.13, time: 3.73 sec
epoch: 54, train_loss: 7.123499870300293, train_acc: 82.8, train_fscore: 82.73, valid_loss: 6.534599781036377, valid_acc: 72.29, valid_fscore: 73.67, test_loss: 7.63129997253418, test_acc: 67.22, test_fscore: 67.75, time: 4.47 sec
epoch: 55, train_loss: 7.084499835968018, train_acc: 83.11, train_fscore: 83.05, valid_loss: 6.508200168609619, valid_acc: 72.14, valid_fscore: 73.01, test_loss: 7.579699993133545, test_acc: 68.76, test_fscore: 69.29, time: 4.48 sec
epoch: 56, train_loss: 7.084400177001953, train_acc: 83.02, train_fscore: 82.88, valid_loss: 6.5447998046875, valid_acc: 72.29, valid_fscore: 73.2, test_loss: 7.578100204467773, test_acc: 69.13, test_fscore: 69.65, time: 4.53 sec
epoch: 57, train_loss: 7.065999984741211, train_acc: 83.7, train_fscore: 83.59, valid_loss: 6.558000087738037, valid_acc: 72.89, valid_fscore: 73.94, test_loss: 7.586699962615967, test_acc: 68.52, test_fscore: 69.09, time: 4.22 sec
epoch: 58, train_loss: 7.059999942779541, train_acc: 83.7, train_fscore: 83.62, valid_loss: 6.5432000160217285, valid_acc: 72.44, valid_fscore: 73.44, test_loss: 7.559800148010254, test_acc: 68.88, test_fscore: 69.43, time: 4.55 sec
epoch: 59, train_loss: 7.045499801635742, train_acc: 83.33, train_fscore: 83.23, valid_loss: 6.550300121307373, valid_acc: 72.74, valid_fscore: 73.79, test_loss: 7.57919979095459, test_acc: 68.7, test_fscore: 69.3, time: 4.18 sec
epoch: 60, train_loss: 6.9953999519348145, train_acc: 83.99, train_fscore: 83.86, valid_loss: 6.497700214385986, valid_acc: 74.1, valid_fscore: 74.72, test_loss: 7.5746002197265625, test_acc: 69.62, test_fscore: 70.07, time: 4.54 sec
              precision    recall  f1-score   support

           0     0.4596    0.7500    0.5699     144.0
           1     0.8000    0.8000    0.8000     245.0
           2     0.7167    0.6719    0.6935     384.0
           3     0.6250    0.7647    0.6878     170.0
           4     0.8733    0.6455    0.7423     299.0
           5     0.6921    0.6430    0.6667     381.0

    accuracy                         0.6962    1623.0
   macro avg     0.6944    0.7125    0.6934    1623.0
weighted avg     0.7199    0.6962    0.7007    1623.0

[[108.   5.  13.   0.  17.   1.]
 [  2. 196.  19.   2.   0.  26.]
 [ 37.  28. 258.  12.   5.  44.]
 [  0.   0.   5. 130.   0.  35.]
 [ 88.   1.  14.   0. 193.   3.]
 [  0.  15.  51.  64.   6. 245.]]
epoch: 61, train_loss: 6.999000072479248, train_acc: 83.81, train_fscore: 83.68, valid_loss: 6.519899845123291, valid_acc: 72.59, valid_fscore: 73.53, test_loss: 7.631499767303467, test_acc: 68.39, test_fscore: 68.96, time: 3.97 sec
epoch: 62, train_loss: 6.9741997718811035, train_acc: 84.32, train_fscore: 84.27, valid_loss: 6.551599979400635, valid_acc: 72.59, valid_fscore: 73.64, test_loss: 7.580100059509277, test_acc: 68.7, test_fscore: 69.25, time: 4.23 sec
epoch: 63, train_loss: 6.94890022277832, train_acc: 84.55, train_fscore: 84.43, valid_loss: 6.547699928283691, valid_acc: 72.14, valid_fscore: 73.21, test_loss: 7.552800178527832, test_acc: 69.19, test_fscore: 69.69, time: 3.84 sec
epoch: 64, train_loss: 6.950300216674805, train_acc: 83.66, train_fscore: 83.49, valid_loss: 6.515500068664551, valid_acc: 73.04, valid_fscore: 73.9, test_loss: 7.572800159454346, test_acc: 69.19, test_fscore: 69.71, time: 4.42 sec
epoch: 65, train_loss: 6.917399883270264, train_acc: 85.11, train_fscore: 85.05, valid_loss: 6.524099826812744, valid_acc: 73.95, valid_fscore: 74.72, test_loss: 7.576000213623047, test_acc: 69.69, test_fscore: 70.2, time: 4.52 sec
epoch: 66, train_loss: 6.910999774932861, train_acc: 84.76, train_fscore: 84.69, valid_loss: 6.5121002197265625, valid_acc: 74.25, valid_fscore: 74.74, test_loss: 7.510000228881836, test_acc: 70.36, test_fscore: 70.82, time: 4.23 sec
epoch: 67, train_loss: 6.896900177001953, train_acc: 85.31, train_fscore: 85.2, valid_loss: 6.550899982452393, valid_acc: 72.89, valid_fscore: 73.95, test_loss: 7.585599899291992, test_acc: 68.82, test_fscore: 69.33, time: 3.49 sec
epoch: 68, train_loss: 6.881400108337402, train_acc: 85.04, train_fscore: 84.96, valid_loss: 6.546000003814697, valid_acc: 73.8, valid_fscore: 74.6, test_loss: 7.623799800872803, test_acc: 68.33, test_fscore: 68.77, time: 4.52 sec
epoch: 69, train_loss: 6.868100166320801, train_acc: 85.97, train_fscore: 85.88, valid_loss: 6.533100128173828, valid_acc: 74.25, valid_fscore: 74.74, test_loss: 7.58620023727417, test_acc: 69.75, test_fscore: 70.22, time: 4.54 sec
epoch: 70, train_loss: 6.834700107574463, train_acc: 85.43, train_fscore: 85.33, valid_loss: 6.5630998611450195, valid_acc: 73.8, valid_fscore: 74.44, test_loss: 7.586599826812744, test_acc: 69.87, test_fscore: 70.4, time: 4.31 sec
              precision    recall  f1-score   support

           0     0.4618    0.7986    0.5852     144.0
           1     0.8326    0.7714    0.8008     245.0
           2     0.7189    0.6927    0.7056     384.0
           3     0.6244    0.7529    0.6827     170.0
           4     0.8884    0.6388    0.7432     299.0
           5     0.6863    0.6430    0.6640     381.0

    accuracy                         0.6987    1623.0
   macro avg     0.7021    0.7163    0.6969    1623.0
weighted avg     0.7269    0.6987    0.7040    1623.0

[[115.   4.  10.   0.  14.   1.]
 [  3. 189.  20.   3.   0.  30.]
 [ 41.  19. 266.  12.   4.  42.]
 [  0.   0.   5. 128.   0.  37.]
 [ 89.   1.  16.   0. 191.   2.]
 [  1.  14.  53.  62.   6. 245.]]
epoch: 71, train_loss: 6.846499919891357, train_acc: 85.87, train_fscore: 85.79, valid_loss: 6.539599895477295, valid_acc: 73.8, valid_fscore: 74.51, test_loss: 7.614999771118164, test_acc: 68.82, test_fscore: 69.28, time: 3.96 sec
epoch: 72, train_loss: 6.808700084686279, train_acc: 86.26, train_fscore: 86.19, valid_loss: 6.531199932098389, valid_acc: 74.25, valid_fscore: 74.9, test_loss: 7.6072998046875, test_acc: 69.56, test_fscore: 70.02, time: 4.55 sec
epoch: 73, train_loss: 6.789599895477295, train_acc: 85.64, train_fscore: 85.53, valid_loss: 6.585700035095215, valid_acc: 72.59, valid_fscore: 73.08, test_loss: 7.616199970245361, test_acc: 70.36, test_fscore: 70.96, time: 4.41 sec
epoch: 74, train_loss: 6.804699897766113, train_acc: 85.58, train_fscore: 85.5, valid_loss: 6.541100025177002, valid_acc: 74.4, valid_fscore: 75.07, test_loss: 7.606100082397461, test_acc: 69.69, test_fscore: 70.14, time: 4.54 sec
epoch: 75, train_loss: 6.7733001708984375, train_acc: 86.57, train_fscore: 86.47, valid_loss: 6.55620002746582, valid_acc: 73.95, valid_fscore: 74.44, test_loss: 7.63670015335083, test_acc: 68.88, test_fscore: 69.27, time: 4.54 sec
epoch: 76, train_loss: 6.791900157928467, train_acc: 86.38, train_fscore: 86.3, valid_loss: 6.565999984741211, valid_acc: 73.34, valid_fscore: 74.09, test_loss: 7.557499885559082, test_acc: 70.18, test_fscore: 70.71, time: 3.37 sec
epoch: 77, train_loss: 6.733699798583984, train_acc: 86.82, train_fscore: 86.73, valid_loss: 6.582600116729736, valid_acc: 73.95, valid_fscore: 74.47, test_loss: 7.570099830627441, test_acc: 70.24, test_fscore: 70.76, time: 3.13 sec
epoch: 78, train_loss: 6.745999813079834, train_acc: 87.31, train_fscore: 87.22, valid_loss: 6.584499835968018, valid_acc: 72.74, valid_fscore: 73.56, test_loss: 7.658199787139893, test_acc: 69.32, test_fscore: 69.78, time: 3.26 sec
epoch: 79, train_loss: 6.7368998527526855, train_acc: 86.92, train_fscore: 86.88, valid_loss: 6.5644001960754395, valid_acc: 74.7, valid_fscore: 75.27, test_loss: 7.623899936676025, test_acc: 69.56, test_fscore: 69.96, time: 2.91 sec
epoch: 80, train_loss: 6.716599941253662, train_acc: 87.16, train_fscore: 87.04, valid_loss: 6.563499927520752, valid_acc: 73.8, valid_fscore: 74.54, test_loss: 7.598499774932861, test_acc: 70.73, test_fscore: 71.19, time: 3.07 sec
              precision    recall  f1-score   support

           0     0.4756    0.8125    0.6000     144.0
           1     0.8120    0.7755    0.7933     245.0
           2     0.7188    0.7188    0.7188     384.0
           3     0.6596    0.7294    0.6927     170.0
           4     0.8962    0.6355    0.7436     299.0
           5     0.6992    0.6588    0.6784     381.0

    accuracy                         0.7073    1623.0
   macro avg     0.7102    0.7217    0.7045    1623.0
weighted avg     0.7331    0.7073    0.7119    1623.0

[[117.   5.   9.   0.  12.   1.]
 [  3. 190.  22.   3.   0.  27.]
 [ 36.  24. 276.   8.   4.  36.]
 [  0.   0.   5. 124.   0.  41.]
 [ 89.   1.  16.   0. 190.   3.]
 [  1.  14.  56.  53.   6. 251.]]
epoch: 81, train_loss: 6.691800117492676, train_acc: 87.12, train_fscore: 87.03, valid_loss: 6.603700160980225, valid_acc: 74.1, valid_fscore: 74.77, test_loss: 7.638500213623047, test_acc: 70.24, test_fscore: 70.71, time: 3.18 sec
epoch: 82, train_loss: 6.700200080871582, train_acc: 87.12, train_fscore: 87.02, valid_loss: 6.604400157928467, valid_acc: 73.95, valid_fscore: 74.44, test_loss: 7.651400089263916, test_acc: 69.5, test_fscore: 69.98, time: 2.97 sec
epoch: 83, train_loss: 6.694699764251709, train_acc: 87.7, train_fscore: 87.66, valid_loss: 6.613800048828125, valid_acc: 73.49, valid_fscore: 74.32, test_loss: 7.684100151062012, test_acc: 69.19, test_fscore: 69.68, time: 3.23 sec
epoch: 84, train_loss: 6.6529998779296875, train_acc: 87.68, train_fscore: 87.6, valid_loss: 6.567200183868408, valid_acc: 74.1, valid_fscore: 74.74, test_loss: 7.621200084686279, test_acc: 69.87, test_fscore: 70.34, time: 3.93 sec
epoch: 85, train_loss: 6.665599822998047, train_acc: 88.2, train_fscore: 88.11, valid_loss: 6.592599868774414, valid_acc: 73.95, valid_fscore: 74.72, test_loss: 7.6255998611450195, test_acc: 70.3, test_fscore: 70.75, time: 2.21 sec
epoch: 86, train_loss: 6.644999980926514, train_acc: 87.87, train_fscore: 87.83, valid_loss: 6.636499881744385, valid_acc: 73.19, valid_fscore: 73.97, test_loss: 7.631999969482422, test_acc: 69.75, test_fscore: 70.22, time: 3.81 sec
epoch: 87, train_loss: 6.629799842834473, train_acc: 87.99, train_fscore: 87.9, valid_loss: 6.649400234222412, valid_acc: 73.34, valid_fscore: 73.94, test_loss: 7.578100204467773, test_acc: 70.98, test_fscore: 71.44, time: 3.18 sec
epoch: 88, train_loss: 6.616700172424316, train_acc: 87.95, train_fscore: 87.88, valid_loss: 6.6178998947143555, valid_acc: 73.49, valid_fscore: 74.11, test_loss: 7.633299827575684, test_acc: 69.93, test_fscore: 70.4, time: 3.02 sec
epoch: 89, train_loss: 6.602799892425537, train_acc: 88.38, train_fscore: 88.28, valid_loss: 6.588099956512451, valid_acc: 73.95, valid_fscore: 74.46, test_loss: 7.63700008392334, test_acc: 69.93, test_fscore: 70.37, time: 3.32 sec
epoch: 90, train_loss: 6.578199863433838, train_acc: 88.52, train_fscore: 88.43, valid_loss: 6.605199813842773, valid_acc: 74.55, valid_fscore: 75.14, test_loss: 7.664599895477295, test_acc: 70.55, test_fscore: 71.01, time: 3.13 sec
              precision    recall  f1-score   support

           0     0.4772    0.7986    0.5974     144.0
           1     0.8356    0.7673    0.8000     245.0
           2     0.7215    0.7083    0.7148     384.0
           3     0.6704    0.7059    0.6877     170.0
           4     0.8894    0.6187    0.7298     299.0
           5     0.6743    0.6955    0.6848     381.0

    accuracy                         0.7055    1623.0
   macro avg     0.7114    0.7157    0.7024    1623.0
weighted avg     0.7315    0.7055    0.7101    1623.0

[[115.   4.  11.   0.  13.   1.]
 [  2. 188.  21.   3.   0.  31.]
 [ 35.  19. 272.   8.   4.  46.]
 [  0.   0.   3. 120.   0.  47.]
 [ 89.   1.  21.   0. 185.   3.]
 [  0.  13.  49.  48.   6. 265.]]
epoch: 91, train_loss: 6.581200122833252, train_acc: 88.79, train_fscore: 88.73, valid_loss: 6.599699974060059, valid_acc: 73.8, valid_fscore: 74.32, test_loss: 7.6356000900268555, test_acc: 70.86, test_fscore: 71.29, time: 4.04 sec
epoch: 92, train_loss: 6.590099811553955, train_acc: 88.57, train_fscore: 88.48, valid_loss: 6.595099925994873, valid_acc: 73.8, valid_fscore: 74.13, test_loss: 7.617700099945068, test_acc: 70.3, test_fscore: 70.67, time: 3.11 sec
epoch: 93, train_loss: 6.563700199127197, train_acc: 88.88, train_fscore: 88.79, valid_loss: 6.652500152587891, valid_acc: 73.49, valid_fscore: 74.1, test_loss: 7.639500141143799, test_acc: 70.67, test_fscore: 71.08, time: 3.1 sec
epoch: 94, train_loss: 6.543600082397461, train_acc: 88.87, train_fscore: 88.79, valid_loss: 6.6996002197265625, valid_acc: 73.19, valid_fscore: 73.87, test_loss: 7.668099880218506, test_acc: 69.75, test_fscore: 70.18, time: 3.01 sec
epoch: 95, train_loss: 6.538400173187256, train_acc: 89.29, train_fscore: 89.21, valid_loss: 6.707399845123291, valid_acc: 74.25, valid_fscore: 74.63, test_loss: 7.644199848175049, test_acc: 70.73, test_fscore: 71.14, time: 2.99 sec
epoch: 96, train_loss: 6.540599822998047, train_acc: 89.41, train_fscore: 89.34, valid_loss: 6.695300102233887, valid_acc: 73.8, valid_fscore: 74.15, test_loss: 7.638800144195557, test_acc: 70.49, test_fscore: 70.86, time: 3.05 sec
epoch: 97, train_loss: 6.518899917602539, train_acc: 89.41, train_fscore: 89.33, valid_loss: 6.747200012207031, valid_acc: 72.74, valid_fscore: 73.57, test_loss: 7.7266998291015625, test_acc: 70.12, test_fscore: 70.52, time: 2.38 sec
epoch: 98, train_loss: 6.500100135803223, train_acc: 89.37, train_fscore: 89.32, valid_loss: 6.729499816894531, valid_acc: 74.1, valid_fscore: 74.59, test_loss: 7.613100051879883, test_acc: 71.23, test_fscore: 71.63, time: 3.7 sec
epoch: 99, train_loss: 6.507500171661377, train_acc: 89.35, train_fscore: 89.28, valid_loss: 6.735499858856201, valid_acc: 73.95, valid_fscore: 74.13, test_loss: 7.598499774932861, test_acc: 71.04, test_fscore: 71.39, time: 3.21 sec
epoch: 100, train_loss: 6.493599891662598, train_acc: 89.74, train_fscore: 89.67, valid_loss: 6.7154998779296875, valid_acc: 73.8, valid_fscore: 74.46, test_loss: 7.728099822998047, test_acc: 69.99, test_fscore: 70.35, time: 3.76 sec
              precision    recall  f1-score   support

           0     0.4664    0.8194    0.5945     144.0
           1     0.8000    0.8000    0.8000     245.0
           2     0.7169    0.7057    0.7113     384.0
           3     0.6740    0.7176    0.6952     170.0
           4     0.9048    0.5719    0.7008     299.0
           5     0.6844    0.6772    0.6807     381.0

    accuracy                         0.6999    1623.0
   macro avg     0.7077    0.7153    0.6971    1623.0
weighted avg     0.7297    0.6999    0.7035    1623.0

[[118.   6.  11.   0.   8.   1.]
 [  2. 196.  16.   3.   0.  28.]
 [ 34.  25. 271.   6.   4.  44.]
 [  0.   1.   4. 122.   0.  43.]
 [ 99.   2.  24.   0. 171.   3.]
 [  0.  15.  52.  50.   6. 258.]]
epoch: 101, train_loss: 6.469099998474121, train_acc: 90.09, train_fscore: 90.02, valid_loss: 6.6880998611450195, valid_acc: 74.55, valid_fscore: 74.72, test_loss: 7.7032999992370605, test_acc: 70.92, test_fscore: 71.21, time: 2.99 sec
epoch: 102, train_loss: 6.480000019073486, train_acc: 90.21, train_fscore: 90.15, valid_loss: 6.715199947357178, valid_acc: 73.64, valid_fscore: 74.26, test_loss: 7.664400100708008, test_acc: 70.98, test_fscore: 71.42, time: 3.4 sec
epoch: 103, train_loss: 6.446899890899658, train_acc: 90.32, train_fscore: 90.26, valid_loss: 6.7769999504089355, valid_acc: 73.95, valid_fscore: 74.62, test_loss: 7.70419979095459, test_acc: 70.73, test_fscore: 71.18, time: 2.72 sec
epoch: 104, train_loss: 6.457099914550781, train_acc: 90.48, train_fscore: 90.42, valid_loss: 6.71120023727417, valid_acc: 75.0, valid_fscore: 74.99, test_loss: 7.662799835205078, test_acc: 71.6, test_fscore: 71.84, time: 2.97 sec
epoch: 105, train_loss: 6.444699764251709, train_acc: 90.5, train_fscore: 90.43, valid_loss: 6.68720006942749, valid_acc: 73.95, valid_fscore: 74.29, test_loss: 7.741300106048584, test_acc: 70.86, test_fscore: 71.19, time: 3.02 sec
epoch: 106, train_loss: 6.4394001960754395, train_acc: 90.63, train_fscore: 90.59, valid_loss: 6.717800140380859, valid_acc: 73.8, valid_fscore: 74.38, test_loss: 7.77400016784668, test_acc: 69.81, test_fscore: 70.25, time: 2.41 sec
epoch: 107, train_loss: 6.397500038146973, train_acc: 90.54, train_fscore: 90.47, valid_loss: 6.755799770355225, valid_acc: 75.15, valid_fscore: 75.05, test_loss: 7.6717000007629395, test_acc: 71.47, test_fscore: 71.8, time: 2.49 sec
epoch: 108, train_loss: 6.421599864959717, train_acc: 90.94, train_fscore: 90.88, valid_loss: 6.787499904632568, valid_acc: 74.55, valid_fscore: 74.7, test_loss: 7.662799835205078, test_acc: 71.6, test_fscore: 71.87, time: 3.17 sec
epoch: 109, train_loss: 6.412700176239014, train_acc: 90.73, train_fscore: 90.67, valid_loss: 6.801599979400635, valid_acc: 73.04, valid_fscore: 73.73, test_loss: 7.782800197601318, test_acc: 69.75, test_fscore: 70.2, time: 2.9 sec
epoch: 110, train_loss: 6.396500110626221, train_acc: 90.58, train_fscore: 90.53, valid_loss: 6.811500072479248, valid_acc: 73.49, valid_fscore: 73.96, test_loss: 7.753799915313721, test_acc: 71.04, test_fscore: 71.43, time: 2.75 sec
              precision    recall  f1-score   support

           0     0.5139    0.7708    0.6167     144.0
           1     0.8274    0.7633    0.7941     245.0
           2     0.7231    0.7005    0.7116     384.0
           3     0.6632    0.7412    0.7000     170.0
           4     0.8844    0.6656    0.7595     299.0
           5     0.6624    0.6850    0.6735     381.0

    accuracy                         0.7104    1623.0
   macro avg     0.7124    0.7211    0.7092    1623.0
weighted avg     0.7295    0.7104    0.7143    1623.0

[[111.   5.  11.   0.  16.   1.]
 [  2. 187.  21.   3.   0.  32.]
 [ 31.  18. 269.   6.   4.  56.]
 [  0.   1.   2. 126.   0.  41.]
 [ 72.   2.  23.   0. 199.   3.]
 [  0.  13.  46.  55.   6. 261.]]
epoch: 111, train_loss: 6.386199951171875, train_acc: 91.24, train_fscore: 91.17, valid_loss: 6.878900051116943, valid_acc: 73.8, valid_fscore: 74.08, test_loss: 7.7104997634887695, test_acc: 71.78, test_fscore: 72.09, time: 3.19 sec
epoch: 112, train_loss: 6.3815999031066895, train_acc: 91.24, train_fscore: 91.18, valid_loss: 6.849299907684326, valid_acc: 73.95, valid_fscore: 74.34, test_loss: 7.680300235748291, test_acc: 70.86, test_fscore: 71.19, time: 3.0 sec
epoch: 113, train_loss: 6.356599807739258, train_acc: 90.85, train_fscore: 90.78, valid_loss: 6.81689977645874, valid_acc: 74.55, valid_fscore: 74.86, test_loss: 7.698800086975098, test_acc: 70.67, test_fscore: 71.02, time: 2.98 sec
epoch: 114, train_loss: 6.353899955749512, train_acc: 90.96, train_fscore: 90.89, valid_loss: 6.793900012969971, valid_acc: 74.4, valid_fscore: 74.9, test_loss: 7.7378997802734375, test_acc: 71.29, test_fscore: 71.66, time: 2.98 sec
epoch: 115, train_loss: 6.349599838256836, train_acc: 91.55, train_fscore: 91.49, valid_loss: 6.8520002365112305, valid_acc: 74.25, valid_fscore: 74.59, test_loss: 7.752799987792969, test_acc: 71.29, test_fscore: 71.62, time: 3.02 sec
epoch: 116, train_loss: 6.32450008392334, train_acc: 91.57, train_fscore: 91.51, valid_loss: 6.873199939727783, valid_acc: 74.4, valid_fscore: 74.65, test_loss: 7.707499980926514, test_acc: 71.35, test_fscore: 71.68, time: 3.05 sec
epoch: 117, train_loss: 6.311399936676025, train_acc: 91.72, train_fscore: 91.67, valid_loss: 6.886000156402588, valid_acc: 74.55, valid_fscore: 74.92, test_loss: 7.7332000732421875, test_acc: 71.29, test_fscore: 71.64, time: 3.0 sec
epoch: 118, train_loss: 6.304699897766113, train_acc: 91.92, train_fscore: 91.86, valid_loss: 6.89109992980957, valid_acc: 75.0, valid_fscore: 75.28, test_loss: 7.732999801635742, test_acc: 71.66, test_fscore: 71.97, time: 3.05 sec
epoch: 119, train_loss: 6.310100078582764, train_acc: 91.61, train_fscore: 91.54, valid_loss: 6.888599872589111, valid_acc: 74.7, valid_fscore: 74.87, test_loss: 7.792600154876709, test_acc: 71.72, test_fscore: 72.04, time: 2.94 sec
epoch: 120, train_loss: 6.293300151824951, train_acc: 92.3, train_fscore: 92.27, valid_loss: 6.857600212097168, valid_acc: 75.15, valid_fscore: 75.32, test_loss: 7.768099784851074, test_acc: 70.79, test_fscore: 71.13, time: 3.14 sec
              precision    recall  f1-score   support

           0     0.5146    0.7361    0.6057     144.0
           1     0.8136    0.7837    0.7983     245.0
           2     0.7069    0.7161    0.7115     384.0
           3     0.6400    0.7529    0.6919     170.0
           4     0.8855    0.6722    0.7643     299.0
           5     0.6767    0.6483    0.6622     381.0

    accuracy                         0.7079    1623.0
   macro avg     0.7062    0.7182    0.7057    1623.0
weighted avg     0.7247    0.7079    0.7113    1623.0

[[106.   5.  15.   0.  17.   1.]
 [  2. 192.  19.   3.   0.  29.]
 [ 30.  18. 275.   8.   4.  49.]
 [  0.   1.   4. 128.   0.  37.]
 [ 68.   2.  26.   0. 201.   2.]
 [  0.  18.  50.  61.   5. 247.]]
epoch: 121, train_loss: 6.284999847412109, train_acc: 92.03, train_fscore: 91.97, valid_loss: 6.917900085449219, valid_acc: 73.64, valid_fscore: 73.9, test_loss: 7.7291998863220215, test_acc: 71.6, test_fscore: 71.94, time: 2.93 sec
epoch: 122, train_loss: 6.274400234222412, train_acc: 92.19, train_fscore: 92.14, valid_loss: 6.919600009918213, valid_acc: 74.25, valid_fscore: 74.49, test_loss: 7.7606000900268555, test_acc: 71.6, test_fscore: 71.94, time: 3.02 sec
epoch: 123, train_loss: 6.276800155639648, train_acc: 92.4, train_fscore: 92.35, valid_loss: 6.927299976348877, valid_acc: 73.64, valid_fscore: 73.81, test_loss: 7.807700157165527, test_acc: 70.86, test_fscore: 71.21, time: 3.05 sec
epoch: 124, train_loss: 6.281599998474121, train_acc: 92.21, train_fscore: 92.16, valid_loss: 6.929999828338623, valid_acc: 73.95, valid_fscore: 74.01, test_loss: 7.7729997634887695, test_acc: 71.47, test_fscore: 71.82, time: 2.9 sec
epoch: 125, train_loss: 6.2778000831604, train_acc: 91.78, train_fscore: 91.73, valid_loss: 6.882999897003174, valid_acc: 74.55, valid_fscore: 74.7, test_loss: 7.759699821472168, test_acc: 71.29, test_fscore: 71.57, time: 4.06 sec
epoch: 126, train_loss: 6.255000114440918, train_acc: 91.94, train_fscore: 91.87, valid_loss: 6.959000110626221, valid_acc: 74.55, valid_fscore: 74.82, test_loss: 7.802599906921387, test_acc: 71.1, test_fscore: 71.48, time: 2.87 sec
epoch: 127, train_loss: 6.235899925231934, train_acc: 92.71, train_fscore: 92.68, valid_loss: 6.954899787902832, valid_acc: 74.7, valid_fscore: 74.61, test_loss: 7.815400123596191, test_acc: 70.92, test_fscore: 71.26, time: 2.03 sec
epoch: 128, train_loss: 6.243000030517578, train_acc: 92.67, train_fscore: 92.62, valid_loss: 6.907599925994873, valid_acc: 74.4, valid_fscore: 74.55, test_loss: 7.846399784088135, test_acc: 71.41, test_fscore: 71.73, time: 3.02 sec
epoch: 129, train_loss: 6.225900173187256, train_acc: 92.83, train_fscore: 92.78, valid_loss: 6.961699962615967, valid_acc: 73.49, valid_fscore: 73.87, test_loss: 7.890399932861328, test_acc: 71.1, test_fscore: 71.42, time: 3.15 sec
epoch: 130, train_loss: 6.226200103759766, train_acc: 92.81, train_fscore: 92.76, valid_loss: 7.000999927520752, valid_acc: 74.7, valid_fscore: 74.89, test_loss: 7.836599826812744, test_acc: 71.47, test_fscore: 71.8, time: 3.26 sec
              precision    recall  f1-score   support

           0     0.5309    0.7153    0.6095     144.0
           1     0.8384    0.7837    0.8101     245.0
           2     0.7124    0.7161    0.7143     384.0
           3     0.6649    0.7353    0.6983     170.0
           4     0.8631    0.6957    0.7704     299.0
           5     0.6675    0.6745    0.6710     381.0

    accuracy                         0.7147    1623.0
   macro avg     0.7129    0.7201    0.7123    1623.0
weighted avg     0.7276    0.7147    0.7180    1623.0

[[103.   5.  13.   0.  22.   1.]
 [  2. 192.  18.   3.   0.  30.]
 [ 27.  18. 275.   5.   5.  54.]
 [  0.   1.   4. 125.   0.  40.]
 [ 62.   1.  25.   0. 208.   3.]
 [  0.  12.  51.  55.   6. 257.]]
epoch: 131, train_loss: 6.220099925994873, train_acc: 92.95, train_fscore: 92.92, valid_loss: 6.893799781799316, valid_acc: 75.45, valid_fscore: 75.67, test_loss: 7.818600177764893, test_acc: 71.72, test_fscore: 72.01, time: 3.08 sec
epoch: 132, train_loss: 6.215700149536133, train_acc: 92.64, train_fscore: 92.58, valid_loss: 6.876699924468994, valid_acc: 74.55, valid_fscore: 74.94, test_loss: 7.8582000732421875, test_acc: 70.67, test_fscore: 70.92, time: 2.8 sec
epoch: 133, train_loss: 6.19980001449585, train_acc: 92.77, train_fscore: 92.71, valid_loss: 6.9816999435424805, valid_acc: 74.25, valid_fscore: 74.4, test_loss: 7.8140997886657715, test_acc: 71.04, test_fscore: 71.39, time: 3.04 sec
epoch: 134, train_loss: 6.196499824523926, train_acc: 93.61, train_fscore: 93.58, valid_loss: 6.973700046539307, valid_acc: 75.3, valid_fscore: 75.42, test_loss: 7.806600093841553, test_acc: 71.72, test_fscore: 71.98, time: 2.97 sec
epoch: 135, train_loss: 6.17710018157959, train_acc: 93.26, train_fscore: 93.22, valid_loss: 6.946400165557861, valid_acc: 74.1, valid_fscore: 74.27, test_loss: 7.8308000564575195, test_acc: 71.41, test_fscore: 71.68, time: 3.06 sec
epoch: 136, train_loss: 6.203199863433838, train_acc: 93.12, train_fscore: 93.08, valid_loss: 6.975100040435791, valid_acc: 74.7, valid_fscore: 74.71, test_loss: 7.85890007019043, test_acc: 70.98, test_fscore: 71.31, time: 3.0 sec
epoch: 137, train_loss: 6.174699783325195, train_acc: 93.45, train_fscore: 93.42, valid_loss: 6.9629998207092285, valid_acc: 74.7, valid_fscore: 74.6, test_loss: 7.833000183105469, test_acc: 70.43, test_fscore: 70.69, time: 3.01 sec
epoch: 138, train_loss: 6.159599781036377, train_acc: 93.43, train_fscore: 93.39, valid_loss: 6.937900066375732, valid_acc: 73.95, valid_fscore: 74.16, test_loss: 7.886600017547607, test_acc: 71.6, test_fscore: 71.88, time: 3.96 sec
epoch: 139, train_loss: 6.158100128173828, train_acc: 93.35, train_fscore: 93.32, valid_loss: 6.99560022354126, valid_acc: 74.55, valid_fscore: 74.51, test_loss: 7.887599945068359, test_acc: 71.41, test_fscore: 71.67, time: 2.86 sec
epoch: 140, train_loss: 6.13730001449585, train_acc: 93.86, train_fscore: 93.82, valid_loss: 7.039100170135498, valid_acc: 74.4, valid_fscore: 74.41, test_loss: 7.895500183105469, test_acc: 71.16, test_fscore: 71.52, time: 3.04 sec
              precision    recall  f1-score   support

           0     0.5253    0.7222    0.6082     144.0
           1     0.8447    0.7551    0.7974     245.0
           2     0.6967    0.7240    0.7101     384.0
           3     0.6632    0.7412    0.7000     170.0
           4     0.8672    0.6990    0.7741     299.0
           5     0.6729    0.6640    0.6684     381.0

    accuracy                         0.7116    1623.0
   macro avg     0.7117    0.7176    0.7097    1623.0
weighted avg     0.7262    0.7116    0.7152    1623.0

[[104.   5.  13.   0.  21.   1.]
 [  2. 185.  24.   3.   0.  31.]
 [ 31.  15. 278.   5.   5.  50.]
 [  0.   1.   4. 126.   0.  39.]
 [ 61.   1.  26.   0. 209.   2.]
 [  0.  12.  54.  56.   6. 253.]]
epoch: 141, train_loss: 6.1392998695373535, train_acc: 94.07, train_fscore: 94.05, valid_loss: 7.008900165557861, valid_acc: 73.64, valid_fscore: 73.98, test_loss: 7.956299781799316, test_acc: 70.24, test_fscore: 70.65, time: 2.14 sec
epoch: 142, train_loss: 6.127500057220459, train_acc: 94.05, train_fscore: 94.03, valid_loss: 6.934100151062012, valid_acc: 74.7, valid_fscore: 74.67, test_loss: 7.924600124359131, test_acc: 70.36, test_fscore: 70.55, time: 2.94 sec
epoch: 143, train_loss: 6.111599922180176, train_acc: 93.94, train_fscore: 93.89, valid_loss: 6.993500232696533, valid_acc: 73.8, valid_fscore: 73.76, test_loss: 7.860000133514404, test_acc: 71.66, test_fscore: 71.92, time: 2.88 sec
epoch: 144, train_loss: 6.136499881744385, train_acc: 93.9, train_fscore: 93.87, valid_loss: 7.082600116729736, valid_acc: 74.1, valid_fscore: 74.22, test_loss: 7.904600143432617, test_acc: 71.53, test_fscore: 71.84, time: 3.24 sec
epoch: 145, train_loss: 6.120100021362305, train_acc: 93.76, train_fscore: 93.73, valid_loss: 7.011199951171875, valid_acc: 74.1, valid_fscore: 74.41, test_loss: 7.963500022888184, test_acc: 70.3, test_fscore: 70.61, time: 2.82 sec
epoch: 146, train_loss: 6.0995001792907715, train_acc: 94.01, train_fscore: 93.98, valid_loss: 7.019800186157227, valid_acc: 74.25, valid_fscore: 74.24, test_loss: 7.94950008392334, test_acc: 70.49, test_fscore: 70.79, time: 2.87 sec
epoch: 147, train_loss: 6.120100021362305, train_acc: 93.84, train_fscore: 93.8, valid_loss: 7.054500102996826, valid_acc: 74.4, valid_fscore: 74.26, test_loss: 7.88040018081665, test_acc: 70.67, test_fscore: 70.87, time: 2.99 sec
epoch: 148, train_loss: 6.098800182342529, train_acc: 93.94, train_fscore: 93.89, valid_loss: 7.127799987792969, valid_acc: 74.25, valid_fscore: 74.46, test_loss: 7.926199913024902, test_acc: 71.23, test_fscore: 71.55, time: 2.97 sec
epoch: 149, train_loss: 6.079100131988525, train_acc: 94.52, train_fscore: 94.5, valid_loss: 7.115699768066406, valid_acc: 73.64, valid_fscore: 73.86, test_loss: 7.923299789428711, test_acc: 71.16, test_fscore: 71.47, time: 3.02 sec
epoch: 150, train_loss: 6.094900131225586, train_acc: 94.21, train_fscore: 94.17, valid_loss: 7.053100109100342, valid_acc: 74.4, valid_fscore: 74.32, test_loss: 7.935699939727783, test_acc: 70.98, test_fscore: 71.24, time: 3.02 sec
              precision    recall  f1-score   support

           0     0.5291    0.6944    0.6006     144.0
           1     0.8190    0.7755    0.7966     245.0
           2     0.6930    0.7526    0.7216     384.0
           3     0.6614    0.7353    0.6964     170.0
           4     0.8670    0.6756    0.7594     299.0
           5     0.6777    0.6457    0.6613     381.0

    accuracy                         0.7098    1623.0
   macro avg     0.7079    0.7132    0.7060    1623.0
weighted avg     0.7226    0.7098    0.7124    1623.0

[[100.   5.  18.   0.  20.   1.]
 [  2. 190.  22.   3.   0.  28.]
 [ 24.  17. 289.   4.   5.  45.]
 [  0.   1.   5. 125.   0.  39.]
 [ 63.   2.  28.   0. 202.   4.]
 [  0.  17.  55.  57.   6. 246.]]
Best validation F-Score: 71.24
Test performance..
F-Score: 71.24
Accuracy: 70.98
Loss: 7.935699939727783
--- 3 ---
loss_mask: [True, True, True, True]
Namespace(no_cuda=False, lr=0.0001, l2=1e-05, dropout=0.5, batch_size=64, hidden_dim=1024, n_head=8, epochs=150, temp=2, tensorboard=False, class_weight=True, Dataset='IEMOCAP', loss_mask='1111')
Running on GPU
temp 2
total parameters: 97535000
training parameters: 97535000
epoch: 1, train_loss: 12.263999938964844, train_acc: 24.21, train_fscore: 23.46, valid_loss: 10.132599830627441, valid_acc: 36.75, valid_fscore: 31.47, test_loss: 11.102700233459473, test_acc: 30.19, test_fscore: 26.64, time: 4.7 sec
epoch: 2, train_loss: 11.530900001525879, train_acc: 38.32, train_fscore: 34.94, valid_loss: 9.529999732971191, valid_acc: 41.87, valid_fscore: 41.32, test_loss: 10.567000389099121, test_acc: 43.75, test_fscore: 41.65, time: 2.99 sec
epoch: 3, train_loss: 11.022700309753418, train_acc: 49.63, train_fscore: 47.42, valid_loss: 9.074199676513672, valid_acc: 55.12, valid_fscore: 54.53, test_loss: 10.272899627685547, test_acc: 47.94, test_fscore: 46.47, time: 2.99 sec
epoch: 4, train_loss: 10.618499755859375, train_acc: 52.66, train_fscore: 49.77, valid_loss: 8.8233003616333, valid_acc: 58.28, valid_fscore: 58.74, test_loss: 10.094599723815918, test_acc: 47.94, test_fscore: 47.59, time: 2.99 sec
epoch: 5, train_loss: 10.326899528503418, train_acc: 57.21, train_fscore: 55.72, valid_loss: 8.666000366210938, valid_acc: 62.95, valid_fscore: 64.15, test_loss: 9.872900009155273, test_acc: 57.3, test_fscore: 57.56, time: 2.91 sec
epoch: 6, train_loss: 10.06760025024414, train_acc: 62.28, train_fscore: 61.82, valid_loss: 8.49590015411377, valid_acc: 61.14, valid_fscore: 63.3, test_loss: 9.63070011138916, test_acc: 57.49, test_fscore: 58.4, time: 3.92 sec
epoch: 7, train_loss: 9.743499755859375, train_acc: 63.08, train_fscore: 63.11, valid_loss: 8.177399635314941, valid_acc: 59.34, valid_fscore: 62.05, test_loss: 9.322999954223633, test_acc: 55.82, test_fscore: 56.32, time: 3.1 sec
epoch: 8, train_loss: 9.386799812316895, train_acc: 63.8, train_fscore: 63.54, valid_loss: 7.756499767303467, valid_acc: 64.91, valid_fscore: 66.38, test_loss: 8.975000381469727, test_acc: 60.2, test_fscore: 60.81, time: 3.0 sec
epoch: 9, train_loss: 9.121899604797363, train_acc: 66.83, train_fscore: 66.57, valid_loss: 7.452300071716309, valid_acc: 65.96, valid_fscore: 67.18, test_loss: 8.72350025177002, test_acc: 62.35, test_fscore: 63.14, time: 2.69 sec
epoch: 10, train_loss: 8.935099601745605, train_acc: 67.66, train_fscore: 67.29, valid_loss: 7.371600151062012, valid_acc: 67.47, valid_fscore: 68.58, test_loss: 8.668600082397461, test_acc: 62.6, test_fscore: 63.48, time: 3.47 sec
              precision    recall  f1-score   support

           0     0.3383    0.6250    0.4390     144.0
           1     0.7938    0.6286    0.7016     245.0
           2     0.6344    0.5286    0.5767     384.0
           3     0.5913    0.7235    0.6508     170.0
           4     0.8228    0.6522    0.7276     299.0
           5     0.6307    0.6588    0.6444     381.0

    accuracy                         0.6260    1623.0
   macro avg     0.6352    0.6361    0.6234    1623.0
weighted avg     0.6615    0.6260    0.6348    1623.0

[[ 90.   5.  10.   2.  35.   2.]
 [ 16. 154.  40.   2.   0.  33.]
 [ 63.  24. 203.  22.   3.  69.]
 [  0.   0.   6. 123.   0.  41.]
 [ 89.   0.  12.   1. 195.   2.]
 [  8.  11.  49.  58.   4. 251.]]
epoch: 11, train_loss: 8.829500198364258, train_acc: 68.56, train_fscore: 68.39, valid_loss: 7.321100234985352, valid_acc: 66.42, valid_fscore: 68.3, test_loss: 8.580400466918945, test_acc: 63.15, test_fscore: 64.33, time: 2.39 sec
epoch: 12, train_loss: 8.761099815368652, train_acc: 68.64, train_fscore: 68.61, valid_loss: 7.1483001708984375, valid_acc: 68.07, valid_fscore: 69.28, test_loss: 8.449299812316895, test_acc: 63.09, test_fscore: 64.12, time: 3.9 sec
epoch: 13, train_loss: 8.643500328063965, train_acc: 68.99, train_fscore: 68.78, valid_loss: 6.961599826812744, valid_acc: 67.77, valid_fscore: 69.43, test_loss: 8.298399925231934, test_acc: 62.29, test_fscore: 63.3, time: 3.29 sec
epoch: 14, train_loss: 8.526399612426758, train_acc: 69.72, train_fscore: 69.39, valid_loss: 6.85890007019043, valid_acc: 68.83, valid_fscore: 69.82, test_loss: 8.181900024414062, test_acc: 63.15, test_fscore: 63.92, time: 2.64 sec
epoch: 15, train_loss: 8.458999633789062, train_acc: 69.2, train_fscore: 68.46, valid_loss: 6.838799953460693, valid_acc: 70.78, valid_fscore: 71.89, test_loss: 8.129199981689453, test_acc: 65.06, test_fscore: 65.7, time: 2.9 sec
epoch: 16, train_loss: 8.375499725341797, train_acc: 70.17, train_fscore: 69.5, valid_loss: 6.847599983215332, valid_acc: 68.22, valid_fscore: 70.11, test_loss: 8.139699935913086, test_acc: 64.02, test_fscore: 64.83, time: 2.92 sec
epoch: 17, train_loss: 8.32509994506836, train_acc: 71.38, train_fscore: 71.13, valid_loss: 6.861199855804443, valid_acc: 68.83, valid_fscore: 70.21, test_loss: 8.168399810791016, test_acc: 64.39, test_fscore: 65.13, time: 2.92 sec
epoch: 18, train_loss: 8.279000282287598, train_acc: 71.18, train_fscore: 70.84, valid_loss: 6.7906999588012695, valid_acc: 68.83, valid_fscore: 70.32, test_loss: 8.157899856567383, test_acc: 64.2, test_fscore: 64.95, time: 3.82 sec
epoch: 19, train_loss: 8.180700302124023, train_acc: 71.88, train_fscore: 71.46, valid_loss: 6.6768999099731445, valid_acc: 69.43, valid_fscore: 70.43, test_loss: 8.058899879455566, test_acc: 65.56, test_fscore: 66.26, time: 2.98 sec
epoch: 20, train_loss: 8.137200355529785, train_acc: 72.39, train_fscore: 72.1, valid_loss: 6.664100170135498, valid_acc: 69.28, valid_fscore: 69.97, test_loss: 8.018899917602539, test_acc: 66.42, test_fscore: 67.1, time: 2.78 sec
              precision    recall  f1-score   support

           0     0.4069    0.6528    0.5013     144.0
           1     0.7905    0.6776    0.7297     245.0
           2     0.6510    0.6510    0.6510     384.0
           3     0.6078    0.7294    0.6631     170.0
           4     0.8571    0.6823    0.7598     299.0
           5     0.6742    0.6299    0.6513     381.0

    accuracy                         0.6642    1623.0
   macro avg     0.6646    0.6705    0.6594    1623.0
weighted avg     0.6893    0.6642    0.6710    1623.0

[[ 94.   6.  13.   3.  26.   2.]
 [  6. 166.  42.   1.   0.  30.]
 [ 51.  21. 250.  16.   4.  42.]
 [  0.   0.   5. 124.   0.  41.]
 [ 78.   0.  16.   0. 204.   1.]
 [  2.  17.  58.  60.   4. 240.]]
epoch: 21, train_loss: 8.10200023651123, train_acc: 73.8, train_fscore: 73.55, valid_loss: 6.65310001373291, valid_acc: 70.63, valid_fscore: 71.46, test_loss: 7.980000019073486, test_acc: 66.73, test_fscore: 67.37, time: 3.27 sec
epoch: 22, train_loss: 8.018600463867188, train_acc: 73.44, train_fscore: 73.14, valid_loss: 6.641200065612793, valid_acc: 70.63, valid_fscore: 71.47, test_loss: 7.947199821472168, test_acc: 66.79, test_fscore: 67.4, time: 4.5 sec
epoch: 23, train_loss: 7.999199867248535, train_acc: 74.6, train_fscore: 74.38, valid_loss: 6.669099807739258, valid_acc: 67.17, valid_fscore: 69.28, test_loss: 7.983099937438965, test_acc: 64.45, test_fscore: 65.35, time: 2.17 sec
epoch: 24, train_loss: 7.938199996948242, train_acc: 74.39, train_fscore: 74.2, valid_loss: 6.606299877166748, valid_acc: 70.78, valid_fscore: 72.05, test_loss: 7.957900047302246, test_acc: 66.67, test_fscore: 67.42, time: 2.88 sec
epoch: 25, train_loss: 7.897799968719482, train_acc: 75.17, train_fscore: 74.93, valid_loss: 6.571700096130371, valid_acc: 71.69, valid_fscore: 72.62, test_loss: 7.916600227355957, test_acc: 67.22, test_fscore: 67.8, time: 2.21 sec
epoch: 26, train_loss: 7.828499794006348, train_acc: 74.85, train_fscore: 74.55, valid_loss: 6.568999767303467, valid_acc: 71.84, valid_fscore: 72.97, test_loss: 7.852399826049805, test_acc: 67.34, test_fscore: 67.97, time: 2.74 sec
epoch: 27, train_loss: 7.784299850463867, train_acc: 75.38, train_fscore: 75.1, valid_loss: 6.576900005340576, valid_acc: 71.54, valid_fscore: 72.55, test_loss: 7.823400020599365, test_acc: 67.59, test_fscore: 68.19, time: 2.85 sec
epoch: 28, train_loss: 7.757599830627441, train_acc: 75.01, train_fscore: 74.78, valid_loss: 6.545199871063232, valid_acc: 72.74, valid_fscore: 73.68, test_loss: 7.813399791717529, test_acc: 67.47, test_fscore: 68.09, time: 2.93 sec
epoch: 29, train_loss: 7.713099956512451, train_acc: 76.39, train_fscore: 76.15, valid_loss: 6.5472002029418945, valid_acc: 70.63, valid_fscore: 71.58, test_loss: 7.758699893951416, test_acc: 67.84, test_fscore: 68.43, time: 2.91 sec
epoch: 30, train_loss: 7.690800189971924, train_acc: 76.53, train_fscore: 76.3, valid_loss: 6.503600120544434, valid_acc: 70.78, valid_fscore: 71.85, test_loss: 7.727700233459473, test_acc: 67.22, test_fscore: 67.84, time: 2.89 sec
              precision    recall  f1-score   support

           0     0.4267    0.6875    0.5266     144.0
           1     0.7826    0.7347    0.7579     245.0
           2     0.6813    0.6458    0.6631     384.0
           3     0.6019    0.7294    0.6596     170.0
           4     0.8761    0.6622    0.7543     299.0
           5     0.6630    0.6352    0.6488     381.0

    accuracy                         0.6722    1623.0
   macro avg     0.6720    0.6825    0.6684    1623.0
weighted avg     0.6973    0.6722    0.6784    1623.0

[[ 99.   7.  13.   3.  19.   3.]
 [  3. 180.  29.   1.   0.  32.]
 [ 43.  25. 248.  20.   4.  44.]
 [  0.   0.   3. 124.   0.  43.]
 [ 87.   0.  13.   0. 198.   1.]
 [  0.  18.  58.  58.   5. 242.]]
epoch: 31, train_loss: 7.664700031280518, train_acc: 76.95, train_fscore: 76.73, valid_loss: 6.512899875640869, valid_acc: 71.54, valid_fscore: 72.73, test_loss: 7.782100200653076, test_acc: 67.04, test_fscore: 67.71, time: 3.81 sec
epoch: 32, train_loss: 7.61269998550415, train_acc: 77.3, train_fscore: 77.2, valid_loss: 6.540599822998047, valid_acc: 71.39, valid_fscore: 72.52, test_loss: 7.768799781799316, test_acc: 67.1, test_fscore: 67.79, time: 2.97 sec
epoch: 33, train_loss: 7.588500022888184, train_acc: 77.73, train_fscore: 77.59, valid_loss: 6.501299858093262, valid_acc: 72.14, valid_fscore: 73.12, test_loss: 7.697000026702881, test_acc: 67.34, test_fscore: 67.95, time: 3.18 sec
epoch: 34, train_loss: 7.564000129699707, train_acc: 77.42, train_fscore: 77.21, valid_loss: 6.485799789428711, valid_acc: 70.48, valid_fscore: 71.61, test_loss: 7.651700019836426, test_acc: 67.84, test_fscore: 68.44, time: 2.6 sec
epoch: 35, train_loss: 7.545599937438965, train_acc: 77.96, train_fscore: 77.78, valid_loss: 6.476900100708008, valid_acc: 71.54, valid_fscore: 72.65, test_loss: 7.673099994659424, test_acc: 67.59, test_fscore: 68.27, time: 3.78 sec
epoch: 36, train_loss: 7.462100028991699, train_acc: 78.76, train_fscore: 78.63, valid_loss: 6.49970006942749, valid_acc: 71.69, valid_fscore: 72.71, test_loss: 7.70419979095459, test_acc: 67.41, test_fscore: 68.07, time: 3.03 sec
epoch: 37, train_loss: 7.468200206756592, train_acc: 78.92, train_fscore: 78.77, valid_loss: 6.477700233459473, valid_acc: 72.29, valid_fscore: 73.56, test_loss: 7.716800212860107, test_acc: 67.41, test_fscore: 68.08, time: 2.89 sec
epoch: 38, train_loss: 7.439000129699707, train_acc: 78.7, train_fscore: 78.62, valid_loss: 6.470900058746338, valid_acc: 72.44, valid_fscore: 73.53, test_loss: 7.684999942779541, test_acc: 67.16, test_fscore: 67.83, time: 2.96 sec
epoch: 39, train_loss: 7.408100128173828, train_acc: 78.88, train_fscore: 78.72, valid_loss: 6.441400051116943, valid_acc: 72.44, valid_fscore: 73.24, test_loss: 7.587500095367432, test_acc: 67.78, test_fscore: 68.35, time: 2.92 sec
epoch: 40, train_loss: 7.369100093841553, train_acc: 79.21, train_fscore: 78.99, valid_loss: 6.458799839019775, valid_acc: 72.29, valid_fscore: 73.46, test_loss: 7.625199794769287, test_acc: 66.97, test_fscore: 67.69, time: 2.98 sec
              precision    recall  f1-score   support

           0     0.4093    0.7361    0.5261     144.0
           1     0.7991    0.7306    0.7633     245.0
           2     0.7055    0.6302    0.6657     384.0
           3     0.6283    0.7059    0.6648     170.0
           4     0.8911    0.6020    0.7186     299.0
           5     0.6436    0.6824    0.6624     381.0

    accuracy                         0.6697    1623.0
   macro avg     0.6795    0.6812    0.6668    1623.0
weighted avg     0.7049    0.6697    0.6769    1623.0

[[106.   7.  15.   0.  12.   4.]
 [  3. 179.  25.   2.   0.  36.]
 [ 45.  23. 242.  14.   4.  56.]
 [  0.   0.   3. 120.   0.  47.]
 [105.   0.  13.   0. 180.   1.]
 [  0.  15.  45.  55.   6. 260.]]
epoch: 41, train_loss: 7.367700099945068, train_acc: 79.65, train_fscore: 79.58, valid_loss: 6.4944000244140625, valid_acc: 72.44, valid_fscore: 73.5, test_loss: 7.67579984664917, test_acc: 67.71, test_fscore: 68.39, time: 3.73 sec
epoch: 42, train_loss: 7.32859992980957, train_acc: 80.16, train_fscore: 80.05, valid_loss: 6.450500011444092, valid_acc: 71.69, valid_fscore: 72.56, test_loss: 7.6194000244140625, test_acc: 68.02, test_fscore: 68.6, time: 2.98 sec
epoch: 43, train_loss: 7.292600154876709, train_acc: 79.89, train_fscore: 79.71, valid_loss: 6.440999984741211, valid_acc: 72.44, valid_fscore: 73.4, test_loss: 7.612599849700928, test_acc: 67.78, test_fscore: 68.39, time: 2.88 sec
epoch: 44, train_loss: 7.270199775695801, train_acc: 80.45, train_fscore: 80.33, valid_loss: 6.439300060272217, valid_acc: 72.59, valid_fscore: 73.53, test_loss: 7.583099842071533, test_acc: 67.9, test_fscore: 68.54, time: 3.95 sec
epoch: 45, train_loss: 7.257500171661377, train_acc: 80.9, train_fscore: 80.72, valid_loss: 6.4375, valid_acc: 73.04, valid_fscore: 73.87, test_loss: 7.566500186920166, test_acc: 67.96, test_fscore: 68.6, time: 4.24 sec
epoch: 46, train_loss: 7.238100051879883, train_acc: 81.23, train_fscore: 81.1, valid_loss: 6.434000015258789, valid_acc: 73.19, valid_fscore: 74.1, test_loss: 7.604400157928467, test_acc: 67.34, test_fscore: 68.0, time: 3.29 sec
epoch: 47, train_loss: 7.203700065612793, train_acc: 80.99, train_fscore: 80.86, valid_loss: 6.456999778747559, valid_acc: 72.89, valid_fscore: 73.68, test_loss: 7.585299968719482, test_acc: 68.76, test_fscore: 69.39, time: 3.17 sec
epoch: 48, train_loss: 7.222499847412109, train_acc: 81.36, train_fscore: 81.25, valid_loss: 6.48799991607666, valid_acc: 72.74, valid_fscore: 73.76, test_loss: 7.573699951171875, test_acc: 68.64, test_fscore: 69.25, time: 2.88 sec
epoch: 49, train_loss: 7.179800033569336, train_acc: 81.69, train_fscore: 81.58, valid_loss: 6.438000202178955, valid_acc: 73.49, valid_fscore: 74.4, test_loss: 7.5995001792907715, test_acc: 67.9, test_fscore: 68.48, time: 2.94 sec
epoch: 50, train_loss: 7.162700176239014, train_acc: 81.85, train_fscore: 81.73, valid_loss: 6.428999900817871, valid_acc: 74.25, valid_fscore: 75.08, test_loss: 7.6255998611450195, test_acc: 67.96, test_fscore: 68.6, time: 3.0 sec
              precision    recall  f1-score   support

           0     0.4303    0.7500    0.5468     144.0
           1     0.8063    0.7306    0.7666     245.0
           2     0.6725    0.6953    0.6837     384.0
           3     0.6448    0.6941    0.6686     170.0
           4     0.9010    0.6087    0.7265     299.0
           5     0.6766    0.6535    0.6649     381.0

    accuracy                         0.6796    1623.0
   macro avg     0.6886    0.6887    0.6762    1623.0
weighted avg     0.7114    0.6796    0.6860    1623.0

[[108.   7.  17.   0.  10.   2.]
 [  3. 179.  30.   2.   0.  31.]
 [ 42.  20. 267.  12.   4.  39.]
 [  0.   0.   6. 118.   0.  46.]
 [ 98.   0.  18.   0. 182.   1.]
 [  0.  16.  59.  51.   6. 249.]]
epoch: 51, train_loss: 7.132900238037109, train_acc: 82.67, train_fscore: 82.56, valid_loss: 6.43720006942749, valid_acc: 73.34, valid_fscore: 74.18, test_loss: 7.565499782562256, test_acc: 68.7, test_fscore: 69.28, time: 2.76 sec
epoch: 52, train_loss: 7.1280999183654785, train_acc: 81.5, train_fscore: 81.35, valid_loss: 6.472099781036377, valid_acc: 73.8, valid_fscore: 74.65, test_loss: 7.562099933624268, test_acc: 68.7, test_fscore: 69.27, time: 2.91 sec
epoch: 53, train_loss: 7.078800201416016, train_acc: 83.11, train_fscore: 83.0, valid_loss: 6.474599838256836, valid_acc: 73.95, valid_fscore: 74.77, test_loss: 7.594099998474121, test_acc: 68.58, test_fscore: 69.13, time: 2.83 sec
epoch: 54, train_loss: 7.081699848175049, train_acc: 82.8, train_fscore: 82.72, valid_loss: 6.457099914550781, valid_acc: 74.25, valid_fscore: 74.96, test_loss: 7.593999862670898, test_acc: 68.82, test_fscore: 69.36, time: 2.89 sec
epoch: 55, train_loss: 7.035600185394287, train_acc: 83.31, train_fscore: 83.2, valid_loss: 6.4319000244140625, valid_acc: 74.55, valid_fscore: 75.08, test_loss: 7.554100036621094, test_acc: 69.44, test_fscore: 69.96, time: 2.97 sec
epoch: 56, train_loss: 7.038300037384033, train_acc: 83.02, train_fscore: 82.89, valid_loss: 6.507599830627441, valid_acc: 73.8, valid_fscore: 74.87, test_loss: 7.627500057220459, test_acc: 67.96, test_fscore: 68.54, time: 2.94 sec
epoch: 57, train_loss: 7.016300201416016, train_acc: 83.56, train_fscore: 83.47, valid_loss: 6.497799873352051, valid_acc: 74.7, valid_fscore: 75.29, test_loss: 7.561100006103516, test_acc: 69.75, test_fscore: 70.27, time: 2.89 sec
epoch: 58, train_loss: 6.992700099945068, train_acc: 83.54, train_fscore: 83.44, valid_loss: 6.507299900054932, valid_acc: 73.04, valid_fscore: 73.81, test_loss: 7.531799793243408, test_acc: 69.5, test_fscore: 70.03, time: 2.9 sec
epoch: 59, train_loss: 6.9959001541137695, train_acc: 83.56, train_fscore: 83.44, valid_loss: 6.506800174713135, valid_acc: 73.95, valid_fscore: 74.95, test_loss: 7.571499824523926, test_acc: 68.82, test_fscore: 69.37, time: 3.0 sec
epoch: 60, train_loss: 6.977399826049805, train_acc: 83.42, train_fscore: 83.3, valid_loss: 6.5030999183654785, valid_acc: 74.55, valid_fscore: 75.2, test_loss: 7.5655999183654785, test_acc: 69.56, test_fscore: 70.08, time: 3.75 sec
              precision    recall  f1-score   support

           0     0.4625    0.7708    0.5781     144.0
           1     0.8182    0.7714    0.7941     245.0
           2     0.6907    0.6979    0.6943     384.0
           3     0.6471    0.7118    0.6779     170.0
           4     0.8899    0.6488    0.7505     299.0
           5     0.6852    0.6457    0.6649     381.0

    accuracy                         0.6956    1623.0
   macro avg     0.6989    0.7077    0.6933    1623.0
weighted avg     0.7205    0.6956    0.7008    1623.0

[[111.   5.  15.   0.  12.   1.]
 [  2. 189.  24.   2.   0.  28.]
 [ 41.  20. 268.  11.   5.  39.]
 [  0.   0.   5. 121.   0.  44.]
 [ 86.   2.  16.   0. 194.   1.]
 [  0.  15.  60.  53.   7. 246.]]
epoch: 61, train_loss: 6.977700233459473, train_acc: 84.26, train_fscore: 84.15, valid_loss: 6.527400016784668, valid_acc: 72.44, valid_fscore: 73.14, test_loss: 7.605000019073486, test_acc: 69.19, test_fscore: 69.7, time: 3.04 sec
epoch: 62, train_loss: 6.942800045013428, train_acc: 84.61, train_fscore: 84.56, valid_loss: 6.526100158691406, valid_acc: 74.1, valid_fscore: 74.96, test_loss: 7.625, test_acc: 68.08, test_fscore: 68.58, time: 3.96 sec
epoch: 63, train_loss: 6.901299953460693, train_acc: 84.73, train_fscore: 84.65, valid_loss: 6.475900173187256, valid_acc: 75.45, valid_fscore: 75.91, test_loss: 7.551499843597412, test_acc: 70.12, test_fscore: 70.58, time: 2.87 sec
epoch: 64, train_loss: 6.915599822998047, train_acc: 84.18, train_fscore: 84.05, valid_loss: 6.548299789428711, valid_acc: 73.04, valid_fscore: 73.87, test_loss: 7.564799785614014, test_acc: 69.44, test_fscore: 70.07, time: 2.9 sec
epoch: 65, train_loss: 6.8850998878479, train_acc: 84.65, train_fscore: 84.54, valid_loss: 6.5304999351501465, valid_acc: 72.89, valid_fscore: 73.6, test_loss: 7.587500095367432, test_acc: 69.38, test_fscore: 69.89, time: 2.98 sec
epoch: 66, train_loss: 6.880499839782715, train_acc: 85.13, train_fscore: 85.05, valid_loss: 6.507699966430664, valid_acc: 74.25, valid_fscore: 74.9, test_loss: 7.589300155639648, test_acc: 69.5, test_fscore: 69.99, time: 3.68 sec
epoch: 67, train_loss: 6.864099979400635, train_acc: 85.1, train_fscore: 85.02, valid_loss: 6.557499885559082, valid_acc: 73.04, valid_fscore: 74.06, test_loss: 7.564799785614014, test_acc: 68.7, test_fscore: 69.26, time: 3.0 sec
epoch: 68, train_loss: 6.845900058746338, train_acc: 84.71, train_fscore: 84.59, valid_loss: 6.564599990844727, valid_acc: 73.04, valid_fscore: 73.51, test_loss: 7.510300159454346, test_acc: 69.5, test_fscore: 69.95, time: 2.81 sec
epoch: 69, train_loss: 6.821899890899658, train_acc: 85.7, train_fscore: 85.59, valid_loss: 6.541600227355957, valid_acc: 73.95, valid_fscore: 74.53, test_loss: 7.597400188446045, test_acc: 69.69, test_fscore: 70.18, time: 2.9 sec
epoch: 70, train_loss: 6.826000213623047, train_acc: 86.4, train_fscore: 86.34, valid_loss: 6.571499824523926, valid_acc: 72.59, valid_fscore: 73.58, test_loss: 7.648499965667725, test_acc: 68.7, test_fscore: 69.17, time: 2.91 sec
              precision    recall  f1-score   support

           0     0.4453    0.8472    0.5837     144.0
           1     0.8253    0.7714    0.7975     245.0
           2     0.7016    0.6979    0.6997     384.0
           3     0.6214    0.7529    0.6809     170.0
           4     0.9171    0.5552    0.6917     299.0
           5     0.6895    0.6352    0.6612     381.0

    accuracy                         0.6870    1623.0
   macro avg     0.7000    0.7100    0.6858    1623.0
weighted avg     0.7260    0.6870    0.6917    1623.0

[[122.   4.  11.   0.   6.   1.]
 [  2. 189.  22.   3.   0.  29.]
 [ 42.  20. 268.  11.   3.  40.]
 [  0.   0.   5. 128.   0.  37.]
 [108.   1.  22.   0. 166.   2.]
 [  0.  15.  54.  64.   6. 242.]]
epoch: 71, train_loss: 6.794099807739258, train_acc: 85.78, train_fscore: 85.67, valid_loss: 6.559500217437744, valid_acc: 74.1, valid_fscore: 74.55, test_loss: 7.5507001876831055, test_acc: 70.3, test_fscore: 70.84, time: 3.09 sec
epoch: 72, train_loss: 6.771599769592285, train_acc: 85.93, train_fscore: 85.86, valid_loss: 6.5578999519348145, valid_acc: 73.95, valid_fscore: 74.54, test_loss: 7.539400100708008, test_acc: 70.12, test_fscore: 70.6, time: 2.91 sec
epoch: 73, train_loss: 6.769199848175049, train_acc: 86.22, train_fscore: 86.14, valid_loss: 6.549600124359131, valid_acc: 74.1, valid_fscore: 74.7, test_loss: 7.57859992980957, test_acc: 68.88, test_fscore: 69.36, time: 2.69 sec
epoch: 74, train_loss: 6.743899822235107, train_acc: 86.44, train_fscore: 86.32, valid_loss: 6.535200119018555, valid_acc: 75.15, valid_fscore: 75.48, test_loss: 7.56879997253418, test_acc: 70.24, test_fscore: 70.7, time: 3.15 sec
epoch: 75, train_loss: 6.751500129699707, train_acc: 86.77, train_fscore: 86.69, valid_loss: 6.565800189971924, valid_acc: 74.55, valid_fscore: 75.13, test_loss: 7.6092000007629395, test_acc: 69.01, test_fscore: 69.53, time: 2.99 sec
epoch: 76, train_loss: 6.722300052642822, train_acc: 86.59, train_fscore: 86.48, valid_loss: 6.576000213623047, valid_acc: 73.8, valid_fscore: 74.53, test_loss: 7.60099983215332, test_acc: 69.19, test_fscore: 69.71, time: 3.97 sec
epoch: 77, train_loss: 6.698400020599365, train_acc: 87.45, train_fscore: 87.38, valid_loss: 6.612299919128418, valid_acc: 73.95, valid_fscore: 74.36, test_loss: 7.569799900054932, test_acc: 70.06, test_fscore: 70.53, time: 2.48 sec
epoch: 78, train_loss: 6.6981000900268555, train_acc: 87.29, train_fscore: 87.2, valid_loss: 6.618599891662598, valid_acc: 74.1, valid_fscore: 74.62, test_loss: 7.600599765777588, test_acc: 69.07, test_fscore: 69.56, time: 3.81 sec
epoch: 79, train_loss: 6.6956000328063965, train_acc: 87.0, train_fscore: 86.91, valid_loss: 6.6529998779296875, valid_acc: 73.34, valid_fscore: 74.22, test_loss: 7.691299915313721, test_acc: 69.01, test_fscore: 69.58, time: 2.81 sec
epoch: 80, train_loss: 6.694699764251709, train_acc: 86.67, train_fscore: 86.57, valid_loss: 6.619100093841553, valid_acc: 75.75, valid_fscore: 75.92, test_loss: 7.6641998291015625, test_acc: 69.99, test_fscore: 70.39, time: 2.79 sec
              precision    recall  f1-score   support

           0     0.4977    0.7361    0.5938     144.0
           1     0.8318    0.7469    0.7871     245.0
           2     0.6755    0.7318    0.7025     384.0
           3     0.6378    0.7353    0.6831     170.0
           4     0.8795    0.6589    0.7533     299.0
           5     0.6893    0.6404    0.6639     381.0

    accuracy                         0.6999    1623.0
   macro avg     0.7019    0.7082    0.6973    1623.0
weighted avg     0.7202    0.6999    0.7039    1623.0

[[106.   4.  17.   0.  16.   1.]
 [  3. 183.  26.   3.   0.  30.]
 [ 32.  18. 281.  10.   5.  38.]
 [  0.   0.   5. 125.   0.  40.]
 [ 72.   2.  27.   0. 197.   1.]
 [  0.  13.  60.  58.   6. 244.]]
epoch: 81, train_loss: 6.693600177764893, train_acc: 88.07, train_fscore: 87.98, valid_loss: 6.684899806976318, valid_acc: 73.19, valid_fscore: 73.87, test_loss: 7.673799991607666, test_acc: 69.13, test_fscore: 69.62, time: 2.95 sec
epoch: 82, train_loss: 6.654099941253662, train_acc: 87.21, train_fscore: 87.14, valid_loss: 6.69320011138916, valid_acc: 72.14, valid_fscore: 72.67, test_loss: 7.573999881744385, test_acc: 70.12, test_fscore: 70.65, time: 4.04 sec
epoch: 83, train_loss: 6.636300086975098, train_acc: 87.33, train_fscore: 87.24, valid_loss: 6.647200107574463, valid_acc: 74.55, valid_fscore: 74.87, test_loss: 7.649899959564209, test_acc: 69.75, test_fscore: 70.23, time: 2.6 sec
epoch: 84, train_loss: 6.649099826812744, train_acc: 87.78, train_fscore: 87.7, valid_loss: 6.7153000831604, valid_acc: 74.1, valid_fscore: 74.59, test_loss: 7.7129998207092285, test_acc: 69.07, test_fscore: 69.6, time: 2.89 sec
epoch: 85, train_loss: 6.630499839782715, train_acc: 88.01, train_fscore: 87.92, valid_loss: 6.700500011444092, valid_acc: 74.1, valid_fscore: 74.49, test_loss: 7.633800029754639, test_acc: 70.06, test_fscore: 70.56, time: 2.84 sec
epoch: 86, train_loss: 6.621500015258789, train_acc: 88.18, train_fscore: 88.12, valid_loss: 6.7052001953125, valid_acc: 74.25, valid_fscore: 74.71, test_loss: 7.639400005340576, test_acc: 69.75, test_fscore: 70.24, time: 2.92 sec
epoch: 87, train_loss: 6.594900131225586, train_acc: 88.4, train_fscore: 88.31, valid_loss: 6.689700126647949, valid_acc: 74.1, valid_fscore: 74.45, test_loss: 7.6265997886657715, test_acc: 69.44, test_fscore: 69.94, time: 2.94 sec
epoch: 88, train_loss: 6.5725998878479, train_acc: 88.3, train_fscore: 88.2, valid_loss: 6.695400238037109, valid_acc: 74.25, valid_fscore: 74.55, test_loss: 7.652900218963623, test_acc: 69.75, test_fscore: 70.24, time: 2.85 sec
epoch: 89, train_loss: 6.559500217437744, train_acc: 89.1, train_fscore: 89.04, valid_loss: 6.7042999267578125, valid_acc: 74.25, valid_fscore: 74.54, test_loss: 7.706399917602539, test_acc: 69.87, test_fscore: 70.27, time: 2.87 sec
epoch: 90, train_loss: 6.532100200653076, train_acc: 89.23, train_fscore: 89.16, valid_loss: 6.698699951171875, valid_acc: 74.25, valid_fscore: 74.58, test_loss: 7.675600051879883, test_acc: 70.24, test_fscore: 70.7, time: 2.89 sec
              precision    recall  f1-score   support

           0     0.4770    0.7917    0.5953     144.0
           1     0.8289    0.7714    0.7992     245.0
           2     0.7117    0.7135    0.7126     384.0
           3     0.6443    0.7353    0.6868     170.0
           4     0.8952    0.6288    0.7387     299.0
           5     0.6812    0.6562    0.6684     381.0

    accuracy                         0.7024    1623.0
   macro avg     0.7064    0.7161    0.7002    1623.0
weighted avg     0.7282    0.7024    0.7070    1623.0

[[114.   4.  13.   0.  12.   1.]
 [  2. 189.  20.   3.   0.  31.]
 [ 35.  19. 274.  10.   4.  42.]
 [  0.   0.   3. 125.   0.  42.]
 [ 88.   2.  20.   0. 188.   1.]
 [  0.  14.  55.  56.   6. 250.]]
epoch: 91, train_loss: 6.530300140380859, train_acc: 88.53, train_fscore: 88.46, valid_loss: 6.7368998527526855, valid_acc: 74.25, valid_fscore: 74.61, test_loss: 7.638500213623047, test_acc: 70.61, test_fscore: 71.03, time: 2.91 sec
epoch: 92, train_loss: 6.551599979400635, train_acc: 89.04, train_fscore: 88.97, valid_loss: 6.72760009765625, valid_acc: 73.34, valid_fscore: 73.77, test_loss: 7.71120023727417, test_acc: 69.13, test_fscore: 69.6, time: 3.54 sec
epoch: 93, train_loss: 6.5005998611450195, train_acc: 89.12, train_fscore: 89.02, valid_loss: 6.769100189208984, valid_acc: 73.95, valid_fscore: 74.44, test_loss: 7.700799942016602, test_acc: 70.06, test_fscore: 70.59, time: 2.28 sec
epoch: 94, train_loss: 6.507900238037109, train_acc: 89.04, train_fscore: 88.97, valid_loss: 6.750699996948242, valid_acc: 73.49, valid_fscore: 73.93, test_loss: 7.688700199127197, test_acc: 70.79, test_fscore: 71.2, time: 2.86 sec
epoch: 95, train_loss: 6.509799957275391, train_acc: 89.43, train_fscore: 89.36, valid_loss: 6.732699871063232, valid_acc: 73.8, valid_fscore: 74.24, test_loss: 7.71619987487793, test_acc: 70.06, test_fscore: 70.46, time: 2.9 sec
epoch: 96, train_loss: 6.492199897766113, train_acc: 89.51, train_fscore: 89.44, valid_loss: 6.745299816131592, valid_acc: 74.55, valid_fscore: 74.97, test_loss: 7.691999912261963, test_acc: 70.79, test_fscore: 71.28, time: 2.82 sec
epoch: 97, train_loss: 6.4720001220703125, train_acc: 89.39, train_fscore: 89.32, valid_loss: 6.691100120544434, valid_acc: 75.0, valid_fscore: 75.32, test_loss: 7.69920015335083, test_acc: 70.79, test_fscore: 71.22, time: 3.79 sec
epoch: 98, train_loss: 6.466100215911865, train_acc: 90.11, train_fscore: 90.02, valid_loss: 6.705599784851074, valid_acc: 73.95, valid_fscore: 74.28, test_loss: 7.721199989318848, test_acc: 70.3, test_fscore: 70.69, time: 2.9 sec
epoch: 99, train_loss: 6.472400188446045, train_acc: 90.19, train_fscore: 90.12, valid_loss: 6.764800071716309, valid_acc: 74.25, valid_fscore: 74.6, test_loss: 7.702899932861328, test_acc: 70.92, test_fscore: 71.38, time: 2.87 sec
epoch: 100, train_loss: 6.464399814605713, train_acc: 89.84, train_fscore: 89.76, valid_loss: 6.730100154876709, valid_acc: 74.25, valid_fscore: 74.55, test_loss: 7.697199821472168, test_acc: 70.92, test_fscore: 71.33, time: 2.35 sec
              precision    recall  f1-score   support

           0     0.4852    0.7986    0.6037     144.0
           1     0.8363    0.7714    0.8025     245.0
           2     0.7111    0.7370    0.7238     384.0
           3     0.6649    0.7235    0.6930     170.0
           4     0.8937    0.6187    0.7312     299.0
           5     0.6919    0.6719    0.6818     381.0

    accuracy                         0.7092    1623.0
   macro avg     0.7138    0.7202    0.7060    1623.0
weighted avg     0.7342    0.7092    0.7133    1623.0

[[115.   4.  12.   0.  12.   1.]
 [  3. 189.  23.   2.   0.  28.]
 [ 31.  18. 283.   7.   5.  40.]
 [  0.   0.   4. 123.   0.  43.]
 [ 88.   1.  23.   0. 185.   2.]
 [  0.  14.  53.  53.   5. 256.]]
epoch: 101, train_loss: 6.416399955749512, train_acc: 90.4, train_fscore: 90.34, valid_loss: 6.75629997253418, valid_acc: 74.85, valid_fscore: 75.1, test_loss: 7.718800067901611, test_acc: 70.98, test_fscore: 71.32, time: 2.39 sec
epoch: 102, train_loss: 6.444200038909912, train_acc: 90.11, train_fscore: 90.04, valid_loss: 6.7804999351501465, valid_acc: 73.64, valid_fscore: 74.07, test_loss: 7.773399829864502, test_acc: 70.06, test_fscore: 70.45, time: 2.92 sec
epoch: 103, train_loss: 6.408599853515625, train_acc: 90.17, train_fscore: 90.11, valid_loss: 6.796599864959717, valid_acc: 73.64, valid_fscore: 74.14, test_loss: 7.766200065612793, test_acc: 70.79, test_fscore: 71.11, time: 3.8 sec
epoch: 104, train_loss: 6.4029998779296875, train_acc: 90.23, train_fscore: 90.16, valid_loss: 6.806600093841553, valid_acc: 74.25, valid_fscore: 74.33, test_loss: 7.689700126647949, test_acc: 71.16, test_fscore: 71.5, time: 2.85 sec
epoch: 105, train_loss: 6.382400035858154, train_acc: 91.24, train_fscore: 91.18, valid_loss: 6.803599834442139, valid_acc: 75.15, valid_fscore: 75.47, test_loss: 7.752999782562256, test_acc: 70.24, test_fscore: 70.64, time: 3.89 sec
epoch: 106, train_loss: 6.394700050354004, train_acc: 90.48, train_fscore: 90.41, valid_loss: 6.812099933624268, valid_acc: 74.7, valid_fscore: 75.02, test_loss: 7.75029993057251, test_acc: 70.24, test_fscore: 70.6, time: 2.8 sec
epoch: 107, train_loss: 6.394100189208984, train_acc: 90.69, train_fscore: 90.61, valid_loss: 6.832600116729736, valid_acc: 74.1, valid_fscore: 74.25, test_loss: 7.784200191497803, test_acc: 70.92, test_fscore: 71.28, time: 2.87 sec
epoch: 108, train_loss: 6.385200023651123, train_acc: 91.06, train_fscore: 91.02, valid_loss: 6.853799819946289, valid_acc: 72.44, valid_fscore: 72.96, test_loss: 7.8024001121521, test_acc: 70.24, test_fscore: 70.63, time: 2.33 sec
epoch: 109, train_loss: 6.364299774169922, train_acc: 90.89, train_fscore: 90.83, valid_loss: 6.808599948883057, valid_acc: 73.34, valid_fscore: 73.65, test_loss: 7.767899990081787, test_acc: 70.79, test_fscore: 71.17, time: 3.24 sec
epoch: 110, train_loss: 6.334799766540527, train_acc: 91.35, train_fscore: 91.3, valid_loss: 6.881800174713135, valid_acc: 73.8, valid_fscore: 73.85, test_loss: 7.773099899291992, test_acc: 71.35, test_fscore: 71.68, time: 3.07 sec
              precision    recall  f1-score   support

           0     0.5369    0.7569    0.6282     144.0
           1     0.8288    0.7510    0.7880     245.0
           2     0.6901    0.7422    0.7152     384.0
           3     0.6742    0.7059    0.6897     170.0
           4     0.8894    0.6722    0.7657     299.0
           5     0.6798    0.6798    0.6798     381.0

    accuracy                         0.7135    1623.0
   macro avg     0.7165    0.7180    0.7111    1623.0
weighted avg     0.7301    0.7135    0.7168    1623.0

[[109.   4.  16.   0.  14.   1.]
 [  3. 184.  24.   3.   0.  31.]
 [ 24.  18. 285.   8.   6.  43.]
 [  0.   0.   4. 120.   0.  46.]
 [ 67.   2.  28.   0. 201.   1.]
 [  0.  14.  56.  47.   5. 259.]]
epoch: 111, train_loss: 6.350900173187256, train_acc: 91.06, train_fscore: 91.02, valid_loss: 6.879799842834473, valid_acc: 73.34, valid_fscore: 73.8, test_loss: 7.820300102233887, test_acc: 69.81, test_fscore: 70.22, time: 2.94 sec
epoch: 112, train_loss: 6.345399856567383, train_acc: 91.35, train_fscore: 91.3, valid_loss: 6.888599872589111, valid_acc: 74.55, valid_fscore: 74.95, test_loss: 7.813300132751465, test_acc: 70.61, test_fscore: 71.07, time: 3.77 sec
epoch: 113, train_loss: 6.336900234222412, train_acc: 91.68, train_fscore: 91.64, valid_loss: 6.842100143432617, valid_acc: 73.95, valid_fscore: 74.19, test_loss: 7.786600112915039, test_acc: 70.73, test_fscore: 71.12, time: 3.16 sec
epoch: 114, train_loss: 6.325399875640869, train_acc: 90.96, train_fscore: 90.89, valid_loss: 6.905799865722656, valid_acc: 73.64, valid_fscore: 73.97, test_loss: 7.867499828338623, test_acc: 69.99, test_fscore: 70.37, time: 2.61 sec
epoch: 115, train_loss: 6.306300163269043, train_acc: 91.64, train_fscore: 91.6, valid_loss: 6.933899879455566, valid_acc: 72.74, valid_fscore: 73.04, test_loss: 7.811399936676025, test_acc: 70.67, test_fscore: 71.06, time: 2.87 sec
epoch: 116, train_loss: 6.314300060272217, train_acc: 91.62, train_fscore: 91.58, valid_loss: 6.938300132751465, valid_acc: 73.49, valid_fscore: 73.51, test_loss: 7.759099960327148, test_acc: 71.04, test_fscore: 71.41, time: 2.89 sec
epoch: 117, train_loss: 6.297800064086914, train_acc: 91.53, train_fscore: 91.46, valid_loss: 6.909599781036377, valid_acc: 73.34, valid_fscore: 73.63, test_loss: 7.838099956512451, test_acc: 69.93, test_fscore: 70.32, time: 2.43 sec
epoch: 118, train_loss: 6.2804999351501465, train_acc: 91.59, train_fscore: 91.5, valid_loss: 6.936200141906738, valid_acc: 73.64, valid_fscore: 73.77, test_loss: 7.904799938201904, test_acc: 70.86, test_fscore: 71.19, time: 2.39 sec
epoch: 119, train_loss: 6.283299922943115, train_acc: 92.23, train_fscore: 92.19, valid_loss: 6.979800224304199, valid_acc: 73.8, valid_fscore: 74.08, test_loss: 7.911600112915039, test_acc: 70.73, test_fscore: 71.09, time: 3.73 sec
epoch: 120, train_loss: 6.281499862670898, train_acc: 92.52, train_fscore: 92.49, valid_loss: 6.917699813842773, valid_acc: 73.95, valid_fscore: 74.2, test_loss: 7.8394999504089355, test_acc: 70.18, test_fscore: 70.55, time: 3.03 sec
              precision    recall  f1-score   support

           0     0.4813    0.8056    0.6026     144.0
           1     0.8162    0.7796    0.7975     245.0
           2     0.6933    0.7240    0.7083     384.0
           3     0.6497    0.7529    0.6975     170.0
           4     0.8932    0.6154    0.7287     299.0
           5     0.7035    0.6352    0.6676     381.0

    accuracy                         0.7018    1623.0
   macro avg     0.7062    0.7188    0.7004    1623.0
weighted avg     0.7277    0.7018    0.7055    1623.0

[[116.   4.  12.   0.  11.   1.]
 [  3. 191.  23.   3.   0.  25.]
 [ 35.  19. 278.   8.   5.  39.]
 [  0.   1.   5. 128.   0.  36.]
 [ 87.   2.  25.   0. 184.   1.]
 [  0.  17.  58.  58.   6. 242.]]
epoch: 121, train_loss: 6.263500213623047, train_acc: 91.72, train_fscore: 91.65, valid_loss: 6.906499862670898, valid_acc: 74.55, valid_fscore: 74.73, test_loss: 7.860099792480469, test_acc: 70.79, test_fscore: 71.1, time: 2.77 sec
epoch: 122, train_loss: 6.236199855804443, train_acc: 92.17, train_fscore: 92.12, valid_loss: 6.919899940490723, valid_acc: 74.1, valid_fscore: 74.33, test_loss: 7.914100170135498, test_acc: 70.67, test_fscore: 71.02, time: 2.84 sec
epoch: 123, train_loss: 6.238999843597412, train_acc: 92.81, train_fscore: 92.77, valid_loss: 6.936500072479248, valid_acc: 73.8, valid_fscore: 74.0, test_loss: 7.885300159454346, test_acc: 70.61, test_fscore: 70.95, time: 2.83 sec
epoch: 124, train_loss: 6.217800140380859, train_acc: 92.64, train_fscore: 92.59, valid_loss: 6.976500034332275, valid_acc: 73.95, valid_fscore: 74.09, test_loss: 7.848100185394287, test_acc: 71.1, test_fscore: 71.4, time: 2.83 sec
epoch: 125, train_loss: 6.239099979400635, train_acc: 92.36, train_fscore: 92.3, valid_loss: 7.0208001136779785, valid_acc: 74.7, valid_fscore: 74.9, test_loss: 7.854499816894531, test_acc: 71.04, test_fscore: 71.37, time: 2.86 sec
epoch: 126, train_loss: 6.212800025939941, train_acc: 93.22, train_fscore: 93.18, valid_loss: 7.015900135040283, valid_acc: 73.8, valid_fscore: 74.13, test_loss: 7.884699821472168, test_acc: 70.67, test_fscore: 71.03, time: 3.82 sec
epoch: 127, train_loss: 6.214399814605713, train_acc: 93.02, train_fscore: 92.99, valid_loss: 6.997399806976318, valid_acc: 74.4, valid_fscore: 74.26, test_loss: 7.851500034332275, test_acc: 71.41, test_fscore: 71.67, time: 2.98 sec
epoch: 128, train_loss: 6.198699951171875, train_acc: 92.3, train_fscore: 92.25, valid_loss: 7.027900218963623, valid_acc: 73.19, valid_fscore: 73.42, test_loss: 7.887199878692627, test_acc: 71.23, test_fscore: 71.52, time: 2.75 sec
epoch: 129, train_loss: 6.191800117492676, train_acc: 93.14, train_fscore: 93.1, valid_loss: 6.993800163269043, valid_acc: 73.8, valid_fscore: 74.1, test_loss: 7.914599895477295, test_acc: 70.73, test_fscore: 71.05, time: 2.85 sec
epoch: 130, train_loss: 6.172100067138672, train_acc: 92.97, train_fscore: 92.93, valid_loss: 6.949100017547607, valid_acc: 73.95, valid_fscore: 74.02, test_loss: 7.8480000495910645, test_acc: 70.98, test_fscore: 71.28, time: 2.8 sec
              precision    recall  f1-score   support

           0     0.5300    0.7361    0.6163     144.0
           1     0.8333    0.7551    0.7923     245.0
           2     0.6761    0.7500    0.7111     384.0
           3     0.6851    0.7294    0.7066     170.0
           4     0.8750    0.6555    0.7495     299.0
           5     0.6838    0.6640    0.6738     381.0

    accuracy                         0.7098    1623.0
   macro avg     0.7139    0.7150    0.7083    1623.0
weighted avg     0.7262    0.7098    0.7128    1623.0

[[106.   4.  16.   0.  17.   1.]
 [  3. 185.  26.   2.   0.  29.]
 [ 23.  17. 288.   5.   6.  45.]
 [  0.   0.   5. 124.   0.  41.]
 [ 68.   2.  32.   0. 196.   1.]
 [  0.  14.  59.  50.   5. 253.]]
epoch: 131, train_loss: 6.171999931335449, train_acc: 93.28, train_fscore: 93.23, valid_loss: 6.93310022354126, valid_acc: 75.15, valid_fscore: 75.16, test_loss: 7.851600170135498, test_acc: 71.53, test_fscore: 71.82, time: 2.96 sec
epoch: 132, train_loss: 6.16379976272583, train_acc: 93.26, train_fscore: 93.21, valid_loss: 6.9120001792907715, valid_acc: 73.19, valid_fscore: 73.6, test_loss: 8.042699813842773, test_acc: 69.69, test_fscore: 70.01, time: 3.7 sec
epoch: 133, train_loss: 6.156899929046631, train_acc: 92.77, train_fscore: 92.74, valid_loss: 6.994900226593018, valid_acc: 73.34, valid_fscore: 73.48, test_loss: 8.00979995727539, test_acc: 70.36, test_fscore: 70.65, time: 2.73 sec
epoch: 134, train_loss: 6.153600215911865, train_acc: 93.63, train_fscore: 93.59, valid_loss: 7.033699989318848, valid_acc: 74.25, valid_fscore: 74.24, test_loss: 7.875100135803223, test_acc: 71.41, test_fscore: 71.66, time: 3.8 sec
epoch: 135, train_loss: 6.127200126647949, train_acc: 93.43, train_fscore: 93.38, valid_loss: 7.031000137329102, valid_acc: 73.64, valid_fscore: 73.89, test_loss: 7.924900054931641, test_acc: 70.67, test_fscore: 71.06, time: 2.8 sec
epoch: 136, train_loss: 6.1296000480651855, train_acc: 93.33, train_fscore: 93.3, valid_loss: 7.072800159454346, valid_acc: 73.95, valid_fscore: 74.17, test_loss: 7.995299816131592, test_acc: 70.36, test_fscore: 70.71, time: 2.87 sec
epoch: 137, train_loss: 6.146100044250488, train_acc: 93.8, train_fscore: 93.76, valid_loss: 7.059700012207031, valid_acc: 73.95, valid_fscore: 73.94, test_loss: 7.99459981918335, test_acc: 70.67, test_fscore: 70.95, time: 2.8 sec
epoch: 138, train_loss: 6.142600059509277, train_acc: 94.07, train_fscore: 94.04, valid_loss: 7.039100170135498, valid_acc: 74.55, valid_fscore: 74.55, test_loss: 7.886499881744385, test_acc: 71.66, test_fscore: 71.96, time: 3.42 sec
epoch: 139, train_loss: 6.134699821472168, train_acc: 93.59, train_fscore: 93.55, valid_loss: 7.045899868011475, valid_acc: 73.64, valid_fscore: 73.96, test_loss: 7.940999984741211, test_acc: 71.1, test_fscore: 71.43, time: 3.44 sec
epoch: 140, train_loss: 6.108399868011475, train_acc: 93.88, train_fscore: 93.84, valid_loss: 7.0447998046875, valid_acc: 74.1, valid_fscore: 74.16, test_loss: 8.049099922180176, test_acc: 70.24, test_fscore: 70.49, time: 2.59 sec
              precision    recall  f1-score   support

           0     0.5283    0.7778    0.6292     144.0
           1     0.8387    0.7429    0.7879     245.0
           2     0.6607    0.7708    0.7115     384.0
           3     0.6545    0.7353    0.6925     170.0
           4     0.8894    0.6187    0.7298     299.0
           5     0.6916    0.6299    0.6593     381.0

    accuracy                         0.7024    1623.0
   macro avg     0.7105    0.7126    0.7017    1623.0
weighted avg     0.7246    0.7024    0.7049    1623.0

[[112.   4.  15.   0.  12.   1.]
 [  2. 182.  31.   3.   0.  27.]
 [ 22.  15. 296.   6.   6.  39.]
 [  0.   0.   6. 125.   0.  39.]
 [ 76.   2.  35.   0. 185.   1.]
 [  0.  14.  65.  57.   5. 240.]]
epoch: 141, train_loss: 6.103400230407715, train_acc: 94.23, train_fscore: 94.2, valid_loss: 7.0370001792907715, valid_acc: 74.1, valid_fscore: 74.09, test_loss: 7.9781999588012695, test_acc: 71.29, test_fscore: 71.57, time: 2.89 sec
epoch: 142, train_loss: 6.097499847412109, train_acc: 94.35, train_fscore: 94.31, valid_loss: 7.0569000244140625, valid_acc: 74.7, valid_fscore: 74.72, test_loss: 8.000800132751465, test_acc: 70.61, test_fscore: 70.95, time: 3.2 sec
epoch: 143, train_loss: 6.109499931335449, train_acc: 93.78, train_fscore: 93.73, valid_loss: 7.096399784088135, valid_acc: 74.55, valid_fscore: 74.7, test_loss: 8.07229995727539, test_acc: 70.24, test_fscore: 70.54, time: 2.41 sec
epoch: 144, train_loss: 6.103400230407715, train_acc: 94.44, train_fscore: 94.42, valid_loss: 7.069399833679199, valid_acc: 73.95, valid_fscore: 74.08, test_loss: 8.006600379943848, test_acc: 70.73, test_fscore: 71.07, time: 2.9 sec
epoch: 145, train_loss: 6.07919979095459, train_acc: 93.96, train_fscore: 93.92, valid_loss: 7.060800075531006, valid_acc: 74.4, valid_fscore: 74.44, test_loss: 8.016799926757812, test_acc: 70.36, test_fscore: 70.72, time: 3.0 sec
epoch: 146, train_loss: 6.072999954223633, train_acc: 94.13, train_fscore: 94.09, valid_loss: 7.150700092315674, valid_acc: 73.8, valid_fscore: 73.88, test_loss: 8.059900283813477, test_acc: 70.92, test_fscore: 71.22, time: 2.63 sec
epoch: 147, train_loss: 6.070199966430664, train_acc: 94.62, train_fscore: 94.59, valid_loss: 7.154600143432617, valid_acc: 72.89, valid_fscore: 72.9, test_loss: 8.044699668884277, test_acc: 70.67, test_fscore: 70.95, time: 2.81 sec
epoch: 148, train_loss: 6.0370001792907715, train_acc: 94.54, train_fscore: 94.51, valid_loss: 7.105000019073486, valid_acc: 73.8, valid_fscore: 74.09, test_loss: 8.060799598693848, test_acc: 70.55, test_fscore: 70.82, time: 2.79 sec
epoch: 149, train_loss: 6.018400192260742, train_acc: 94.46, train_fscore: 94.43, valid_loss: 7.159299850463867, valid_acc: 73.64, valid_fscore: 73.69, test_loss: 8.04740047454834, test_acc: 70.86, test_fscore: 71.18, time: 2.92 sec
epoch: 150, train_loss: 6.037199974060059, train_acc: 94.87, train_fscore: 94.85, valid_loss: 7.15369987487793, valid_acc: 73.64, valid_fscore: 73.55, test_loss: 8.043000221252441, test_acc: 70.73, test_fscore: 71.01, time: 3.76 sec
              precision    recall  f1-score   support

           0     0.5312    0.7083    0.6071     144.0
           1     0.8333    0.7551    0.7923     245.0
           2     0.6636    0.7552    0.7065     384.0
           3     0.6684    0.7471    0.7056     170.0
           4     0.8684    0.6622    0.7514     299.0
           5     0.6949    0.6457    0.6694     381.0

    accuracy                         0.7073    1623.0
   macro avg     0.7100    0.7123    0.7054    1623.0
weighted avg     0.7231    0.7073    0.7101    1623.0

[[102.   4.  18.   0.  19.   1.]
 [  2. 185.  29.   3.   0.  26.]
 [ 22.  17. 290.   6.   6.  43.]
 [  0.   0.   6. 127.   0.  37.]
 [ 66.   2.  32.   0. 198.   1.]
 [  0.  14.  62.  54.   5. 246.]]
Best validation F-Score: 71.01
Test performance..
F-Score: 71.01
Accuracy: 70.73
Loss: 8.043000221252441
--- 4 ---
loss_mask: [True, True, True, True]
Namespace(no_cuda=False, lr=0.0001, l2=1e-05, dropout=0.5, batch_size=64, hidden_dim=1024, n_head=8, epochs=150, temp=2, tensorboard=False, class_weight=True, Dataset='IEMOCAP', loss_mask='1111')
Running on GPU
temp 2
total parameters: 97535000
training parameters: 97535000
epoch: 1, train_loss: 12.321800231933594, train_acc: 20.93, train_fscore: 21.31, valid_loss: 10.246399879455566, valid_acc: 31.78, valid_fscore: 30.04, test_loss: 11.230600357055664, test_acc: 34.81, test_fscore: 30.61, time: 3.89 sec
epoch: 2, train_loss: 11.543899536132812, train_acc: 41.9, train_fscore: 40.22, valid_loss: 9.758999824523926, valid_acc: 44.58, valid_fscore: 43.4, test_loss: 10.714900016784668, test_acc: 40.23, test_fscore: 38.59, time: 2.78 sec
epoch: 3, train_loss: 11.051600456237793, train_acc: 47.16, train_fscore: 44.36, valid_loss: 9.135199546813965, valid_acc: 51.96, valid_fscore: 53.17, test_loss: 10.236900329589844, test_acc: 47.01, test_fscore: 45.96, time: 2.82 sec
epoch: 4, train_loss: 10.638699531555176, train_acc: 52.55, train_fscore: 51.14, valid_loss: 8.7677001953125, valid_acc: 59.19, valid_fscore: 59.08, test_loss: 9.96619987487793, test_acc: 53.11, test_fscore: 52.8, time: 2.82 sec
epoch: 5, train_loss: 10.29580020904541, train_acc: 58.41, train_fscore: 57.33, valid_loss: 8.605600357055664, valid_acc: 61.9, valid_fscore: 63.19, test_loss: 9.799099922180176, test_acc: 56.56, test_fscore: 56.77, time: 2.87 sec
epoch: 6, train_loss: 9.999600410461426, train_acc: 61.31, train_fscore: 60.97, valid_loss: 8.402999877929688, valid_acc: 62.35, valid_fscore: 64.49, test_loss: 9.641400337219238, test_acc: 57.49, test_fscore: 57.88, time: 2.88 sec
epoch: 7, train_loss: 9.678099632263184, train_acc: 64.22, train_fscore: 64.02, valid_loss: 8.029199600219727, valid_acc: 65.21, valid_fscore: 66.22, test_loss: 9.293100357055664, test_acc: 60.75, test_fscore: 61.23, time: 3.69 sec
epoch: 8, train_loss: 9.331999778747559, train_acc: 65.58, train_fscore: 65.21, valid_loss: 7.6682000160217285, valid_acc: 64.76, valid_fscore: 66.83, test_loss: 8.919500350952148, test_acc: 60.01, test_fscore: 60.81, time: 2.91 sec
epoch: 9, train_loss: 9.073200225830078, train_acc: 66.19, train_fscore: 65.69, valid_loss: 7.5208001136779785, valid_acc: 65.81, valid_fscore: 67.95, test_loss: 8.760700225830078, test_acc: 61.49, test_fscore: 62.48, time: 2.85 sec
epoch: 10, train_loss: 8.892600059509277, train_acc: 67.49, train_fscore: 67.32, valid_loss: 7.451499938964844, valid_acc: 65.81, valid_fscore: 67.88, test_loss: 8.699000358581543, test_acc: 61.8, test_fscore: 62.78, time: 3.44 sec
              precision    recall  f1-score   support

           0     0.3269    0.7014    0.4459     144.0
           1     0.8010    0.6571    0.7220     245.0
           2     0.6566    0.5078    0.5727     384.0
           3     0.6099    0.6529    0.6307     170.0
           4     0.8670    0.5452    0.6694     299.0
           5     0.6099    0.7139    0.6578     381.0

    accuracy                         0.6180    1623.0
   macro avg     0.6452    0.6297    0.6164    1623.0
weighted avg     0.6720    0.6180    0.6278    1623.0

[[101.   6.   9.   3.  22.   3.]
 [ 13. 161.  30.   2.   0.  39.]
 [ 65.  24. 195.  23.   1.  76.]
 [  0.   0.   5. 111.   0.  54.]
 [121.   0.  11.   2. 163.   2.]
 [  9.  10.  47.  41.   2. 272.]]
epoch: 11, train_loss: 8.813199996948242, train_acc: 68.32, train_fscore: 68.07, valid_loss: 7.284200191497803, valid_acc: 67.17, valid_fscore: 68.47, test_loss: 8.610899925231934, test_acc: 62.66, test_fscore: 63.85, time: 3.21 sec
epoch: 12, train_loss: 8.711999893188477, train_acc: 69.14, train_fscore: 69.07, valid_loss: 7.117599964141846, valid_acc: 67.62, valid_fscore: 69.22, test_loss: 8.46150016784668, test_acc: 62.6, test_fscore: 63.65, time: 2.84 sec
epoch: 13, train_loss: 8.620800018310547, train_acc: 68.54, train_fscore: 68.15, valid_loss: 6.948599815368652, valid_acc: 69.43, valid_fscore: 70.05, test_loss: 8.265199661254883, test_acc: 64.02, test_fscore: 64.72, time: 2.75 sec
epoch: 14, train_loss: 8.534799575805664, train_acc: 69.28, train_fscore: 68.84, valid_loss: 6.934500217437744, valid_acc: 68.37, valid_fscore: 70.05, test_loss: 8.220800399780273, test_acc: 62.42, test_fscore: 63.4, time: 3.13 sec
epoch: 15, train_loss: 8.433199882507324, train_acc: 70.33, train_fscore: 70.0, valid_loss: 6.8815999031066895, valid_acc: 69.13, valid_fscore: 70.61, test_loss: 8.205100059509277, test_acc: 64.33, test_fscore: 65.03, time: 2.23 sec
epoch: 16, train_loss: 8.380800247192383, train_acc: 70.4, train_fscore: 69.93, valid_loss: 6.837900161743164, valid_acc: 69.13, valid_fscore: 70.68, test_loss: 8.175600051879883, test_acc: 64.45, test_fscore: 65.22, time: 3.11 sec
epoch: 17, train_loss: 8.33899974822998, train_acc: 71.45, train_fscore: 71.16, valid_loss: 6.8231000900268555, valid_acc: 67.62, valid_fscore: 69.43, test_loss: 8.122900009155273, test_acc: 63.65, test_fscore: 64.61, time: 2.83 sec
epoch: 18, train_loss: 8.25, train_acc: 71.82, train_fscore: 71.56, valid_loss: 6.763599872589111, valid_acc: 70.03, valid_fscore: 71.25, test_loss: 8.087400436401367, test_acc: 65.25, test_fscore: 65.96, time: 3.89 sec
epoch: 19, train_loss: 8.202500343322754, train_acc: 71.88, train_fscore: 71.35, valid_loss: 6.724299907684326, valid_acc: 68.98, valid_fscore: 70.81, test_loss: 8.087499618530273, test_acc: 64.14, test_fscore: 65.03, time: 2.75 sec
epoch: 20, train_loss: 8.115900039672852, train_acc: 73.14, train_fscore: 72.97, valid_loss: 6.740699768066406, valid_acc: 68.07, valid_fscore: 70.27, test_loss: 8.122099876403809, test_acc: 62.97, test_fscore: 63.87, time: 2.79 sec
              precision    recall  f1-score   support

           0     0.3454    0.7292    0.4688     144.0
           1     0.7962    0.6857    0.7368     245.0
           2     0.6490    0.6068    0.6272     384.0
           3     0.6196    0.6706    0.6441     170.0
           4     0.8757    0.4950    0.6325     299.0
           5     0.6414    0.6667    0.6538     381.0

    accuracy                         0.6297    1623.0
   macro avg     0.6546    0.6423    0.6272    1623.0
weighted avg     0.6812    0.6297    0.6387    1623.0

[[105.   5.  12.   3.  17.   2.]
 [  6. 168.  36.   1.   0.  34.]
 [ 57.  21. 233.  19.   1.  53.]
 [  0.   0.   5. 114.   0.  51.]
 [132.   0.  17.   0. 148.   2.]
 [  4.  17.  56.  47.   3. 254.]]
epoch: 21, train_loss: 8.083399772644043, train_acc: 73.51, train_fscore: 73.33, valid_loss: 6.698400020599365, valid_acc: 70.93, valid_fscore: 72.0, test_loss: 8.087800025939941, test_acc: 66.11, test_fscore: 66.67, time: 3.61 sec
epoch: 22, train_loss: 8.031999588012695, train_acc: 73.26, train_fscore: 72.83, valid_loss: 6.6519999504089355, valid_acc: 69.43, valid_fscore: 70.45, test_loss: 7.956200122833252, test_acc: 66.67, test_fscore: 67.24, time: 2.47 sec
epoch: 23, train_loss: 7.9721999168396, train_acc: 74.49, train_fscore: 74.29, valid_loss: 6.7027997970581055, valid_acc: 67.47, valid_fscore: 69.6, test_loss: 7.963699817657471, test_acc: 63.71, test_fscore: 64.63, time: 2.51 sec
epoch: 24, train_loss: 7.940700054168701, train_acc: 73.65, train_fscore: 73.55, valid_loss: 6.643400192260742, valid_acc: 71.54, valid_fscore: 72.95, test_loss: 7.991099834442139, test_acc: 65.74, test_fscore: 66.4, time: 2.93 sec
epoch: 25, train_loss: 7.900400161743164, train_acc: 74.47, train_fscore: 74.12, valid_loss: 6.611100196838379, valid_acc: 71.99, valid_fscore: 73.11, test_loss: 7.9664998054504395, test_acc: 66.54, test_fscore: 67.12, time: 2.8 sec
epoch: 26, train_loss: 7.834099769592285, train_acc: 75.42, train_fscore: 75.19, valid_loss: 6.58489990234375, valid_acc: 70.48, valid_fscore: 72.04, test_loss: 7.921500205993652, test_acc: 65.37, test_fscore: 66.21, time: 2.81 sec
epoch: 27, train_loss: 7.807499885559082, train_acc: 75.51, train_fscore: 75.33, valid_loss: 6.520500183105469, valid_acc: 71.69, valid_fscore: 72.97, test_loss: 7.865900039672852, test_acc: 66.73, test_fscore: 67.37, time: 2.86 sec
epoch: 28, train_loss: 7.746099948883057, train_acc: 76.18, train_fscore: 75.92, valid_loss: 6.526199817657471, valid_acc: 71.69, valid_fscore: 72.6, test_loss: 7.820799827575684, test_acc: 68.21, test_fscore: 68.63, time: 3.17 sec
epoch: 29, train_loss: 7.708600044250488, train_acc: 76.18, train_fscore: 75.91, valid_loss: 6.580599784851074, valid_acc: 70.63, valid_fscore: 72.14, test_loss: 7.7993998527526855, test_acc: 66.85, test_fscore: 67.54, time: 2.53 sec
epoch: 30, train_loss: 7.686299800872803, train_acc: 76.53, train_fscore: 76.39, valid_loss: 6.609499931335449, valid_acc: 69.73, valid_fscore: 71.82, test_loss: 7.83050012588501, test_acc: 65.43, test_fscore: 66.18, time: 2.78 sec
              precision    recall  f1-score   support

           0     0.3741    0.7639    0.5023     144.0
           1     0.7937    0.7224    0.7564     245.0
           2     0.7035    0.6302    0.6648     384.0
           3     0.6425    0.6765    0.6590     170.0
           4     0.8994    0.5084    0.6496     299.0
           5     0.6425    0.6982    0.6692     381.0

    accuracy                         0.6543    1623.0
   macro avg     0.6760    0.6666    0.6502    1623.0
weighted avg     0.7033    0.6543    0.6618    1623.0

[[110.   7.  11.   2.  10.   4.]
 [  5. 177.  26.   1.   0.  36.]
 [ 43.  25. 242.  17.   3.  54.]
 [  0.   0.   3. 115.   0.  52.]
 [134.   0.  11.   0. 152.   2.]
 [  2.  14.  51.  44.   4. 266.]]
epoch: 31, train_loss: 7.660399913787842, train_acc: 75.94, train_fscore: 75.82, valid_loss: 6.514999866485596, valid_acc: 72.29, valid_fscore: 73.13, test_loss: 7.792500019073486, test_acc: 67.16, test_fscore: 67.73, time: 2.83 sec
epoch: 32, train_loss: 7.619699954986572, train_acc: 76.66, train_fscore: 76.35, valid_loss: 6.48960018157959, valid_acc: 71.99, valid_fscore: 72.51, test_loss: 7.7291998863220215, test_acc: 68.08, test_fscore: 68.43, time: 4.42 sec
epoch: 33, train_loss: 7.616300106048584, train_acc: 77.71, train_fscore: 77.51, valid_loss: 6.53380012512207, valid_acc: 70.33, valid_fscore: 71.81, test_loss: 7.730500221252441, test_acc: 67.1, test_fscore: 67.84, time: 3.22 sec
epoch: 34, train_loss: 7.560699939727783, train_acc: 77.69, train_fscore: 77.65, valid_loss: 6.531799793243408, valid_acc: 71.08, valid_fscore: 72.66, test_loss: 7.777500152587891, test_acc: 66.48, test_fscore: 67.14, time: 3.76 sec
epoch: 35, train_loss: 7.526000022888184, train_acc: 77.85, train_fscore: 77.64, valid_loss: 6.52400016784668, valid_acc: 72.29, valid_fscore: 72.97, test_loss: 7.7565999031066895, test_acc: 68.27, test_fscore: 68.69, time: 2.86 sec
epoch: 36, train_loss: 7.502999782562256, train_acc: 78.12, train_fscore: 77.95, valid_loss: 6.533199787139893, valid_acc: 71.39, valid_fscore: 72.32, test_loss: 7.709400177001953, test_acc: 68.33, test_fscore: 68.94, time: 2.87 sec
epoch: 37, train_loss: 7.46750020980835, train_acc: 79.11, train_fscore: 79.01, valid_loss: 6.518099784851074, valid_acc: 71.23, valid_fscore: 72.68, test_loss: 7.713900089263916, test_acc: 65.8, test_fscore: 66.48, time: 2.73 sec
epoch: 38, train_loss: 7.441800117492676, train_acc: 78.94, train_fscore: 78.75, valid_loss: 6.480100154876709, valid_acc: 71.54, valid_fscore: 72.77, test_loss: 7.672500133514404, test_acc: 67.34, test_fscore: 67.98, time: 3.79 sec
epoch: 39, train_loss: 7.401100158691406, train_acc: 79.13, train_fscore: 78.97, valid_loss: 6.533999919891357, valid_acc: 71.23, valid_fscore: 72.24, test_loss: 7.622499942779541, test_acc: 68.7, test_fscore: 69.16, time: 2.86 sec
epoch: 40, train_loss: 7.414400100708008, train_acc: 79.13, train_fscore: 78.96, valid_loss: 6.5304999351501465, valid_acc: 71.23, valid_fscore: 72.47, test_loss: 7.634200096130371, test_acc: 67.34, test_fscore: 67.96, time: 2.79 sec
              precision    recall  f1-score   support

           0     0.4280    0.7222    0.5375     144.0
           1     0.7957    0.7469    0.7705     245.0
           2     0.6994    0.6302    0.6630     384.0
           3     0.6058    0.7412    0.6667     170.0
           4     0.8767    0.6421    0.7413     299.0
           5     0.6525    0.6457    0.6491     381.0

    accuracy                         0.6734    1623.0
   macro avg     0.6763    0.6881    0.6713    1623.0
weighted avg     0.7017    0.6734    0.6796    1623.0

[[104.   7.  15.   0.  16.   2.]
 [  3. 183.  23.   2.   0.  34.]
 [ 43.  24. 242.  18.   5.  52.]
 [  0.   0.   3. 126.   0.  41.]
 [ 93.   0.  12.   0. 192.   2.]
 [  0.  16.  51.  62.   6. 246.]]
epoch: 41, train_loss: 7.3790998458862305, train_acc: 79.69, train_fscore: 79.53, valid_loss: 6.56279993057251, valid_acc: 69.73, valid_fscore: 71.77, test_loss: 7.729400157928467, test_acc: 66.3, test_fscore: 66.98, time: 2.74 sec
epoch: 42, train_loss: 7.3471999168396, train_acc: 79.58, train_fscore: 79.55, valid_loss: 6.4517998695373535, valid_acc: 72.74, valid_fscore: 73.59, test_loss: 7.655300140380859, test_acc: 68.15, test_fscore: 68.67, time: 2.87 sec
epoch: 43, train_loss: 7.30019998550415, train_acc: 80.65, train_fscore: 80.49, valid_loss: 6.504799842834473, valid_acc: 72.44, valid_fscore: 73.21, test_loss: 7.593599796295166, test_acc: 69.07, test_fscore: 69.54, time: 2.81 sec
epoch: 44, train_loss: 7.261300086975098, train_acc: 80.2, train_fscore: 80.03, valid_loss: 6.583199977874756, valid_acc: 70.93, valid_fscore: 72.42, test_loss: 7.647299766540527, test_acc: 67.71, test_fscore: 68.34, time: 2.78 sec
epoch: 45, train_loss: 7.282199859619141, train_acc: 80.61, train_fscore: 80.54, valid_loss: 6.482699871063232, valid_acc: 72.74, valid_fscore: 73.71, test_loss: 7.631899833679199, test_acc: 67.22, test_fscore: 67.86, time: 2.89 sec
epoch: 46, train_loss: 7.251800060272217, train_acc: 80.84, train_fscore: 80.75, valid_loss: 6.4604997634887695, valid_acc: 72.89, valid_fscore: 73.51, test_loss: 7.577400207519531, test_acc: 68.64, test_fscore: 69.13, time: 2.82 sec
epoch: 47, train_loss: 7.2546000480651855, train_acc: 81.75, train_fscore: 81.6, valid_loss: 6.5218000411987305, valid_acc: 71.23, valid_fscore: 72.56, test_loss: 7.6092000007629395, test_acc: 68.08, test_fscore: 68.7, time: 3.89 sec
epoch: 48, train_loss: 7.221199989318848, train_acc: 81.03, train_fscore: 80.91, valid_loss: 6.543399810791016, valid_acc: 71.84, valid_fscore: 73.09, test_loss: 7.628399848937988, test_acc: 67.53, test_fscore: 68.15, time: 3.62 sec
epoch: 49, train_loss: 7.203000068664551, train_acc: 81.64, train_fscore: 81.54, valid_loss: 6.521500110626221, valid_acc: 72.14, valid_fscore: 72.91, test_loss: 7.577899932861328, test_acc: 68.39, test_fscore: 68.93, time: 2.95 sec
epoch: 50, train_loss: 7.1458001136779785, train_acc: 82.16, train_fscore: 82.04, valid_loss: 6.514900207519531, valid_acc: 71.99, valid_fscore: 73.07, test_loss: 7.534299850463867, test_acc: 68.33, test_fscore: 68.92, time: 2.88 sec
              precision    recall  f1-score   support

           0     0.4476    0.7708    0.5663     144.0
           1     0.8122    0.7592    0.7848     245.0
           2     0.7214    0.6406    0.6786     384.0
           3     0.6162    0.7176    0.6630     170.0
           4     0.8739    0.6488    0.7447     299.0
           5     0.6494    0.6562    0.6527     381.0

    accuracy                         0.6833    1623.0
   macro avg     0.6868    0.6989    0.6817    1623.0
weighted avg     0.7110    0.6833    0.6892    1623.0

[[111.   5.  11.   0.  15.   2.]
 [  2. 186.  20.   2.   1.  34.]
 [ 43.  23. 246.  13.   5.  54.]
 [  0.   0.   5. 122.   0.  43.]
 [ 91.   0.  12.   0. 194.   2.]
 [  1.  15.  47.  61.   7. 250.]]
epoch: 51, train_loss: 7.157299995422363, train_acc: 82.08, train_fscore: 81.96, valid_loss: 6.522799968719482, valid_acc: 71.84, valid_fscore: 73.08, test_loss: 7.5569000244140625, test_acc: 67.59, test_fscore: 68.17, time: 2.66 sec
epoch: 52, train_loss: 7.149799823760986, train_acc: 81.89, train_fscore: 81.73, valid_loss: 6.496200084686279, valid_acc: 73.19, valid_fscore: 74.06, test_loss: 7.58050012588501, test_acc: 68.45, test_fscore: 69.0, time: 2.85 sec
epoch: 53, train_loss: 7.110000133514404, train_acc: 82.26, train_fscore: 82.13, valid_loss: 6.518400192260742, valid_acc: 72.44, valid_fscore: 73.34, test_loss: 7.576399803161621, test_acc: 69.01, test_fscore: 69.6, time: 2.86 sec
epoch: 54, train_loss: 7.0802998542785645, train_acc: 82.63, train_fscore: 82.55, valid_loss: 6.530900001525879, valid_acc: 72.59, valid_fscore: 73.57, test_loss: 7.545899868011475, test_acc: 68.64, test_fscore: 69.23, time: 2.71 sec
epoch: 55, train_loss: 7.048500061035156, train_acc: 82.69, train_fscore: 82.54, valid_loss: 6.545199871063232, valid_acc: 72.59, valid_fscore: 73.69, test_loss: 7.553699970245361, test_acc: 67.84, test_fscore: 68.43, time: 2.92 sec
epoch: 56, train_loss: 7.045300006866455, train_acc: 83.52, train_fscore: 83.44, valid_loss: 6.527900218963623, valid_acc: 73.34, valid_fscore: 74.24, test_loss: 7.587399959564209, test_acc: 68.21, test_fscore: 68.74, time: 2.79 sec
epoch: 57, train_loss: 7.025000095367432, train_acc: 83.15, train_fscore: 83.06, valid_loss: 6.532100200653076, valid_acc: 73.8, valid_fscore: 74.68, test_loss: 7.600900173187256, test_acc: 68.52, test_fscore: 69.02, time: 2.81 sec
epoch: 58, train_loss: 6.9980998039245605, train_acc: 83.46, train_fscore: 83.32, valid_loss: 6.5507001876831055, valid_acc: 72.59, valid_fscore: 73.78, test_loss: 7.586599826812744, test_acc: 68.76, test_fscore: 69.29, time: 2.7 sec
epoch: 59, train_loss: 6.968100070953369, train_acc: 83.85, train_fscore: 83.76, valid_loss: 6.536900043487549, valid_acc: 73.04, valid_fscore: 73.97, test_loss: 7.572400093078613, test_acc: 67.96, test_fscore: 68.53, time: 3.5 sec
epoch: 60, train_loss: 6.979700088500977, train_acc: 83.73, train_fscore: 83.64, valid_loss: 6.550600051879883, valid_acc: 73.04, valid_fscore: 73.94, test_loss: 7.542699813842773, test_acc: 68.88, test_fscore: 69.45, time: 3.22 sec
              precision    recall  f1-score   support

           0     0.4609    0.7361    0.5668     144.0
           1     0.8380    0.7388    0.7852     245.0
           2     0.6842    0.6771    0.6806     384.0
           3     0.6417    0.7059    0.6723     170.0
           4     0.8734    0.6689    0.7576     299.0
           5     0.6588    0.6588    0.6588     381.0

    accuracy                         0.6888    1623.0
   macro avg     0.6928    0.6976    0.6869    1623.0
weighted avg     0.7120    0.6888    0.6945    1623.0

[[106.   4.  15.   0.  18.   1.]
 [  2. 181.  24.   1.   1.  36.]
 [ 42.  18. 260.  12.   5.  47.]
 [  0.   0.   6. 120.   0.  44.]
 [ 79.   0.  18.   0. 200.   2.]
 [  1.  13.  57.  54.   5. 251.]]
epoch: 61, train_loss: 6.971799850463867, train_acc: 84.05, train_fscore: 83.95, valid_loss: 6.568399906158447, valid_acc: 72.74, valid_fscore: 73.89, test_loss: 7.592599868774414, test_acc: 68.27, test_fscore: 68.8, time: 2.65 sec
epoch: 62, train_loss: 6.9644999504089355, train_acc: 83.93, train_fscore: 83.84, valid_loss: 6.542799949645996, valid_acc: 73.34, valid_fscore: 74.2, test_loss: 7.587800025939941, test_acc: 68.21, test_fscore: 68.73, time: 2.71 sec
epoch: 63, train_loss: 6.912199974060059, train_acc: 84.96, train_fscore: 84.85, valid_loss: 6.507699966430664, valid_acc: 73.95, valid_fscore: 74.37, test_loss: 7.5106000900268555, test_acc: 69.38, test_fscore: 69.83, time: 3.88 sec
epoch: 64, train_loss: 6.906300067901611, train_acc: 85.13, train_fscore: 85.03, valid_loss: 6.557199954986572, valid_acc: 72.29, valid_fscore: 73.39, test_loss: 7.572199821472168, test_acc: 68.52, test_fscore: 69.07, time: 2.69 sec
epoch: 65, train_loss: 6.879300117492676, train_acc: 84.78, train_fscore: 84.69, valid_loss: 6.55620002746582, valid_acc: 72.74, valid_fscore: 73.73, test_loss: 7.59060001373291, test_acc: 68.82, test_fscore: 69.33, time: 3.86 sec
epoch: 66, train_loss: 6.872900009155273, train_acc: 85.35, train_fscore: 85.29, valid_loss: 6.554100036621094, valid_acc: 72.59, valid_fscore: 73.5, test_loss: 7.5671000480651855, test_acc: 69.56, test_fscore: 70.06, time: 4.35 sec
epoch: 67, train_loss: 6.872700214385986, train_acc: 84.9, train_fscore: 84.8, valid_loss: 6.5447001457214355, valid_acc: 73.49, valid_fscore: 74.26, test_loss: 7.555099964141846, test_acc: 68.95, test_fscore: 69.42, time: 2.99 sec
epoch: 68, train_loss: 6.847300052642822, train_acc: 85.31, train_fscore: 85.2, valid_loss: 6.540299892425537, valid_acc: 72.89, valid_fscore: 73.76, test_loss: 7.559100151062012, test_acc: 68.27, test_fscore: 68.82, time: 3.73 sec
epoch: 69, train_loss: 6.844799995422363, train_acc: 85.7, train_fscore: 85.62, valid_loss: 6.526500225067139, valid_acc: 73.34, valid_fscore: 74.16, test_loss: 7.585299968719482, test_acc: 68.45, test_fscore: 68.96, time: 2.83 sec
epoch: 70, train_loss: 6.825200080871582, train_acc: 85.74, train_fscore: 85.63, valid_loss: 6.547900199890137, valid_acc: 73.49, valid_fscore: 74.27, test_loss: 7.574100017547607, test_acc: 69.13, test_fscore: 69.6, time: 2.8 sec
              precision    recall  f1-score   support

           0     0.4664    0.7708    0.5812     144.0
           1     0.8166    0.7633    0.7890     245.0
           2     0.6851    0.7083    0.6965     384.0
           3     0.6402    0.7118    0.6741     170.0
           4     0.8905    0.6254    0.7348     299.0
           5     0.6778    0.6404    0.6586     381.0

    accuracy                         0.6913    1623.0
   macro avg     0.6961    0.7033    0.6890    1623.0
weighted avg     0.7170    0.6913    0.6960    1623.0

[[111.   4.  16.   0.  12.   1.]
 [  2. 187.  22.   1.   1.  32.]
 [ 36.  23. 272.  11.   4.  38.]
 [  0.   0.   5. 121.   0.  44.]
 [ 88.   1.  22.   0. 187.   1.]
 [  1.  14.  60.  56.   6. 244.]]
epoch: 71, train_loss: 6.8379998207092285, train_acc: 85.79, train_fscore: 85.72, valid_loss: 6.603099822998047, valid_acc: 71.84, valid_fscore: 72.72, test_loss: 7.590700149536133, test_acc: 69.38, test_fscore: 69.98, time: 2.79 sec
epoch: 72, train_loss: 6.811399936676025, train_acc: 85.99, train_fscore: 85.9, valid_loss: 6.582699775695801, valid_acc: 73.64, valid_fscore: 74.38, test_loss: 7.617800235748291, test_acc: 68.7, test_fscore: 69.23, time: 2.86 sec
epoch: 73, train_loss: 6.787099838256836, train_acc: 86.36, train_fscore: 86.25, valid_loss: 6.563899993896484, valid_acc: 73.49, valid_fscore: 74.39, test_loss: 7.628399848937988, test_acc: 69.01, test_fscore: 69.47, time: 3.32 sec
epoch: 74, train_loss: 6.768099784851074, train_acc: 86.55, train_fscore: 86.45, valid_loss: 6.629000186920166, valid_acc: 72.74, valid_fscore: 73.63, test_loss: 7.666200160980225, test_acc: 68.21, test_fscore: 68.7, time: 2.35 sec
epoch: 75, train_loss: 6.755000114440918, train_acc: 86.77, train_fscore: 86.7, valid_loss: 6.635799884796143, valid_acc: 72.59, valid_fscore: 73.63, test_loss: 7.6757001876831055, test_acc: 68.76, test_fscore: 69.31, time: 2.83 sec
epoch: 76, train_loss: 6.718500137329102, train_acc: 86.63, train_fscore: 86.53, valid_loss: 6.568299770355225, valid_acc: 73.95, valid_fscore: 74.45, test_loss: 7.633399963378906, test_acc: 69.69, test_fscore: 70.16, time: 3.02 sec
epoch: 77, train_loss: 6.7266998291015625, train_acc: 86.46, train_fscore: 86.36, valid_loss: 6.608399868011475, valid_acc: 73.34, valid_fscore: 74.01, test_loss: 7.629700183868408, test_acc: 68.76, test_fscore: 69.25, time: 2.68 sec
epoch: 78, train_loss: 6.718999862670898, train_acc: 87.56, train_fscore: 87.5, valid_loss: 6.6265997886657715, valid_acc: 73.04, valid_fscore: 73.8, test_loss: 7.57289981842041, test_acc: 69.69, test_fscore: 70.19, time: 2.77 sec
epoch: 79, train_loss: 6.702000141143799, train_acc: 86.61, train_fscore: 86.5, valid_loss: 6.582600116729736, valid_acc: 73.8, valid_fscore: 74.38, test_loss: 7.607500076293945, test_acc: 69.56, test_fscore: 70.03, time: 2.69 sec
epoch: 80, train_loss: 6.6975998878479, train_acc: 87.19, train_fscore: 87.1, valid_loss: 6.603600025177002, valid_acc: 73.64, valid_fscore: 74.29, test_loss: 7.731400012969971, test_acc: 68.58, test_fscore: 69.03, time: 2.87 sec
              precision    recall  f1-score   support

           0     0.4538    0.7500    0.5654     144.0
           1     0.8267    0.7592    0.7915     245.0
           2     0.6716    0.7083    0.6895     384.0
           3     0.6425    0.7294    0.6832     170.0
           4     0.8794    0.5853    0.7028     299.0
           5     0.6832    0.6509    0.6667     381.0

    accuracy                         0.6858    1623.0
   macro avg     0.6929    0.6972    0.6832    1623.0
weighted avg     0.7136    0.6858    0.6903    1623.0

[[108.   4.  16.   0.  15.   1.]
 [  3. 186.  23.   2.   0.  31.]
 [ 37.  21. 272.  10.   4.  40.]
 [  0.   0.   5. 124.   0.  41.]
 [ 89.   1.  32.   0. 175.   2.]
 [  1.  13.  57.  57.   5. 248.]]
epoch: 81, train_loss: 6.688499927520752, train_acc: 87.41, train_fscore: 87.33, valid_loss: 6.6697998046875, valid_acc: 72.29, valid_fscore: 72.75, test_loss: 7.579100131988525, test_acc: 70.49, test_fscore: 70.98, time: 2.83 sec
epoch: 82, train_loss: 6.655300140380859, train_acc: 87.66, train_fscore: 87.56, valid_loss: 6.666600227355957, valid_acc: 73.19, valid_fscore: 74.09, test_loss: 7.619699954986572, test_acc: 69.25, test_fscore: 69.82, time: 2.85 sec
epoch: 83, train_loss: 6.664700031280518, train_acc: 87.41, train_fscore: 87.33, valid_loss: 6.6631999015808105, valid_acc: 72.74, valid_fscore: 74.0, test_loss: 7.729800224304199, test_acc: 68.33, test_fscore: 68.74, time: 2.39 sec
epoch: 84, train_loss: 6.6321001052856445, train_acc: 87.58, train_fscore: 87.48, valid_loss: 6.654300212860107, valid_acc: 73.34, valid_fscore: 73.87, test_loss: 7.642499923706055, test_acc: 70.98, test_fscore: 71.39, time: 2.51 sec
epoch: 85, train_loss: 6.631100177764893, train_acc: 87.8, train_fscore: 87.72, valid_loss: 6.692200183868408, valid_acc: 72.44, valid_fscore: 73.25, test_loss: 7.59119987487793, test_acc: 70.3, test_fscore: 70.8, time: 2.79 sec
epoch: 86, train_loss: 6.593599796295166, train_acc: 87.58, train_fscore: 87.5, valid_loss: 6.692800045013428, valid_acc: 73.64, valid_fscore: 74.47, test_loss: 7.660099983215332, test_acc: 68.64, test_fscore: 69.11, time: 2.71 sec
epoch: 87, train_loss: 6.594900131225586, train_acc: 87.95, train_fscore: 87.83, valid_loss: 6.6682000160217285, valid_acc: 73.49, valid_fscore: 74.08, test_loss: 7.643799781799316, test_acc: 70.43, test_fscore: 70.9, time: 2.81 sec
epoch: 88, train_loss: 6.600500106811523, train_acc: 88.13, train_fscore: 88.06, valid_loss: 6.712100028991699, valid_acc: 72.74, valid_fscore: 73.63, test_loss: 7.690999984741211, test_acc: 69.62, test_fscore: 70.07, time: 3.68 sec
epoch: 89, train_loss: 6.586400032043457, train_acc: 87.68, train_fscore: 87.59, valid_loss: 6.744200229644775, valid_acc: 72.29, valid_fscore: 73.06, test_loss: 7.658699989318848, test_acc: 69.5, test_fscore: 69.97, time: 3.27 sec
epoch: 90, train_loss: 6.571499824523926, train_acc: 88.81, train_fscore: 88.71, valid_loss: 6.707799911499023, valid_acc: 72.89, valid_fscore: 73.44, test_loss: 7.67519998550415, test_acc: 70.12, test_fscore: 70.56, time: 2.38 sec
              precision    recall  f1-score   support

           0     0.4885    0.7361    0.5873     144.0
           1     0.8304    0.7592    0.7932     245.0
           2     0.6943    0.6979    0.6961     384.0
           3     0.6576    0.7118    0.6836     170.0
           4     0.8750    0.6555    0.7495     299.0
           5     0.6727    0.6850    0.6788     381.0

    accuracy                         0.7012    1623.0
   macro avg     0.7031    0.7076    0.6981    1623.0
weighted avg     0.7209    0.7012    0.7056    1623.0

[[106.   4.  15.   0.  18.   1.]
 [  2. 186.  23.   2.   0.  32.]
 [ 34.  20. 268.  10.   4.  48.]
 [  0.   0.   5. 121.   0.  44.]
 [ 75.   2.  24.   0. 196.   2.]
 [  0.  12.  51.  51.   6. 261.]]
epoch: 91, train_loss: 6.55709981918335, train_acc: 88.94, train_fscore: 88.89, valid_loss: 6.69350004196167, valid_acc: 73.04, valid_fscore: 73.9, test_loss: 7.715099811553955, test_acc: 68.82, test_fscore: 69.29, time: 2.89 sec
epoch: 92, train_loss: 6.546199798583984, train_acc: 88.81, train_fscore: 88.72, valid_loss: 6.7459001541137695, valid_acc: 73.49, valid_fscore: 74.01, test_loss: 7.690999984741211, test_acc: 69.56, test_fscore: 70.04, time: 2.83 sec
epoch: 93, train_loss: 6.504000186920166, train_acc: 89.39, train_fscore: 89.33, valid_loss: 6.734399795532227, valid_acc: 73.95, valid_fscore: 74.25, test_loss: 7.659800052642822, test_acc: 70.67, test_fscore: 71.07, time: 3.5 sec
epoch: 94, train_loss: 6.543300151824951, train_acc: 89.21, train_fscore: 89.14, valid_loss: 6.7179999351501465, valid_acc: 74.85, valid_fscore: 75.27, test_loss: 7.717899799346924, test_acc: 68.82, test_fscore: 69.28, time: 2.95 sec
epoch: 95, train_loss: 6.513400077819824, train_acc: 89.45, train_fscore: 89.37, valid_loss: 6.744200229644775, valid_acc: 73.95, valid_fscore: 74.5, test_loss: 7.712699890136719, test_acc: 69.69, test_fscore: 70.15, time: 2.75 sec
epoch: 96, train_loss: 6.522500038146973, train_acc: 89.04, train_fscore: 88.97, valid_loss: 6.757800102233887, valid_acc: 73.95, valid_fscore: 74.18, test_loss: 7.677599906921387, test_acc: 70.86, test_fscore: 71.19, time: 2.83 sec
epoch: 97, train_loss: 6.501500129699707, train_acc: 89.23, train_fscore: 89.14, valid_loss: 6.739200115203857, valid_acc: 73.19, valid_fscore: 73.85, test_loss: 7.763899803161621, test_acc: 68.7, test_fscore: 69.18, time: 3.69 sec
epoch: 98, train_loss: 6.491199970245361, train_acc: 89.62, train_fscore: 89.57, valid_loss: 6.76609992980957, valid_acc: 73.49, valid_fscore: 74.07, test_loss: 7.785200119018555, test_acc: 69.44, test_fscore: 69.95, time: 3.7 sec
epoch: 99, train_loss: 6.4766998291015625, train_acc: 89.9, train_fscore: 89.82, valid_loss: 6.747399806976318, valid_acc: 73.8, valid_fscore: 74.11, test_loss: 7.752299785614014, test_acc: 70.06, test_fscore: 70.41, time: 2.81 sec
epoch: 100, train_loss: 6.472499847412109, train_acc: 89.9, train_fscore: 89.82, valid_loss: 6.79640007019043, valid_acc: 72.89, valid_fscore: 73.65, test_loss: 7.73769998550415, test_acc: 69.93, test_fscore: 70.39, time: 3.2 sec
              precision    recall  f1-score   support

           0     0.4669    0.7847    0.5855     144.0
           1     0.8356    0.7673    0.8000     245.0
           2     0.6987    0.7188    0.7086     384.0
           3     0.6761    0.7000    0.6879     170.0
           4     0.8950    0.5987    0.7174     299.0
           5     0.6753    0.6824    0.6789     381.0

    accuracy                         0.6993    1623.0
   macro avg     0.7079    0.7086    0.6964    1623.0
weighted avg     0.7271    0.6993    0.7039    1623.0

[[113.   4.  14.   0.  12.   1.]
 [  3. 188.  21.   2.   0.  31.]
 [ 33.  20. 276.   5.   3.  47.]
 [  0.   0.   6. 119.   0.  45.]
 [ 93.   1.  25.   0. 179.   1.]
 [  0.  12.  53.  50.   6. 260.]]
epoch: 101, train_loss: 6.438499927520752, train_acc: 90.19, train_fscore: 90.14, valid_loss: 6.784299850463867, valid_acc: 73.19, valid_fscore: 73.74, test_loss: 7.698699951171875, test_acc: 69.87, test_fscore: 70.2, time: 2.48 sec
epoch: 102, train_loss: 6.428999900817871, train_acc: 89.99, train_fscore: 89.91, valid_loss: 6.732999801635742, valid_acc: 73.8, valid_fscore: 74.29, test_loss: 7.735199928283691, test_acc: 69.87, test_fscore: 70.33, time: 2.63 sec
epoch: 103, train_loss: 6.438899993896484, train_acc: 90.13, train_fscore: 90.07, valid_loss: 6.755799770355225, valid_acc: 74.1, valid_fscore: 74.65, test_loss: 7.7322001457214355, test_acc: 70.18, test_fscore: 70.68, time: 2.76 sec
epoch: 104, train_loss: 6.426000118255615, train_acc: 90.03, train_fscore: 89.97, valid_loss: 6.772500038146973, valid_acc: 74.1, valid_fscore: 74.28, test_loss: 7.667699813842773, test_acc: 71.23, test_fscore: 71.53, time: 3.61 sec
epoch: 105, train_loss: 6.406599998474121, train_acc: 90.89, train_fscore: 90.81, valid_loss: 6.798099994659424, valid_acc: 74.1, valid_fscore: 74.38, test_loss: 7.667900085449219, test_acc: 71.23, test_fscore: 71.55, time: 2.89 sec
epoch: 106, train_loss: 6.397600173950195, train_acc: 90.52, train_fscore: 90.45, valid_loss: 6.780399799346924, valid_acc: 73.19, valid_fscore: 73.97, test_loss: 7.744500160217285, test_acc: 69.5, test_fscore: 69.89, time: 2.81 sec
epoch: 107, train_loss: 6.407800197601318, train_acc: 90.48, train_fscore: 90.4, valid_loss: 6.789000034332275, valid_acc: 74.55, valid_fscore: 74.96, test_loss: 7.7692999839782715, test_acc: 69.56, test_fscore: 70.08, time: 2.77 sec
epoch: 108, train_loss: 6.364299774169922, train_acc: 91.33, train_fscore: 91.29, valid_loss: 6.792799949645996, valid_acc: 74.55, valid_fscore: 74.84, test_loss: 7.7957000732421875, test_acc: 70.49, test_fscore: 70.88, time: 2.79 sec
epoch: 109, train_loss: 6.371099948883057, train_acc: 90.96, train_fscore: 90.9, valid_loss: 6.7957000732421875, valid_acc: 74.7, valid_fscore: 75.02, test_loss: 7.788000106811523, test_acc: 70.06, test_fscore: 70.37, time: 2.86 sec
epoch: 110, train_loss: 6.361700057983398, train_acc: 91.2, train_fscore: 91.12, valid_loss: 6.873799800872803, valid_acc: 73.64, valid_fscore: 74.04, test_loss: 7.759300231933594, test_acc: 71.04, test_fscore: 71.43, time: 2.74 sec
              precision    recall  f1-score   support

           0     0.4976    0.7222    0.5892     144.0
           1     0.8447    0.7551    0.7974     245.0
           2     0.7065    0.7396    0.7226     384.0
           3     0.6740    0.7176    0.6952     170.0
           4     0.8596    0.6555    0.7438     299.0
           5     0.6823    0.6877    0.6850     381.0

    accuracy                         0.7104    1623.0
   macro avg     0.7108    0.7130    0.7055    1623.0
weighted avg     0.7280    0.7104    0.7143    1623.0

[[104.   3.  15.   0.  21.   1.]
 [  3. 185.  23.   1.   1.  32.]
 [ 26.  19. 284.   7.   4.  44.]
 [  0.   0.   4. 122.   0.  44.]
 [ 76.   1.  25.   0. 196.   1.]
 [  0.  11.  51.  51.   6. 262.]]
epoch: 111, train_loss: 6.335400104522705, train_acc: 91.22, train_fscore: 91.17, valid_loss: 6.904099941253662, valid_acc: 73.04, valid_fscore: 73.51, test_loss: 7.82420015335083, test_acc: 70.06, test_fscore: 70.37, time: 3.74 sec
epoch: 112, train_loss: 6.348700046539307, train_acc: 91.0, train_fscore: 90.94, valid_loss: 6.872799873352051, valid_acc: 74.4, valid_fscore: 74.81, test_loss: 7.837900161743164, test_acc: 69.87, test_fscore: 70.33, time: 4.46 sec
epoch: 113, train_loss: 6.32889986038208, train_acc: 91.62, train_fscore: 91.59, valid_loss: 6.801499843597412, valid_acc: 75.0, valid_fscore: 75.08, test_loss: 7.803100109100342, test_acc: 70.98, test_fscore: 71.33, time: 2.53 sec
epoch: 114, train_loss: 6.328700065612793, train_acc: 91.62, train_fscore: 91.55, valid_loss: 6.794400215148926, valid_acc: 74.7, valid_fscore: 74.87, test_loss: 7.8302001953125, test_acc: 70.18, test_fscore: 70.44, time: 2.26 sec
epoch: 115, train_loss: 6.309999942779541, train_acc: 91.78, train_fscore: 91.72, valid_loss: 6.861100196838379, valid_acc: 73.49, valid_fscore: 73.96, test_loss: 7.864999771118164, test_acc: 69.75, test_fscore: 70.0, time: 2.05 sec
epoch: 116, train_loss: 6.304500102996826, train_acc: 91.86, train_fscore: 91.82, valid_loss: 6.835999965667725, valid_acc: 74.1, valid_fscore: 74.5, test_loss: 7.839799880981445, test_acc: 69.87, test_fscore: 70.23, time: 1.97 sec
epoch: 117, train_loss: 6.3105998039245605, train_acc: 91.04, train_fscore: 90.97, valid_loss: 6.879700183868408, valid_acc: 74.7, valid_fscore: 74.85, test_loss: 7.84630012512207, test_acc: 70.24, test_fscore: 70.59, time: 1.99 sec
epoch: 118, train_loss: 6.312900066375732, train_acc: 91.68, train_fscore: 91.64, valid_loss: 6.894000053405762, valid_acc: 74.25, valid_fscore: 74.47, test_loss: 7.867599964141846, test_acc: 70.61, test_fscore: 70.92, time: 1.91 sec
epoch: 119, train_loss: 6.298600196838379, train_acc: 91.84, train_fscore: 91.77, valid_loss: 6.878900051116943, valid_acc: 73.95, valid_fscore: 74.35, test_loss: 7.852700233459473, test_acc: 69.5, test_fscore: 69.88, time: 2.23 sec
epoch: 120, train_loss: 6.273600101470947, train_acc: 91.51, train_fscore: 91.45, valid_loss: 6.915999889373779, valid_acc: 75.0, valid_fscore: 75.25, test_loss: 7.830399990081787, test_acc: 70.43, test_fscore: 70.72, time: 2.06 sec
              precision    recall  f1-score   support

           0     0.5122    0.7292    0.6017     144.0
           1     0.8333    0.7551    0.7923     245.0
           2     0.6797    0.7682    0.7213     384.0
           3     0.6667    0.7176    0.6912     170.0
           4     0.8791    0.6321    0.7354     299.0
           5     0.6786    0.6483    0.6631     381.0

    accuracy                         0.7043    1623.0
   macro avg     0.7083    0.7084    0.7008    1623.0
weighted avg     0.7231    0.7043    0.7072    1623.0

[[105.   4.  17.   0.  17.   1.]
 [  2. 185.  25.   1.   0.  32.]
 [ 22.  18. 295.   4.   4.  41.]
 [  0.   0.   6. 122.   0.  42.]
 [ 76.   1.  32.   0. 189.   1.]
 [  0.  14.  59.  56.   5. 247.]]
epoch: 121, train_loss: 6.288099765777588, train_acc: 92.13, train_fscore: 92.08, valid_loss: 6.912799835205078, valid_acc: 75.15, valid_fscore: 75.36, test_loss: 7.840199947357178, test_acc: 70.43, test_fscore: 70.64, time: 2.0 sec
epoch: 122, train_loss: 6.271299839019775, train_acc: 92.36, train_fscore: 92.31, valid_loss: 6.967899799346924, valid_acc: 74.25, valid_fscore: 74.56, test_loss: 7.821800231933594, test_acc: 71.6, test_fscore: 71.96, time: 1.94 sec
epoch: 123, train_loss: 6.248700141906738, train_acc: 92.05, train_fscore: 92.01, valid_loss: 6.970200061798096, valid_acc: 73.34, valid_fscore: 73.68, test_loss: 7.835400104522705, test_acc: 70.92, test_fscore: 71.27, time: 1.92 sec
epoch: 124, train_loss: 6.233500003814697, train_acc: 92.21, train_fscore: 92.14, valid_loss: 6.937099933624268, valid_acc: 74.7, valid_fscore: 75.1, test_loss: 7.925300121307373, test_acc: 70.49, test_fscore: 70.75, time: 2.05 sec
epoch: 125, train_loss: 6.234099864959717, train_acc: 92.15, train_fscore: 92.1, valid_loss: 7.010300159454346, valid_acc: 73.04, valid_fscore: 73.4, test_loss: 7.929599761962891, test_acc: 70.3, test_fscore: 70.64, time: 1.91 sec
epoch: 126, train_loss: 6.2256999015808105, train_acc: 92.81, train_fscore: 92.78, valid_loss: 7.020299911499023, valid_acc: 73.95, valid_fscore: 74.18, test_loss: 7.857600212097168, test_acc: 70.61, test_fscore: 70.95, time: 1.98 sec
epoch: 127, train_loss: 6.2083001136779785, train_acc: 92.52, train_fscore: 92.46, valid_loss: 6.97160005569458, valid_acc: 74.25, valid_fscore: 74.49, test_loss: 7.892600059509277, test_acc: 70.67, test_fscore: 70.97, time: 1.9 sec
epoch: 128, train_loss: 6.196599960327148, train_acc: 93.26, train_fscore: 93.21, valid_loss: 7.014999866485596, valid_acc: 73.34, valid_fscore: 73.56, test_loss: 7.9004998207092285, test_acc: 70.24, test_fscore: 70.53, time: 1.95 sec
epoch: 129, train_loss: 6.2133002281188965, train_acc: 92.73, train_fscore: 92.68, valid_loss: 7.03000020980835, valid_acc: 73.34, valid_fscore: 73.57, test_loss: 7.9380998611450195, test_acc: 70.36, test_fscore: 70.67, time: 2.02 sec
epoch: 130, train_loss: 6.212399959564209, train_acc: 93.22, train_fscore: 93.18, valid_loss: 7.055300235748291, valid_acc: 74.1, valid_fscore: 74.17, test_loss: 7.911499977111816, test_acc: 70.92, test_fscore: 71.19, time: 1.97 sec
              precision    recall  f1-score   support

           0     0.5276    0.7292    0.6122     144.0
           1     0.8349    0.7429    0.7862     245.0
           2     0.6876    0.7682    0.7257     384.0
           3     0.6631    0.7294    0.6947     170.0
           4     0.8603    0.6589    0.7462     299.0
           5     0.6870    0.6509    0.6685     381.0

    accuracy                         0.7092    1623.0
   macro avg     0.7101    0.7132    0.7056    1623.0
weighted avg     0.7247    0.7092    0.7119    1623.0

[[105.   4.  14.   0.  20.   1.]
 [  2. 182.  26.   3.   2.  30.]
 [ 22.  18. 295.   4.   4.  41.]
 [  0.   0.   6. 124.   0.  40.]
 [ 70.   1.  30.   0. 197.   1.]
 [  0.  13.  58.  56.   6. 248.]]
epoch: 131, train_loss: 6.1921000480651855, train_acc: 92.6, train_fscore: 92.56, valid_loss: 7.034299850463867, valid_acc: 74.1, valid_fscore: 74.27, test_loss: 7.923099994659424, test_acc: 70.24, test_fscore: 70.51, time: 1.92 sec
epoch: 132, train_loss: 6.1732001304626465, train_acc: 92.77, train_fscore: 92.72, valid_loss: 7.049699783325195, valid_acc: 73.04, valid_fscore: 73.53, test_loss: 7.9741997718811035, test_acc: 69.81, test_fscore: 70.13, time: 2.34 sec
epoch: 133, train_loss: 6.1605000495910645, train_acc: 93.12, train_fscore: 93.07, valid_loss: 7.022799968719482, valid_acc: 72.74, valid_fscore: 72.81, test_loss: 7.910099983215332, test_acc: 70.55, test_fscore: 70.79, time: 1.91 sec
epoch: 134, train_loss: 6.148900032043457, train_acc: 93.41, train_fscore: 93.36, valid_loss: 6.994800090789795, valid_acc: 74.7, valid_fscore: 74.78, test_loss: 7.896699905395508, test_acc: 70.49, test_fscore: 70.76, time: 1.94 sec
epoch: 135, train_loss: 6.164299964904785, train_acc: 93.55, train_fscore: 93.5, valid_loss: 6.999499797821045, valid_acc: 73.49, valid_fscore: 73.96, test_loss: 7.958399772644043, test_acc: 69.69, test_fscore: 70.09, time: 2.11 sec
epoch: 136, train_loss: 6.149199962615967, train_acc: 92.93, train_fscore: 92.89, valid_loss: 7.077000141143799, valid_acc: 73.19, valid_fscore: 73.26, test_loss: 7.947400093078613, test_acc: 71.23, test_fscore: 71.47, time: 1.9 sec
epoch: 137, train_loss: 6.150599956512451, train_acc: 93.78, train_fscore: 93.76, valid_loss: 7.0335001945495605, valid_acc: 73.19, valid_fscore: 73.37, test_loss: 7.93149995803833, test_acc: 71.1, test_fscore: 71.34, time: 1.95 sec
epoch: 138, train_loss: 6.1367998123168945, train_acc: 93.61, train_fscore: 93.57, valid_loss: 7.023600101470947, valid_acc: 73.95, valid_fscore: 74.05, test_loss: 7.9319000244140625, test_acc: 70.24, test_fscore: 70.54, time: 1.98 sec
epoch: 139, train_loss: 6.111800193786621, train_acc: 93.53, train_fscore: 93.48, valid_loss: 7.115799903869629, valid_acc: 73.49, valid_fscore: 73.58, test_loss: 7.9741997718811035, test_acc: 70.79, test_fscore: 71.06, time: 1.99 sec
epoch: 140, train_loss: 6.1153998374938965, train_acc: 93.78, train_fscore: 93.75, valid_loss: 7.166200160980225, valid_acc: 72.74, valid_fscore: 72.99, test_loss: 8.02910041809082, test_acc: 70.61, test_fscore: 70.88, time: 1.94 sec
              precision    recall  f1-score   support

           0     0.5288    0.7639    0.6250     144.0
           1     0.8364    0.7510    0.7914     245.0
           2     0.6790    0.7656    0.7197     384.0
           3     0.6578    0.7235    0.6891     170.0
           4     0.8873    0.6321    0.7383     299.0
           5     0.6796    0.6457    0.6622     381.0

    accuracy                         0.7061    1623.0
   macro avg     0.7115    0.7136    0.7043    1623.0
weighted avg     0.7257    0.7061    0.7088    1623.0

[[110.   4.  14.   0.  15.   1.]
 [  2. 184.  26.   2.   0.  31.]
 [ 22.  18. 294.   4.   4.  42.]
 [  0.   0.   7. 123.   0.  40.]
 [ 74.   1.  33.   0. 189.   2.]
 [  0.  13.  59.  58.   5. 246.]]
epoch: 141, train_loss: 6.136099815368652, train_acc: 93.94, train_fscore: 93.91, valid_loss: 7.121699810028076, valid_acc: 72.89, valid_fscore: 73.08, test_loss: 8.037099838256836, test_acc: 70.18, test_fscore: 70.42, time: 1.99 sec
epoch: 142, train_loss: 6.0883002281188965, train_acc: 93.24, train_fscore: 93.19, valid_loss: 7.105000019073486, valid_acc: 73.34, valid_fscore: 73.43, test_loss: 8.072799682617188, test_acc: 70.06, test_fscore: 70.31, time: 1.97 sec
epoch: 143, train_loss: 6.122000217437744, train_acc: 93.96, train_fscore: 93.92, valid_loss: 7.031400203704834, valid_acc: 73.49, valid_fscore: 73.62, test_loss: 8.009200096130371, test_acc: 70.12, test_fscore: 70.38, time: 1.93 sec
epoch: 144, train_loss: 6.089300155639648, train_acc: 94.05, train_fscore: 94.02, valid_loss: 7.104700088500977, valid_acc: 73.95, valid_fscore: 74.14, test_loss: 7.979300022125244, test_acc: 70.98, test_fscore: 71.31, time: 1.95 sec
epoch: 145, train_loss: 6.092199802398682, train_acc: 94.01, train_fscore: 93.98, valid_loss: 7.058700084686279, valid_acc: 73.95, valid_fscore: 74.09, test_loss: 8.01729965209961, test_acc: 70.3, test_fscore: 70.55, time: 1.99 sec
epoch: 146, train_loss: 6.06879997253418, train_acc: 93.82, train_fscore: 93.78, valid_loss: 7.058300018310547, valid_acc: 73.34, valid_fscore: 73.43, test_loss: 8.024499893188477, test_acc: 70.61, test_fscore: 70.85, time: 1.96 sec
epoch: 147, train_loss: 6.082399845123291, train_acc: 94.13, train_fscore: 94.1, valid_loss: 7.076399803161621, valid_acc: 73.8, valid_fscore: 73.95, test_loss: 8.008999824523926, test_acc: 71.41, test_fscore: 71.69, time: 1.99 sec
epoch: 148, train_loss: 6.069499969482422, train_acc: 94.58, train_fscore: 94.55, valid_loss: 7.107800006866455, valid_acc: 74.4, valid_fscore: 74.41, test_loss: 8.011199951171875, test_acc: 70.61, test_fscore: 70.82, time: 1.94 sec
epoch: 149, train_loss: 6.065400123596191, train_acc: 94.68, train_fscore: 94.64, valid_loss: 7.1956000328063965, valid_acc: 73.19, valid_fscore: 73.44, test_loss: 8.020500183105469, test_acc: 71.16, test_fscore: 71.43, time: 1.92 sec
epoch: 150, train_loss: 6.065899848937988, train_acc: 94.64, train_fscore: 94.61, valid_loss: 7.136300086975098, valid_acc: 73.95, valid_fscore: 74.05, test_loss: 8.017800331115723, test_acc: 70.61, test_fscore: 70.84, time: 2.13 sec
              precision    recall  f1-score   support

           0     0.5300    0.7361    0.6163     144.0
           1     0.8282    0.7673    0.7966     245.0
           2     0.6751    0.7630    0.7164     384.0
           3     0.6480    0.7471    0.6940     170.0
           4     0.8739    0.6488    0.7447     299.0
           5     0.6919    0.6247    0.6566     381.0

    accuracy                         0.7061    1623.0
   macro avg     0.7078    0.7145    0.7041    1623.0
weighted avg     0.7231    0.7061    0.7084    1623.0

[[106.   4.  14.   0.  19.   1.]
 [  2. 188.  26.   3.   0.  26.]
 [ 24.  18. 293.   4.   4.  41.]
 [  0.   1.   6. 127.   0.  36.]
 [ 68.   3.  32.   0. 194.   2.]
 [  0.  13.  63.  62.   5. 238.]]
Best validation F-Score: 70.84
Test performance..
F-Score: 70.84
Accuracy: 70.61
Loss: 8.017800331115723
--- 5 ---
loss_mask: [True, True, True, True]
Namespace(no_cuda=False, lr=0.0001, l2=1e-05, dropout=0.5, batch_size=64, hidden_dim=1024, n_head=8, epochs=150, temp=2, tensorboard=False, class_weight=True, Dataset='IEMOCAP', loss_mask='1111')
Running on GPU
temp 2
total parameters: 97535000
training parameters: 97535000
epoch: 1, train_loss: 12.288599967956543, train_acc: 21.2, train_fscore: 21.14, valid_loss: 10.227999687194824, valid_acc: 31.63, valid_fscore: 25.92, test_loss: 11.218500137329102, test_acc: 35.43, test_fscore: 29.07, time: 3.64 sec
epoch: 2, train_loss: 11.597900390625, train_acc: 33.07, train_fscore: 29.56, valid_loss: 9.751799583435059, valid_acc: 43.52, valid_fscore: 43.11, test_loss: 10.748499870300293, test_acc: 42.64, test_fscore: 42.33, time: 2.01 sec
epoch: 3, train_loss: 11.095999717712402, train_acc: 47.88, train_fscore: 46.98, valid_loss: 9.232099533081055, valid_acc: 53.01, valid_fscore: 51.91, test_loss: 10.327300071716309, test_acc: 47.81, test_fscore: 46.18, time: 2.09 sec
epoch: 4, train_loss: 10.663200378417969, train_acc: 53.11, train_fscore: 50.93, valid_loss: 8.861100196838379, valid_acc: 58.13, valid_fscore: 58.19, test_loss: 10.011300086975098, test_acc: 53.67, test_fscore: 53.58, time: 1.99 sec
epoch: 5, train_loss: 10.353099822998047, train_acc: 57.95, train_fscore: 56.83, valid_loss: 8.577400207519531, valid_acc: 62.35, valid_fscore: 62.51, test_loss: 9.755800247192383, test_acc: 57.36, test_fscore: 57.26, time: 2.02 sec
epoch: 6, train_loss: 10.062100410461426, train_acc: 60.65, train_fscore: 59.69, valid_loss: 8.351200103759766, valid_acc: 64.31, valid_fscore: 64.69, test_loss: 9.587699890136719, test_acc: 58.72, test_fscore: 59.1, time: 1.95 sec
epoch: 7, train_loss: 9.73009967803955, train_acc: 62.67, train_fscore: 62.29, valid_loss: 8.142399787902832, valid_acc: 60.39, valid_fscore: 63.01, test_loss: 9.365500450134277, test_acc: 57.24, test_fscore: 57.65, time: 2.07 sec
epoch: 8, train_loss: 9.415399551391602, train_acc: 63.99, train_fscore: 63.75, valid_loss: 7.825200080871582, valid_acc: 64.91, valid_fscore: 66.24, test_loss: 9.048299789428711, test_acc: 57.98, test_fscore: 58.5, time: 1.96 sec
epoch: 9, train_loss: 9.13700008392334, train_acc: 65.92, train_fscore: 65.5, valid_loss: 7.415900230407715, valid_acc: 66.87, valid_fscore: 67.46, test_loss: 8.725199699401855, test_acc: 60.69, test_fscore: 61.23, time: 2.23 sec
epoch: 10, train_loss: 8.961999893188477, train_acc: 67.24, train_fscore: 66.74, valid_loss: 7.361100196838379, valid_acc: 68.37, valid_fscore: 69.64, test_loss: 8.652099609375, test_acc: 61.98, test_fscore: 63.01, time: 2.03 sec
              precision    recall  f1-score   support

           0     0.3298    0.6528    0.4382     144.0
           1     0.7843    0.6531    0.7127     245.0
           2     0.6119    0.5625    0.5862     384.0
           3     0.6082    0.6941    0.6484     170.0
           4     0.8186    0.5886    0.6848     299.0
           5     0.6505    0.6352    0.6428     381.0

    accuracy                         0.6198    1623.0
   macro avg     0.6339    0.6310    0.6188    1623.0
weighted avg     0.6597    0.6198    0.6301    1623.0

[[ 94.   7.  10.   2.  31.   0.]
 [ 16. 160.  40.   3.   0.  26.]
 [ 63.  24. 216.  20.   2.  59.]
 [  0.   0.   9. 118.   0.  43.]
 [102.   0.  17.   2. 176.   2.]
 [ 10.  13.  61.  49.   6. 242.]]
epoch: 11, train_loss: 8.847399711608887, train_acc: 68.6, train_fscore: 68.41, valid_loss: 7.330599784851074, valid_acc: 68.37, valid_fscore: 69.36, test_loss: 8.643600463867188, test_acc: 62.72, test_fscore: 63.75, time: 2.01 sec
epoch: 12, train_loss: 8.786600112915039, train_acc: 68.93, train_fscore: 68.77, valid_loss: 7.1483001708984375, valid_acc: 67.77, valid_fscore: 69.3, test_loss: 8.517399787902832, test_acc: 62.66, test_fscore: 63.74, time: 1.99 sec
epoch: 13, train_loss: 8.661700248718262, train_acc: 68.99, train_fscore: 68.85, valid_loss: 6.992800235748291, valid_acc: 69.13, valid_fscore: 70.24, test_loss: 8.368900299072266, test_acc: 62.05, test_fscore: 62.98, time: 2.06 sec
epoch: 14, train_loss: 8.604700088500977, train_acc: 68.54, train_fscore: 68.16, valid_loss: 6.901000022888184, valid_acc: 69.13, valid_fscore: 70.14, test_loss: 8.212400436401367, test_acc: 63.96, test_fscore: 64.71, time: 2.03 sec
epoch: 15, train_loss: 8.45740032196045, train_acc: 69.53, train_fscore: 69.07, valid_loss: 6.919600009918213, valid_acc: 68.37, valid_fscore: 69.97, test_loss: 8.197799682617188, test_acc: 63.22, test_fscore: 64.19, time: 1.98 sec
epoch: 16, train_loss: 8.413399696350098, train_acc: 70.13, train_fscore: 69.86, valid_loss: 6.865499973297119, valid_acc: 69.13, valid_fscore: 70.54, test_loss: 8.19789981842041, test_acc: 64.2, test_fscore: 65.0, time: 1.93 sec
epoch: 17, train_loss: 8.360899925231934, train_acc: 71.38, train_fscore: 71.03, valid_loss: 6.768400192260742, valid_acc: 70.18, valid_fscore: 71.37, test_loss: 8.181900024414062, test_acc: 64.7, test_fscore: 65.4, time: 1.92 sec
epoch: 18, train_loss: 8.280900001525879, train_acc: 71.71, train_fscore: 71.35, valid_loss: 6.69189977645874, valid_acc: 68.83, valid_fscore: 69.65, test_loss: 8.099300384521484, test_acc: 65.13, test_fscore: 65.85, time: 1.94 sec
epoch: 19, train_loss: 8.20110034942627, train_acc: 71.57, train_fscore: 71.13, valid_loss: 6.670199871063232, valid_acc: 68.98, valid_fscore: 69.79, test_loss: 8.036399841308594, test_acc: 65.68, test_fscore: 66.46, time: 1.94 sec
epoch: 20, train_loss: 8.159799575805664, train_acc: 72.77, train_fscore: 72.47, valid_loss: 6.642199993133545, valid_acc: 71.08, valid_fscore: 72.19, test_loss: 8.061400413513184, test_acc: 64.63, test_fscore: 65.37, time: 2.03 sec
              precision    recall  f1-score   support

           0     0.3710    0.6389    0.4694     144.0
           1     0.7597    0.7224    0.7406     245.0
           2     0.6727    0.5833    0.6248     384.0
           3     0.6173    0.7118    0.6612     170.0
           4     0.8525    0.6187    0.7171     299.0
           5     0.6313    0.6562    0.6435     381.0

    accuracy                         0.6463    1623.0
   macro avg     0.6507    0.6552    0.6428    1623.0
weighted avg     0.6767    0.6463    0.6537    1623.0

[[ 92.   9.  12.   3.  24.   4.]
 [  4. 177.  30.   1.   0.  33.]
 [ 51.  27. 224.  17.   3.  62.]
 [  0.   0.   4. 121.   0.  45.]
 [ 98.   0.  14.   0. 185.   2.]
 [  3.  20.  49.  54.   5. 250.]]
epoch: 21, train_loss: 8.103899955749512, train_acc: 73.55, train_fscore: 73.29, valid_loss: 6.67579984664917, valid_acc: 70.63, valid_fscore: 71.96, test_loss: 8.071499824523926, test_acc: 65.06, test_fscore: 65.85, time: 1.98 sec
epoch: 22, train_loss: 8.043899536132812, train_acc: 73.53, train_fscore: 73.29, valid_loss: 6.644899845123291, valid_acc: 69.58, valid_fscore: 70.52, test_loss: 8.001199722290039, test_acc: 66.3, test_fscore: 67.04, time: 2.69 sec
epoch: 23, train_loss: 8.011199951171875, train_acc: 73.88, train_fscore: 73.65, valid_loss: 6.601099967956543, valid_acc: 70.03, valid_fscore: 70.73, test_loss: 7.957399845123291, test_acc: 67.04, test_fscore: 67.73, time: 2.55 sec
epoch: 24, train_loss: 7.939599990844727, train_acc: 74.39, train_fscore: 74.14, valid_loss: 6.546599864959717, valid_acc: 72.44, valid_fscore: 73.35, test_loss: 7.929500102996826, test_acc: 66.17, test_fscore: 66.82, time: 2.01 sec
epoch: 25, train_loss: 7.897200107574463, train_acc: 75.22, train_fscore: 74.97, valid_loss: 6.541900157928467, valid_acc: 71.39, valid_fscore: 72.3, test_loss: 7.908100128173828, test_acc: 66.97, test_fscore: 67.54, time: 1.96 sec
epoch: 26, train_loss: 7.839000225067139, train_acc: 75.59, train_fscore: 75.32, valid_loss: 6.5518999099731445, valid_acc: 70.78, valid_fscore: 72.03, test_loss: 7.9096999168396, test_acc: 67.04, test_fscore: 67.69, time: 1.99 sec
epoch: 27, train_loss: 7.809000015258789, train_acc: 74.83, train_fscore: 74.65, valid_loss: 6.519000053405762, valid_acc: 71.08, valid_fscore: 72.33, test_loss: 7.875199794769287, test_acc: 67.34, test_fscore: 68.05, time: 1.99 sec
epoch: 28, train_loss: 7.756199836730957, train_acc: 75.59, train_fscore: 75.38, valid_loss: 6.508299827575684, valid_acc: 71.84, valid_fscore: 73.02, test_loss: 7.869100093841553, test_acc: 66.54, test_fscore: 67.23, time: 1.97 sec
epoch: 29, train_loss: 7.725100040435791, train_acc: 76.99, train_fscore: 76.84, valid_loss: 6.512800216674805, valid_acc: 71.69, valid_fscore: 72.93, test_loss: 7.87060022354126, test_acc: 65.8, test_fscore: 66.53, time: 1.94 sec
epoch: 30, train_loss: 7.673299789428711, train_acc: 76.37, train_fscore: 76.22, valid_loss: 6.4878997802734375, valid_acc: 71.69, valid_fscore: 72.64, test_loss: 7.81689977645874, test_acc: 67.22, test_fscore: 67.84, time: 1.95 sec
              precision    recall  f1-score   support

           0     0.4123    0.6528    0.5054     144.0
           1     0.7873    0.7102    0.7468     245.0
           2     0.6880    0.6432    0.6649     384.0
           3     0.6214    0.7529    0.6809     170.0
           4     0.8578    0.6455    0.7366     299.0
           5     0.6641    0.6693    0.6667     381.0

    accuracy                         0.6722    1623.0
   macro avg     0.6718    0.6790    0.6669    1623.0
weighted avg     0.6972    0.6722    0.6784    1623.0

[[ 94.   7.  16.   3.  21.   3.]
 [  4. 174.  30.   1.   0.  36.]
 [ 39.  24. 247.  20.   5.  49.]
 [  0.   0.   3. 128.   0.  39.]
 [ 91.   0.  13.   0. 193.   2.]
 [  0.  16.  50.  54.   6. 255.]]
epoch: 31, train_loss: 7.655799865722656, train_acc: 76.66, train_fscore: 76.47, valid_loss: 6.470300197601318, valid_acc: 70.93, valid_fscore: 71.95, test_loss: 7.769100189208984, test_acc: 67.59, test_fscore: 68.21, time: 2.0 sec
epoch: 32, train_loss: 7.633600234985352, train_acc: 76.64, train_fscore: 76.46, valid_loss: 6.479700088500977, valid_acc: 70.78, valid_fscore: 72.11, test_loss: 7.756800174713135, test_acc: 67.1, test_fscore: 67.75, time: 2.0 sec
epoch: 33, train_loss: 7.589799880981445, train_acc: 77.42, train_fscore: 77.24, valid_loss: 6.468699932098389, valid_acc: 71.54, valid_fscore: 72.61, test_loss: 7.76170015335083, test_acc: 66.3, test_fscore: 66.98, time: 4.34 sec
epoch: 34, train_loss: 7.564899921417236, train_acc: 77.48, train_fscore: 77.31, valid_loss: 6.423900127410889, valid_acc: 72.89, valid_fscore: 73.58, test_loss: 7.769199848175049, test_acc: 67.1, test_fscore: 67.7, time: 2.93 sec
epoch: 35, train_loss: 7.563700199127197, train_acc: 77.83, train_fscore: 77.65, valid_loss: 6.417600154876709, valid_acc: 72.44, valid_fscore: 73.33, test_loss: 7.726799964904785, test_acc: 67.41, test_fscore: 68.05, time: 3.32 sec
epoch: 36, train_loss: 7.505199909210205, train_acc: 77.92, train_fscore: 77.78, valid_loss: 6.46120023727417, valid_acc: 71.54, valid_fscore: 72.6, test_loss: 7.71019983291626, test_acc: 66.85, test_fscore: 67.55, time: 4.54 sec
epoch: 37, train_loss: 7.479300022125244, train_acc: 77.96, train_fscore: 77.8, valid_loss: 6.438199996948242, valid_acc: 72.44, valid_fscore: 73.32, test_loss: 7.701200008392334, test_acc: 67.53, test_fscore: 68.17, time: 4.27 sec
epoch: 38, train_loss: 7.4741997718811035, train_acc: 78.49, train_fscore: 78.33, valid_loss: 6.416500091552734, valid_acc: 73.19, valid_fscore: 74.0, test_loss: 7.720300197601318, test_acc: 67.16, test_fscore: 67.79, time: 4.5 sec
epoch: 39, train_loss: 7.432499885559082, train_acc: 79.34, train_fscore: 79.2, valid_loss: 6.406300067901611, valid_acc: 72.29, valid_fscore: 72.98, test_loss: 7.673099994659424, test_acc: 67.22, test_fscore: 67.84, time: 2.79 sec
epoch: 40, train_loss: 7.387499809265137, train_acc: 79.5, train_fscore: 79.33, valid_loss: 6.434599876403809, valid_acc: 71.23, valid_fscore: 72.25, test_loss: 7.678699970245361, test_acc: 66.73, test_fscore: 67.43, time: 1.96 sec
              precision    recall  f1-score   support

           0     0.4122    0.7500    0.5320     144.0
           1     0.8027    0.7306    0.7650     245.0
           2     0.7020    0.6380    0.6685     384.0
           3     0.5890    0.7588    0.6632     170.0
           4     0.8824    0.6020    0.7157     299.0
           5     0.6612    0.6352    0.6479     381.0

    accuracy                         0.6673    1623.0
   macro avg     0.6749    0.6858    0.6654    1623.0
weighted avg     0.7033    0.6673    0.6743    1623.0

[[108.   6.  12.   3.  13.   2.]
 [  4. 179.  29.   2.   0.  31.]
 [ 44.  23. 245.  16.   5.  51.]
 [  0.   0.   3. 129.   0.  38.]
 [106.   0.  11.   0. 180.   2.]
 [  0.  15.  49.  69.   6. 242.]]
epoch: 41, train_loss: 7.396699905395508, train_acc: 79.28, train_fscore: 79.12, valid_loss: 6.411799907684326, valid_acc: 73.04, valid_fscore: 73.93, test_loss: 7.667099952697754, test_acc: 67.28, test_fscore: 67.91, time: 1.98 sec
epoch: 42, train_loss: 7.3592000007629395, train_acc: 79.71, train_fscore: 79.56, valid_loss: 6.4105000495910645, valid_acc: 74.1, valid_fscore: 74.86, test_loss: 7.6458001136779785, test_acc: 67.78, test_fscore: 68.37, time: 1.98 sec
epoch: 43, train_loss: 7.356500148773193, train_acc: 79.71, train_fscore: 79.62, valid_loss: 6.41510009765625, valid_acc: 72.89, valid_fscore: 73.92, test_loss: 7.627399921417236, test_acc: 67.22, test_fscore: 67.88, time: 1.97 sec
epoch: 44, train_loss: 7.306700229644775, train_acc: 80.41, train_fscore: 80.27, valid_loss: 6.4197001457214355, valid_acc: 73.04, valid_fscore: 74.07, test_loss: 7.664299964904785, test_acc: 67.28, test_fscore: 67.95, time: 1.92 sec
epoch: 45, train_loss: 7.299300193786621, train_acc: 80.31, train_fscore: 80.14, valid_loss: 6.401000022888184, valid_acc: 74.4, valid_fscore: 74.98, test_loss: 7.679699897766113, test_acc: 67.9, test_fscore: 68.49, time: 2.12 sec
epoch: 46, train_loss: 7.267499923706055, train_acc: 81.25, train_fscore: 81.12, valid_loss: 6.406400203704834, valid_acc: 73.04, valid_fscore: 73.92, test_loss: 7.656799793243408, test_acc: 66.97, test_fscore: 67.59, time: 1.94 sec
epoch: 47, train_loss: 7.24429988861084, train_acc: 81.27, train_fscore: 81.15, valid_loss: 6.412799835205078, valid_acc: 73.04, valid_fscore: 73.89, test_loss: 7.581500053405762, test_acc: 68.52, test_fscore: 69.17, time: 1.9 sec
epoch: 48, train_loss: 7.227799892425537, train_acc: 81.58, train_fscore: 81.47, valid_loss: 6.383900165557861, valid_acc: 74.4, valid_fscore: 75.07, test_loss: 7.572000026702881, test_acc: 68.7, test_fscore: 69.27, time: 1.92 sec
epoch: 49, train_loss: 7.210299968719482, train_acc: 81.6, train_fscore: 81.46, valid_loss: 6.419899940490723, valid_acc: 74.1, valid_fscore: 74.99, test_loss: 7.676199913024902, test_acc: 67.47, test_fscore: 68.04, time: 1.91 sec
epoch: 50, train_loss: 7.186100006103516, train_acc: 81.38, train_fscore: 81.27, valid_loss: 6.427999973297119, valid_acc: 72.14, valid_fscore: 72.94, test_loss: 7.631199836730957, test_acc: 67.53, test_fscore: 68.19, time: 2.21 sec
              precision    recall  f1-score   support

           0     0.4315    0.7431    0.5459     144.0
           1     0.8279    0.7265    0.7739     245.0
           2     0.7089    0.6406    0.6731     384.0
           3     0.6106    0.7471    0.6720     170.0
           4     0.8815    0.6221    0.7294     299.0
           5     0.6396    0.6614    0.6503     381.0

    accuracy                         0.6753    1623.0
   macro avg     0.6833    0.6901    0.6741    1623.0
weighted avg     0.7075    0.6753    0.6819    1623.0

[[107.   4.  13.   1.  15.   4.]
 [  3. 178.  27.   2.   0.  35.]
 [ 40.  18. 246.  14.   4.  62.]
 [  0.   0.   4. 127.   0.  39.]
 [ 97.   1.  13.   0. 186.   2.]
 [  1.  14.  44.  64.   6. 252.]]
epoch: 51, train_loss: 7.151100158691406, train_acc: 81.36, train_fscore: 81.25, valid_loss: 6.423500061035156, valid_acc: 72.74, valid_fscore: 73.65, test_loss: 7.616600036621094, test_acc: 68.27, test_fscore: 68.87, time: 1.98 sec
epoch: 52, train_loss: 7.142199993133545, train_acc: 82.41, train_fscore: 82.28, valid_loss: 6.407400131225586, valid_acc: 74.55, valid_fscore: 75.24, test_loss: 7.607999801635742, test_acc: 68.15, test_fscore: 68.72, time: 2.17 sec
epoch: 53, train_loss: 7.116799831390381, train_acc: 82.69, train_fscore: 82.58, valid_loss: 6.448599815368652, valid_acc: 72.74, valid_fscore: 73.53, test_loss: 7.589099884033203, test_acc: 68.52, test_fscore: 69.12, time: 1.96 sec
epoch: 54, train_loss: 7.090400218963623, train_acc: 82.71, train_fscore: 82.6, valid_loss: 6.411300182342529, valid_acc: 74.4, valid_fscore: 75.03, test_loss: 7.600800037384033, test_acc: 68.33, test_fscore: 68.9, time: 2.6 sec
epoch: 55, train_loss: 7.089399814605713, train_acc: 83.19, train_fscore: 83.06, valid_loss: 6.422800064086914, valid_acc: 73.95, valid_fscore: 74.82, test_loss: 7.6458001136779785, test_acc: 67.71, test_fscore: 68.3, time: 1.95 sec
epoch: 56, train_loss: 7.076399803161621, train_acc: 82.9, train_fscore: 82.83, valid_loss: 6.435100078582764, valid_acc: 73.95, valid_fscore: 74.68, test_loss: 7.605800151824951, test_acc: 68.08, test_fscore: 68.65, time: 1.97 sec
epoch: 57, train_loss: 7.035799980163574, train_acc: 83.23, train_fscore: 83.09, valid_loss: 6.42579984664917, valid_acc: 73.19, valid_fscore: 73.98, test_loss: 7.580100059509277, test_acc: 68.58, test_fscore: 69.11, time: 1.94 sec
epoch: 58, train_loss: 7.033999919891357, train_acc: 83.54, train_fscore: 83.44, valid_loss: 6.445799827575684, valid_acc: 73.04, valid_fscore: 73.94, test_loss: 7.636199951171875, test_acc: 68.15, test_fscore: 68.68, time: 1.96 sec
epoch: 59, train_loss: 7.013299942016602, train_acc: 83.68, train_fscore: 83.57, valid_loss: 6.450699806213379, valid_acc: 73.95, valid_fscore: 74.61, test_loss: 7.658199787139893, test_acc: 67.96, test_fscore: 68.53, time: 1.94 sec
epoch: 60, train_loss: 6.989999771118164, train_acc: 83.64, train_fscore: 83.56, valid_loss: 6.451300144195557, valid_acc: 73.8, valid_fscore: 74.41, test_loss: 7.617700099945068, test_acc: 68.95, test_fscore: 69.51, time: 2.09 sec
              precision    recall  f1-score   support

           0     0.4328    0.8056    0.5631     144.0
           1     0.8259    0.7551    0.7889     245.0
           2     0.7003    0.7057    0.7030     384.0
           3     0.6704    0.7059    0.6877     170.0
           4     0.8901    0.5686    0.6939     299.0
           5     0.6872    0.6745    0.6808     381.0

    accuracy                         0.6895    1623.0
   macro avg     0.7011    0.7026    0.6862    1623.0
weighted avg     0.7243    0.6895    0.6951    1623.0

[[116.   4.  12.   0.  10.   2.]
 [  3. 185.  25.   1.   1.  30.]
 [ 40.  20. 271.  10.   4.  39.]
 [  0.   0.   6. 120.   0.  44.]
 [108.   1.  18.   0. 170.   2.]
 [  1.  14.  55.  48.   6. 257.]]
epoch: 61, train_loss: 6.98199987411499, train_acc: 84.12, train_fscore: 84.03, valid_loss: 6.435299873352051, valid_acc: 72.59, valid_fscore: 73.35, test_loss: 7.556600093841553, test_acc: 67.96, test_fscore: 68.45, time: 2.13 sec
epoch: 62, train_loss: 6.953499794006348, train_acc: 84.53, train_fscore: 84.42, valid_loss: 6.463799953460693, valid_acc: 72.89, valid_fscore: 73.86, test_loss: 7.548399925231934, test_acc: 68.64, test_fscore: 69.17, time: 1.93 sec
epoch: 63, train_loss: 6.949399948120117, train_acc: 84.28, train_fscore: 84.18, valid_loss: 6.433199882507324, valid_acc: 74.7, valid_fscore: 75.26, test_loss: 7.547800064086914, test_acc: 69.69, test_fscore: 70.2, time: 1.9 sec
epoch: 64, train_loss: 6.9156999588012695, train_acc: 84.75, train_fscore: 84.6, valid_loss: 6.440199851989746, valid_acc: 74.55, valid_fscore: 75.01, test_loss: 7.597700119018555, test_acc: 69.19, test_fscore: 69.72, time: 1.98 sec
epoch: 65, train_loss: 6.914999961853027, train_acc: 85.33, train_fscore: 85.27, valid_loss: 6.543499946594238, valid_acc: 72.59, valid_fscore: 73.62, test_loss: 7.625899791717529, test_acc: 67.71, test_fscore: 68.27, time: 1.97 sec
epoch: 66, train_loss: 6.901299953460693, train_acc: 84.53, train_fscore: 84.47, valid_loss: 6.510200023651123, valid_acc: 73.49, valid_fscore: 74.1, test_loss: 7.531899929046631, test_acc: 69.19, test_fscore: 69.72, time: 1.98 sec
epoch: 67, train_loss: 6.894800186157227, train_acc: 85.31, train_fscore: 85.17, valid_loss: 6.532800197601318, valid_acc: 73.8, valid_fscore: 74.5, test_loss: 7.627099990844727, test_acc: 68.7, test_fscore: 69.23, time: 1.93 sec
epoch: 68, train_loss: 6.904200077056885, train_acc: 85.19, train_fscore: 85.1, valid_loss: 6.526500225067139, valid_acc: 73.49, valid_fscore: 74.16, test_loss: 7.644100189208984, test_acc: 68.52, test_fscore: 69.08, time: 1.91 sec
epoch: 69, train_loss: 6.862100124359131, train_acc: 85.54, train_fscore: 85.43, valid_loss: 6.536799907684326, valid_acc: 73.95, valid_fscore: 74.4, test_loss: 7.606400012969971, test_acc: 69.07, test_fscore: 69.56, time: 1.96 sec
epoch: 70, train_loss: 6.8520002365112305, train_acc: 85.72, train_fscore: 85.63, valid_loss: 6.5467000007629395, valid_acc: 73.19, valid_fscore: 73.96, test_loss: 7.6072001457214355, test_acc: 68.58, test_fscore: 69.07, time: 1.96 sec
              precision    recall  f1-score   support

           0     0.4377    0.8056    0.5672     144.0
           1     0.8303    0.7388    0.7819     245.0
           2     0.6964    0.7109    0.7036     384.0
           3     0.6612    0.7118    0.6856     170.0
           4     0.8956    0.5452    0.6778     299.0
           5     0.6762    0.6798    0.6780     381.0

    accuracy                         0.6858    1623.0
   macro avg     0.6996    0.6987    0.6823    1623.0
weighted avg     0.7219    0.6858    0.6907    1623.0

[[116.   4.  14.   0.   9.   1.]
 [  3. 181.  26.   1.   1.  33.]
 [ 35.  20. 273.  10.   3.  43.]
 [  0.   0.   4. 121.   0.  45.]
 [110.   1.  23.   0. 163.   2.]
 [  1.  12.  52.  51.   6. 259.]]
epoch: 71, train_loss: 6.823400020599365, train_acc: 86.4, train_fscore: 86.34, valid_loss: 6.549200057983398, valid_acc: 72.74, valid_fscore: 73.61, test_loss: 7.620299816131592, test_acc: 68.45, test_fscore: 68.89, time: 2.01 sec
epoch: 72, train_loss: 6.809999942779541, train_acc: 85.39, train_fscore: 85.25, valid_loss: 6.516900062561035, valid_acc: 74.25, valid_fscore: 74.63, test_loss: 7.562399864196777, test_acc: 70.55, test_fscore: 71.0, time: 1.92 sec
epoch: 73, train_loss: 6.828800201416016, train_acc: 86.13, train_fscore: 86.02, valid_loss: 6.600900173187256, valid_acc: 72.74, valid_fscore: 73.78, test_loss: 7.729000091552734, test_acc: 67.47, test_fscore: 67.86, time: 1.9 sec
epoch: 74, train_loss: 6.804599761962891, train_acc: 86.05, train_fscore: 86.02, valid_loss: 6.579400062561035, valid_acc: 73.19, valid_fscore: 74.02, test_loss: 7.643700122833252, test_acc: 68.21, test_fscore: 68.71, time: 1.98 sec
epoch: 75, train_loss: 6.755899906158447, train_acc: 86.26, train_fscore: 86.17, valid_loss: 6.596499919891357, valid_acc: 74.55, valid_fscore: 74.62, test_loss: 7.529699802398682, test_acc: 71.1, test_fscore: 71.51, time: 2.23 sec
epoch: 76, train_loss: 6.774400234222412, train_acc: 86.73, train_fscore: 86.63, valid_loss: 6.570400238037109, valid_acc: 74.7, valid_fscore: 75.3, test_loss: 7.66349983215332, test_acc: 68.58, test_fscore: 69.05, time: 1.98 sec
epoch: 77, train_loss: 6.740200042724609, train_acc: 86.49, train_fscore: 86.41, valid_loss: 6.538599967956543, valid_acc: 73.64, valid_fscore: 74.25, test_loss: 7.643400192260742, test_acc: 68.39, test_fscore: 68.83, time: 2.14 sec
epoch: 78, train_loss: 6.704400062561035, train_acc: 87.19, train_fscore: 87.12, valid_loss: 6.592199802398682, valid_acc: 73.8, valid_fscore: 74.23, test_loss: 7.556600093841553, test_acc: 70.55, test_fscore: 71.0, time: 1.91 sec
epoch: 79, train_loss: 6.709000110626221, train_acc: 86.96, train_fscore: 86.89, valid_loss: 6.583899974822998, valid_acc: 73.49, valid_fscore: 74.05, test_loss: 7.645100116729736, test_acc: 68.52, test_fscore: 69.0, time: 1.95 sec
epoch: 80, train_loss: 6.723499774932861, train_acc: 86.98, train_fscore: 86.86, valid_loss: 6.5391998291015625, valid_acc: 74.25, valid_fscore: 74.86, test_loss: 7.687600135803223, test_acc: 69.01, test_fscore: 69.48, time: 2.01 sec
              precision    recall  f1-score   support

           0     0.4368    0.7917    0.5630     144.0
           1     0.8222    0.7551    0.7872     245.0
           2     0.6939    0.7083    0.7010     384.0
           3     0.6776    0.7294    0.7025     170.0
           4     0.8962    0.5485    0.6805     299.0
           5     0.6887    0.6850    0.6868     381.0

    accuracy                         0.6901    1623.0
   macro avg     0.7026    0.7030    0.6869    1623.0
weighted avg     0.7248    0.6901    0.6948    1623.0

[[114.   5.  15.   0.   9.   1.]
 [  2. 185.  25.   2.   1.  30.]
 [ 36.  22. 272.   8.   3.  43.]
 [  0.   0.   4. 124.   0.  42.]
 [109.   1.  23.   0. 164.   2.]
 [  0.  12.  53.  49.   6. 261.]]
epoch: 81, train_loss: 6.702400207519531, train_acc: 86.98, train_fscore: 86.91, valid_loss: 6.527299880981445, valid_acc: 74.25, valid_fscore: 74.72, test_loss: 7.651500225067139, test_acc: 69.32, test_fscore: 69.86, time: 1.98 sec
epoch: 82, train_loss: 6.674499988555908, train_acc: 87.6, train_fscore: 87.52, valid_loss: 6.5817999839782715, valid_acc: 73.95, valid_fscore: 74.47, test_loss: 7.642499923706055, test_acc: 69.44, test_fscore: 69.95, time: 1.98 sec
epoch: 83, train_loss: 6.685699939727783, train_acc: 87.74, train_fscore: 87.66, valid_loss: 6.578100204467773, valid_acc: 74.85, valid_fscore: 75.34, test_loss: 7.676000118255615, test_acc: 69.19, test_fscore: 69.72, time: 1.92 sec
epoch: 84, train_loss: 6.657100200653076, train_acc: 87.87, train_fscore: 87.8, valid_loss: 6.560400009155273, valid_acc: 74.25, valid_fscore: 74.6, test_loss: 7.669099807739258, test_acc: 68.39, test_fscore: 68.83, time: 2.04 sec
epoch: 85, train_loss: 6.624800205230713, train_acc: 88.17, train_fscore: 88.07, valid_loss: 6.611199855804443, valid_acc: 74.1, valid_fscore: 74.63, test_loss: 7.6433000564575195, test_acc: 69.99, test_fscore: 70.5, time: 2.03 sec
epoch: 86, train_loss: 6.613900184631348, train_acc: 88.48, train_fscore: 88.4, valid_loss: 6.5742998123168945, valid_acc: 74.25, valid_fscore: 74.6, test_loss: 7.684599876403809, test_acc: 69.44, test_fscore: 69.9, time: 1.97 sec
epoch: 87, train_loss: 6.6315999031066895, train_acc: 88.34, train_fscore: 88.23, valid_loss: 6.626399993896484, valid_acc: 74.85, valid_fscore: 75.4, test_loss: 7.755899906158447, test_acc: 69.19, test_fscore: 69.66, time: 1.89 sec
epoch: 88, train_loss: 6.593900203704834, train_acc: 88.92, train_fscore: 88.88, valid_loss: 6.632299900054932, valid_acc: 73.8, valid_fscore: 74.28, test_loss: 7.66349983215332, test_acc: 69.75, test_fscore: 70.27, time: 1.98 sec
epoch: 89, train_loss: 6.585899829864502, train_acc: 88.03, train_fscore: 87.94, valid_loss: 6.598499774932861, valid_acc: 74.7, valid_fscore: 75.0, test_loss: 7.644999980926514, test_acc: 69.99, test_fscore: 70.44, time: 1.99 sec
epoch: 90, train_loss: 6.57919979095459, train_acc: 88.38, train_fscore: 88.27, valid_loss: 6.640200138092041, valid_acc: 73.64, valid_fscore: 74.17, test_loss: 7.734099864959717, test_acc: 69.32, test_fscore: 69.77, time: 2.09 sec
              precision    recall  f1-score   support

           0     0.4431    0.7847    0.5664     144.0
           1     0.8318    0.7469    0.7871     245.0
           2     0.6992    0.7266    0.7126     384.0
           3     0.7012    0.6765    0.6886     170.0
           4     0.8919    0.5518    0.6818     299.0
           5     0.6750    0.7087    0.6914     381.0

    accuracy                         0.6932    1623.0
   macro avg     0.7071    0.6992    0.6880    1623.0
weighted avg     0.7265    0.6932    0.6977    1623.0

[[113.   5.  14.   0.  11.   1.]
 [  2. 183.  27.   1.   0.  32.]
 [ 31.  19. 279.   7.   3.  45.]
 [  0.   0.   4. 115.   0.  51.]
 [109.   1.  23.   0. 165.   1.]
 [  0.  12.  52.  41.   6. 270.]]
epoch: 91, train_loss: 6.581399917602539, train_acc: 88.71, train_fscore: 88.65, valid_loss: 6.669099807739258, valid_acc: 73.95, valid_fscore: 74.46, test_loss: 7.752600193023682, test_acc: 69.44, test_fscore: 69.96, time: 2.34 sec
epoch: 92, train_loss: 6.567699909210205, train_acc: 88.48, train_fscore: 88.37, valid_loss: 6.661900043487549, valid_acc: 74.85, valid_fscore: 75.21, test_loss: 7.657800197601318, test_acc: 70.43, test_fscore: 70.89, time: 2.92 sec
epoch: 93, train_loss: 6.547800064086914, train_acc: 88.83, train_fscore: 88.75, valid_loss: 6.654900074005127, valid_acc: 74.55, valid_fscore: 74.84, test_loss: 7.671199798583984, test_acc: 69.81, test_fscore: 70.23, time: 2.14 sec
epoch: 94, train_loss: 6.540500164031982, train_acc: 88.85, train_fscore: 88.73, valid_loss: 6.645500183105469, valid_acc: 74.25, valid_fscore: 74.54, test_loss: 7.708700180053711, test_acc: 69.25, test_fscore: 69.69, time: 2.07 sec
epoch: 95, train_loss: 6.523900032043457, train_acc: 89.02, train_fscore: 88.94, valid_loss: 6.675899982452393, valid_acc: 74.1, valid_fscore: 74.54, test_loss: 7.747399806976318, test_acc: 70.06, test_fscore: 70.58, time: 1.95 sec
epoch: 96, train_loss: 6.520100116729736, train_acc: 90.13, train_fscore: 90.07, valid_loss: 6.662199974060059, valid_acc: 74.55, valid_fscore: 74.93, test_loss: 7.756499767303467, test_acc: 69.56, test_fscore: 69.96, time: 2.56 sec
epoch: 97, train_loss: 6.517499923706055, train_acc: 89.37, train_fscore: 89.26, valid_loss: 6.692599773406982, valid_acc: 73.95, valid_fscore: 74.53, test_loss: 7.734399795532227, test_acc: 69.87, test_fscore: 70.37, time: 2.04 sec
epoch: 98, train_loss: 6.494800090789795, train_acc: 89.31, train_fscore: 89.23, valid_loss: 6.696499824523926, valid_acc: 74.1, valid_fscore: 74.46, test_loss: 7.741099834442139, test_acc: 69.56, test_fscore: 70.07, time: 1.98 sec
epoch: 99, train_loss: 6.491000175476074, train_acc: 89.95, train_fscore: 89.89, valid_loss: 6.674900054931641, valid_acc: 74.1, valid_fscore: 74.52, test_loss: 7.8643999099731445, test_acc: 68.45, test_fscore: 68.78, time: 2.0 sec
epoch: 100, train_loss: 6.447700023651123, train_acc: 89.97, train_fscore: 89.9, valid_loss: 6.714099884033203, valid_acc: 74.25, valid_fscore: 74.63, test_loss: 7.767600059509277, test_acc: 70.61, test_fscore: 71.05, time: 2.0 sec
              precision    recall  f1-score   support

           0     0.4777    0.7431    0.5815     144.0
           1     0.8238    0.7633    0.7924     245.0
           2     0.7206    0.7188    0.7197     384.0
           3     0.6722    0.7118    0.6914     170.0
           4     0.8785    0.6288    0.7329     299.0
           5     0.6759    0.7008    0.6881     381.0

    accuracy                         0.7061    1623.0
   macro avg     0.7081    0.7111    0.7010    1623.0
weighted avg     0.7282    0.7061    0.7105    1623.0

[[107.   5.  13.   0.  18.   1.]
 [  2. 187.  22.   2.   0.  32.]
 [ 29.  22. 276.   8.   2.  47.]
 [  0.   0.   3. 121.   0.  46.]
 [ 86.   1.  22.   0. 188.   2.]
 [  0.  12.  47.  49.   6. 267.]]
epoch: 101, train_loss: 6.46999979019165, train_acc: 90.13, train_fscore: 90.05, valid_loss: 6.729400157928467, valid_acc: 73.8, valid_fscore: 74.11, test_loss: 7.735599994659424, test_acc: 70.86, test_fscore: 71.28, time: 1.94 sec
epoch: 102, train_loss: 6.4633002281188965, train_acc: 89.16, train_fscore: 89.07, valid_loss: 6.7342000007629395, valid_acc: 73.49, valid_fscore: 73.95, test_loss: 7.862199783325195, test_acc: 68.64, test_fscore: 68.99, time: 2.05 sec
epoch: 103, train_loss: 6.440400123596191, train_acc: 90.48, train_fscore: 90.43, valid_loss: 6.690999984741211, valid_acc: 74.85, valid_fscore: 75.17, test_loss: 7.792099952697754, test_acc: 69.99, test_fscore: 70.44, time: 1.95 sec
epoch: 104, train_loss: 6.434199810028076, train_acc: 90.59, train_fscore: 90.52, valid_loss: 6.695099830627441, valid_acc: 75.3, valid_fscore: 75.54, test_loss: 7.728899955749512, test_acc: 70.73, test_fscore: 71.15, time: 1.95 sec
epoch: 105, train_loss: 6.416399955749512, train_acc: 90.4, train_fscore: 90.31, valid_loss: 6.7779998779296875, valid_acc: 73.95, valid_fscore: 74.25, test_loss: 7.789299964904785, test_acc: 69.13, test_fscore: 69.51, time: 1.93 sec
epoch: 106, train_loss: 6.430699825286865, train_acc: 91.04, train_fscore: 91.01, valid_loss: 6.735000133514404, valid_acc: 73.95, valid_fscore: 74.19, test_loss: 7.783199787139893, test_acc: 69.56, test_fscore: 69.99, time: 1.94 sec
epoch: 107, train_loss: 6.422599792480469, train_acc: 90.34, train_fscore: 90.28, valid_loss: 6.714600086212158, valid_acc: 75.15, valid_fscore: 75.2, test_loss: 7.752200126647949, test_acc: 70.86, test_fscore: 71.24, time: 1.93 sec
epoch: 108, train_loss: 6.39739990234375, train_acc: 90.65, train_fscore: 90.58, valid_loss: 6.781899929046631, valid_acc: 74.55, valid_fscore: 74.7, test_loss: 7.797900199890137, test_acc: 69.87, test_fscore: 70.26, time: 1.92 sec
epoch: 109, train_loss: 6.375899791717529, train_acc: 90.79, train_fscore: 90.73, valid_loss: 6.839000225067139, valid_acc: 74.1, valid_fscore: 74.29, test_loss: 7.785900115966797, test_acc: 69.5, test_fscore: 69.9, time: 2.02 sec
epoch: 110, train_loss: 6.385300159454346, train_acc: 90.98, train_fscore: 90.92, valid_loss: 6.8003997802734375, valid_acc: 73.8, valid_fscore: 74.09, test_loss: 7.77839994430542, test_acc: 69.99, test_fscore: 70.38, time: 1.96 sec
              precision    recall  f1-score   support

           0     0.4802    0.7569    0.5876     144.0
           1     0.8386    0.7633    0.7991     245.0
           2     0.6987    0.7188    0.7086     384.0
           3     0.6597    0.7412    0.6981     170.0
           4     0.8738    0.6020    0.7129     299.0
           5     0.6772    0.6772    0.6772     381.0

    accuracy                         0.6999    1623.0
   macro avg     0.7047    0.7099    0.6972    1623.0
weighted avg     0.7235    0.6999    0.7038    1623.0

[[109.   4.  14.   0.  16.   1.]
 [  2. 187.  25.   2.   0.  29.]
 [ 27.  19. 276.   7.   4.  51.]
 [  0.   0.   3. 126.   0.  41.]
 [ 89.   1.  28.   0. 180.   1.]
 [  0.  12.  49.  56.   6. 258.]]
epoch: 111, train_loss: 6.3709001541137695, train_acc: 91.06, train_fscore: 90.99, valid_loss: 6.755000114440918, valid_acc: 74.7, valid_fscore: 74.86, test_loss: 7.803599834442139, test_acc: 69.56, test_fscore: 69.9, time: 1.98 sec
epoch: 112, train_loss: 6.339300155639648, train_acc: 91.27, train_fscore: 91.19, valid_loss: 6.771999835968018, valid_acc: 74.25, valid_fscore: 74.6, test_loss: 7.8403000831604, test_acc: 68.95, test_fscore: 69.44, time: 1.96 sec
epoch: 113, train_loss: 6.337299823760986, train_acc: 91.35, train_fscore: 91.3, valid_loss: 6.759099960327148, valid_acc: 74.25, valid_fscore: 74.43, test_loss: 7.82390022277832, test_acc: 69.69, test_fscore: 70.09, time: 2.03 sec
epoch: 114, train_loss: 6.339600086212158, train_acc: 91.72, train_fscore: 91.67, valid_loss: 6.776100158691406, valid_acc: 74.85, valid_fscore: 74.95, test_loss: 7.80649995803833, test_acc: 70.18, test_fscore: 70.52, time: 1.98 sec
epoch: 115, train_loss: 6.328700065612793, train_acc: 91.86, train_fscore: 91.78, valid_loss: 6.7631001472473145, valid_acc: 75.15, valid_fscore: 75.41, test_loss: 7.84660005569458, test_acc: 69.93, test_fscore: 70.27, time: 2.06 sec
epoch: 116, train_loss: 6.310500144958496, train_acc: 91.66, train_fscore: 91.61, valid_loss: 6.789899826049805, valid_acc: 74.7, valid_fscore: 74.92, test_loss: 7.851399898529053, test_acc: 69.62, test_fscore: 70.0, time: 2.02 sec
epoch: 117, train_loss: 6.307600021362305, train_acc: 91.68, train_fscore: 91.62, valid_loss: 6.827600002288818, valid_acc: 74.25, valid_fscore: 74.39, test_loss: 7.801599979400635, test_acc: 69.93, test_fscore: 70.33, time: 2.03 sec
epoch: 118, train_loss: 6.314599990844727, train_acc: 91.94, train_fscore: 91.88, valid_loss: 6.8566999435424805, valid_acc: 73.49, valid_fscore: 73.76, test_loss: 7.849599838256836, test_acc: 69.93, test_fscore: 70.35, time: 2.05 sec
epoch: 119, train_loss: 6.29640007019043, train_acc: 91.7, train_fscore: 91.65, valid_loss: 6.84499979019165, valid_acc: 73.8, valid_fscore: 73.94, test_loss: 7.863399982452393, test_acc: 69.62, test_fscore: 69.98, time: 2.05 sec
epoch: 120, train_loss: 6.272799968719482, train_acc: 92.56, train_fscore: 92.51, valid_loss: 6.8379998207092285, valid_acc: 74.55, valid_fscore: 74.75, test_loss: 7.920899868011475, test_acc: 70.12, test_fscore: 70.5, time: 2.0 sec
              precision    recall  f1-score   support

           0     0.4756    0.7431    0.5799     144.0
           1     0.8274    0.7633    0.7941     245.0
           2     0.7028    0.7266    0.7145     384.0
           3     0.6889    0.7294    0.7086     170.0
           4     0.8768    0.5953    0.7092     299.0
           5     0.6709    0.6903    0.6805     381.0

    accuracy                         0.7012    1623.0
   macro avg     0.7071    0.7080    0.6978    1623.0
weighted avg     0.7246    0.7012    0.7050    1623.0

[[107.   6.  14.   0.  16.   1.]
 [  2. 187.  22.   1.   0.  33.]
 [ 26.  19. 279.   5.   3.  52.]
 [  0.   0.   4. 124.   0.  42.]
 [ 90.   1.  29.   0. 178.   1.]
 [  0.  13.  49.  50.   6. 263.]]
epoch: 121, train_loss: 6.289599895477295, train_acc: 92.09, train_fscore: 92.05, valid_loss: 6.8078999519348145, valid_acc: 74.7, valid_fscore: 74.9, test_loss: 7.88040018081665, test_acc: 69.44, test_fscore: 69.83, time: 2.02 sec
epoch: 122, train_loss: 6.278200149536133, train_acc: 91.84, train_fscore: 91.78, valid_loss: 6.837800025939941, valid_acc: 73.04, valid_fscore: 73.34, test_loss: 7.888199806213379, test_acc: 69.93, test_fscore: 70.32, time: 3.23 sec
epoch: 123, train_loss: 6.263500213623047, train_acc: 92.42, train_fscore: 92.37, valid_loss: 6.8531999588012695, valid_acc: 74.1, valid_fscore: 74.5, test_loss: 8.00160026550293, test_acc: 69.44, test_fscore: 69.73, time: 2.31 sec
epoch: 124, train_loss: 6.257400035858154, train_acc: 92.38, train_fscore: 92.34, valid_loss: 6.839600086212158, valid_acc: 75.75, valid_fscore: 75.64, test_loss: 7.92519998550415, test_acc: 70.18, test_fscore: 70.49, time: 2.74 sec
epoch: 125, train_loss: 6.252099990844727, train_acc: 92.34, train_fscore: 92.3, valid_loss: 6.815700054168701, valid_acc: 75.3, valid_fscore: 75.59, test_loss: 7.867300033569336, test_acc: 70.12, test_fscore: 70.55, time: 2.06 sec
epoch: 126, train_loss: 6.255099773406982, train_acc: 92.27, train_fscore: 92.22, valid_loss: 6.84660005569458, valid_acc: 73.49, valid_fscore: 74.04, test_loss: 7.889800071716309, test_acc: 69.07, test_fscore: 69.4, time: 2.02 sec
epoch: 127, train_loss: 6.219200134277344, train_acc: 92.65, train_fscore: 92.6, valid_loss: 6.8765997886657715, valid_acc: 75.0, valid_fscore: 75.1, test_loss: 7.956900119781494, test_acc: 69.87, test_fscore: 70.16, time: 1.92 sec
epoch: 128, train_loss: 6.211299896240234, train_acc: 92.73, train_fscore: 92.7, valid_loss: 6.838600158691406, valid_acc: 74.85, valid_fscore: 74.94, test_loss: 7.996500015258789, test_acc: 70.06, test_fscore: 70.36, time: 4.95 sec
epoch: 129, train_loss: 6.218800067901611, train_acc: 92.5, train_fscore: 92.44, valid_loss: 6.886600017547607, valid_acc: 74.1, valid_fscore: 74.27, test_loss: 7.946400165557861, test_acc: 69.69, test_fscore: 70.08, time: 4.2 sec
epoch: 130, train_loss: 6.208399772644043, train_acc: 92.69, train_fscore: 92.65, valid_loss: 6.992499828338623, valid_acc: 73.95, valid_fscore: 74.16, test_loss: 7.9095001220703125, test_acc: 70.06, test_fscore: 70.4, time: 4.61 sec
              precision    recall  f1-score   support

           0     0.4976    0.7153    0.5869     144.0
           1     0.8433    0.7469    0.7922     245.0
           2     0.6754    0.7370    0.7049     384.0
           3     0.6721    0.7235    0.6969     170.0
           4     0.8539    0.6254    0.7220     299.0
           5     0.6825    0.6772    0.6798     381.0

    accuracy                         0.7006    1623.0
   macro avg     0.7041    0.7042    0.6971    1623.0
weighted avg     0.7192    0.7006    0.7040    1623.0

[[103.   4.  14.   0.  22.   1.]
 [  2. 183.  29.   2.   0.  29.]
 [ 26.  17. 283.   6.   5.  47.]
 [  0.   0.   5. 123.   0.  42.]
 [ 76.   1.  34.   0. 187.   1.]
 [  0.  12.  54.  52.   5. 258.]]
epoch: 131, train_loss: 6.199999809265137, train_acc: 93.0, train_fscore: 92.97, valid_loss: 6.905700206756592, valid_acc: 74.25, valid_fscore: 74.54, test_loss: 8.002900123596191, test_acc: 69.69, test_fscore: 69.91, time: 4.58 sec
epoch: 132, train_loss: 6.19379997253418, train_acc: 93.32, train_fscore: 93.26, valid_loss: 6.862299919128418, valid_acc: 74.55, valid_fscore: 74.64, test_loss: 8.016900062561035, test_acc: 69.93, test_fscore: 70.19, time: 4.64 sec
epoch: 133, train_loss: 6.185200214385986, train_acc: 93.06, train_fscore: 93.01, valid_loss: 6.939300060272217, valid_acc: 74.1, valid_fscore: 74.0, test_loss: 7.99970006942749, test_acc: 69.87, test_fscore: 70.22, time: 4.52 sec
epoch: 134, train_loss: 6.198800086975098, train_acc: 93.06, train_fscore: 93.02, valid_loss: 6.883200168609619, valid_acc: 73.95, valid_fscore: 74.26, test_loss: 8.043600082397461, test_acc: 69.56, test_fscore: 69.98, time: 4.52 sec
epoch: 135, train_loss: 6.18310022354126, train_acc: 93.32, train_fscore: 93.28, valid_loss: 6.862400054931641, valid_acc: 74.4, valid_fscore: 74.58, test_loss: 8.031000137329102, test_acc: 69.25, test_fscore: 69.57, time: 3.41 sec
epoch: 136, train_loss: 6.177599906921387, train_acc: 93.02, train_fscore: 92.97, valid_loss: 6.937600135803223, valid_acc: 74.1, valid_fscore: 74.2, test_loss: 7.979400157928467, test_acc: 69.99, test_fscore: 70.32, time: 3.89 sec
epoch: 137, train_loss: 6.162399768829346, train_acc: 93.49, train_fscore: 93.45, valid_loss: 6.956699848175049, valid_acc: 74.7, valid_fscore: 74.67, test_loss: 8.012200355529785, test_acc: 69.87, test_fscore: 70.2, time: 4.25 sec
epoch: 138, train_loss: 6.133299827575684, train_acc: 93.8, train_fscore: 93.76, valid_loss: 6.900300025939941, valid_acc: 74.55, valid_fscore: 74.86, test_loss: 8.01099967956543, test_acc: 70.12, test_fscore: 70.51, time: 4.51 sec
epoch: 139, train_loss: 6.142899990081787, train_acc: 93.35, train_fscore: 93.31, valid_loss: 6.945000171661377, valid_acc: 74.85, valid_fscore: 75.01, test_loss: 7.964399814605713, test_acc: 70.12, test_fscore: 70.47, time: 4.61 sec
epoch: 140, train_loss: 6.141300201416016, train_acc: 93.88, train_fscore: 93.84, valid_loss: 7.0304999351501465, valid_acc: 74.25, valid_fscore: 74.3, test_loss: 8.015899658203125, test_acc: 70.55, test_fscore: 70.89, time: 3.65 sec
              precision    recall  f1-score   support

           0     0.4904    0.7083    0.5795     144.0
           1     0.8558    0.7510    0.8000     245.0
           2     0.6782    0.7682    0.7204     384.0
           3     0.6720    0.7353    0.7022     170.0
           4     0.8507    0.6288    0.7231     299.0
           5     0.7011    0.6588    0.6793     381.0

    accuracy                         0.7055    1623.0
   macro avg     0.7080    0.7084    0.7008    1623.0
weighted avg     0.7248    0.7055    0.7089    1623.0

[[102.   4.  14.   0.  23.   1.]
 [  2. 184.  28.   2.   0.  29.]
 [ 27.  15. 295.   5.   5.  37.]
 [  0.   0.   6. 125.   0.  39.]
 [ 77.   0.  33.   0. 188.   1.]
 [  0.  12.  59.  54.   5. 251.]]
epoch: 141, train_loss: 6.133299827575684, train_acc: 93.82, train_fscore: 93.79, valid_loss: 6.991199970245361, valid_acc: 74.4, valid_fscore: 74.49, test_loss: 8.032400131225586, test_acc: 70.12, test_fscore: 70.46, time: 4.59 sec
epoch: 142, train_loss: 6.128300189971924, train_acc: 93.57, train_fscore: 93.53, valid_loss: 6.970699787139893, valid_acc: 75.3, valid_fscore: 75.32, test_loss: 8.00629997253418, test_acc: 70.24, test_fscore: 70.51, time: 4.52 sec
epoch: 143, train_loss: 6.119999885559082, train_acc: 94.11, train_fscore: 94.08, valid_loss: 7.026899814605713, valid_acc: 74.7, valid_fscore: 74.83, test_loss: 7.9471001625061035, test_acc: 70.36, test_fscore: 70.67, time: 4.49 sec
epoch: 144, train_loss: 6.108399868011475, train_acc: 94.13, train_fscore: 94.09, valid_loss: 7.060100078582764, valid_acc: 74.25, valid_fscore: 74.38, test_loss: 7.996600151062012, test_acc: 70.24, test_fscore: 70.55, time: 3.74 sec
epoch: 145, train_loss: 6.087900161743164, train_acc: 94.56, train_fscore: 94.54, valid_loss: 6.988500118255615, valid_acc: 74.7, valid_fscore: 74.79, test_loss: 8.068099975585938, test_acc: 70.49, test_fscore: 70.79, time: 4.15 sec
epoch: 146, train_loss: 6.089399814605713, train_acc: 93.84, train_fscore: 93.79, valid_loss: 7.019199848175049, valid_acc: 75.15, valid_fscore: 75.15, test_loss: 8.094799995422363, test_acc: 70.3, test_fscore: 70.58, time: 4.12 sec
epoch: 147, train_loss: 6.09689998626709, train_acc: 94.11, train_fscore: 94.08, valid_loss: 7.103499889373779, valid_acc: 73.64, valid_fscore: 73.81, test_loss: 8.083999633789062, test_acc: 70.24, test_fscore: 70.56, time: 4.57 sec
epoch: 148, train_loss: 6.07889986038208, train_acc: 94.27, train_fscore: 94.24, valid_loss: 7.112100124359131, valid_acc: 73.95, valid_fscore: 74.07, test_loss: 8.042799949645996, test_acc: 70.06, test_fscore: 70.34, time: 4.5 sec
epoch: 149, train_loss: 6.082200050354004, train_acc: 94.13, train_fscore: 94.09, valid_loss: 7.068999767303467, valid_acc: 74.1, valid_fscore: 74.15, test_loss: 8.128999710083008, test_acc: 69.93, test_fscore: 70.24, time: 4.57 sec
epoch: 150, train_loss: 6.059599876403809, train_acc: 94.0, train_fscore: 93.97, valid_loss: 7.024400234222412, valid_acc: 74.7, valid_fscore: 74.78, test_loss: 8.156900405883789, test_acc: 70.06, test_fscore: 70.41, time: 4.48 sec
              precision    recall  f1-score   support

           0     0.4795    0.7292    0.5785     144.0
           1     0.8213    0.7878    0.8042     245.0
           2     0.6931    0.7292    0.7107     384.0
           3     0.6703    0.7294    0.6986     170.0
           4     0.8756    0.6120    0.7205     299.0
           5     0.6792    0.6614    0.6702     381.0

    accuracy                         0.7006    1623.0
   macro avg     0.7032    0.7082    0.6971    1623.0
weighted avg     0.7215    0.7006    0.7041    1623.0

[[105.   5.  15.   0.  18.   1.]
 [  2. 193.  20.   2.   0.  28.]
 [ 28.  21. 280.   4.   3.  48.]
 [  0.   0.   6. 124.   0.  40.]
 [ 84.   1.  29.   0. 183.   2.]
 [  0.  15.  54.  55.   5. 252.]]
Best validation F-Score: 70.41
Test performance..
F-Score: 70.41
Accuracy: 70.06
Loss: 8.156900405883789
--- 6 ---
loss_mask: [True, True, True, True]
Namespace(no_cuda=False, lr=0.0001, l2=1e-05, dropout=0.5, batch_size=64, hidden_dim=1024, n_head=8, epochs=150, temp=2, tensorboard=False, class_weight=True, Dataset='IEMOCAP', loss_mask='1111')
Running on GPU
temp 2
total parameters: 97535000
training parameters: 97535000
epoch: 1, train_loss: 12.389300346374512, train_acc: 23.16, train_fscore: 21.78, valid_loss: 10.166500091552734, valid_acc: 30.72, valid_fscore: 26.72, test_loss: 11.195799827575684, test_acc: 25.2, test_fscore: 21.5, time: 5.59 sec
epoch: 2, train_loss: 11.626399993896484, train_acc: 33.52, train_fscore: 28.37, valid_loss: 9.74429988861084, valid_acc: 43.52, valid_fscore: 38.35, test_loss: 10.770600318908691, test_acc: 36.11, test_fscore: 31.02, time: 4.52 sec
epoch: 3, train_loss: 11.171799659729004, train_acc: 43.9, train_fscore: 41.25, valid_loss: 9.316699981689453, valid_acc: 40.06, valid_fscore: 37.8, test_loss: 10.379799842834473, test_acc: 44.36, test_fscore: 40.62, time: 3.69 sec
epoch: 4, train_loss: 10.742500305175781, train_acc: 51.96, train_fscore: 49.34, valid_loss: 8.8503999710083, valid_acc: 58.28, valid_fscore: 59.16, test_loss: 9.998600006103516, test_acc: 54.53, test_fscore: 54.53, time: 4.59 sec
epoch: 5, train_loss: 10.420100212097168, train_acc: 57.58, train_fscore: 56.69, valid_loss: 8.628299713134766, valid_acc: 62.65, valid_fscore: 64.01, test_loss: 9.81309986114502, test_acc: 56.01, test_fscore: 56.39, time: 4.52 sec
epoch: 6, train_loss: 10.169400215148926, train_acc: 60.01, train_fscore: 59.46, valid_loss: 8.559000015258789, valid_acc: 56.78, valid_fscore: 59.44, test_loss: 9.727499961853027, test_acc: 53.85, test_fscore: 54.69, time: 3.79 sec
epoch: 7, train_loss: 9.85890007019043, train_acc: 61.62, train_fscore: 61.65, valid_loss: 8.30720043182373, valid_acc: 60.24, valid_fscore: 62.07, test_loss: 9.478899955749512, test_acc: 57.36, test_fscore: 58.16, time: 3.92 sec
epoch: 8, train_loss: 9.519399642944336, train_acc: 64.34, train_fscore: 64.12, valid_loss: 7.822700023651123, valid_acc: 65.66, valid_fscore: 66.8, test_loss: 9.049500465393066, test_acc: 61.43, test_fscore: 61.74, time: 4.1 sec
epoch: 9, train_loss: 9.19260025024414, train_acc: 65.86, train_fscore: 65.41, valid_loss: 7.529699802398682, valid_acc: 65.06, valid_fscore: 66.6, test_loss: 8.747400283813477, test_acc: 62.42, test_fscore: 63.04, time: 4.59 sec
epoch: 10, train_loss: 8.965299606323242, train_acc: 67.14, train_fscore: 66.78, valid_loss: 7.471199989318848, valid_acc: 65.36, valid_fscore: 66.65, test_loss: 8.672699928283691, test_acc: 61.37, test_fscore: 62.3, time: 4.65 sec
              precision    recall  f1-score   support

           0     0.3258    0.6042    0.4234     144.0
           1     0.7960    0.6531    0.7175     245.0
           2     0.6147    0.5651    0.5889     384.0
           3     0.5531    0.7353    0.6313     170.0
           4     0.7823    0.6488    0.7093     299.0
           5     0.6494    0.5591    0.6008     381.0

    accuracy                         0.6137    1623.0
   macro avg     0.6202    0.6276    0.6119    1623.0
weighted avg     0.6490    0.6137    0.6230    1623.0

[[ 87.   5.   9.   2.  40.   1.]
 [ 16. 160.  39.   4.   3.  23.]
 [ 64.  23. 217.  23.   3.  54.]
 [  0.   0.   9. 125.   0.  36.]
 [ 90.   0.  12.   2. 194.   1.]
 [ 10.  13.  67.  70.   8. 213.]]
epoch: 11, train_loss: 8.870699882507324, train_acc: 67.31, train_fscore: 66.96, valid_loss: 7.436600208282471, valid_acc: 65.66, valid_fscore: 67.58, test_loss: 8.620100021362305, test_acc: 61.8, test_fscore: 62.95, time: 4.56 sec
epoch: 12, train_loss: 8.8125, train_acc: 67.8, train_fscore: 67.69, valid_loss: 7.3420000076293945, valid_acc: 65.21, valid_fscore: 67.86, test_loss: 8.535099983215332, test_acc: 60.44, test_fscore: 61.41, time: 4.45 sec
epoch: 13, train_loss: 8.718099594116211, train_acc: 67.57, train_fscore: 67.49, valid_loss: 7.145999908447266, valid_acc: 67.17, valid_fscore: 68.34, test_loss: 8.365599632263184, test_acc: 62.97, test_fscore: 63.87, time: 4.02 sec
epoch: 14, train_loss: 8.622699737548828, train_acc: 69.12, train_fscore: 68.84, valid_loss: 6.909900188446045, valid_acc: 69.28, valid_fscore: 69.74, test_loss: 8.189599990844727, test_acc: 64.45, test_fscore: 65.06, time: 4.16 sec
epoch: 15, train_loss: 8.506999969482422, train_acc: 69.69, train_fscore: 69.33, valid_loss: 6.8572001457214355, valid_acc: 69.43, valid_fscore: 71.0, test_loss: 8.200699806213379, test_acc: 62.91, test_fscore: 63.71, time: 3.07 sec
epoch: 16, train_loss: 8.45989990234375, train_acc: 69.59, train_fscore: 69.0, valid_loss: 6.847899913787842, valid_acc: 70.48, valid_fscore: 71.1, test_loss: 8.179400444030762, test_acc: 64.39, test_fscore: 64.88, time: 2.87 sec
epoch: 17, train_loss: 8.391200065612793, train_acc: 69.74, train_fscore: 69.09, valid_loss: 6.870800018310547, valid_acc: 69.28, valid_fscore: 70.36, test_loss: 8.11340045928955, test_acc: 64.63, test_fscore: 65.4, time: 4.02 sec
epoch: 18, train_loss: 8.31879997253418, train_acc: 71.55, train_fscore: 71.13, valid_loss: 6.922100067138672, valid_acc: 64.91, valid_fscore: 67.79, test_loss: 8.118900299072266, test_acc: 61.8, test_fscore: 62.74, time: 4.43 sec
epoch: 19, train_loss: 8.269399642944336, train_acc: 70.72, train_fscore: 70.43, valid_loss: 6.81879997253418, valid_acc: 69.13, valid_fscore: 70.52, test_loss: 8.086099624633789, test_acc: 64.88, test_fscore: 65.67, time: 4.57 sec
epoch: 20, train_loss: 8.203800201416016, train_acc: 72.91, train_fscore: 72.59, valid_loss: 6.713200092315674, valid_acc: 70.18, valid_fscore: 70.92, test_loss: 8.038299560546875, test_acc: 66.67, test_fscore: 67.18, time: 4.57 sec
              precision    recall  f1-score   support

           0     0.4198    0.6181    0.5000     144.0
           1     0.7586    0.7184    0.7379     245.0
           2     0.6611    0.6146    0.6370     384.0
           3     0.6231    0.7294    0.6721     170.0
           4     0.8537    0.7023    0.7706     299.0
           5     0.6552    0.6483    0.6517     381.0

    accuracy                         0.6667    1623.0
   macro avg     0.6619    0.6718    0.6616    1623.0
weighted avg     0.6845    0.6667    0.6718    1623.0

[[ 89.  10.  13.   3.  26.   3.]
 [  4. 176.  34.   2.   0.  29.]
 [ 46.  26. 236.  16.   5.  55.]
 [  0.   0.   5. 124.   0.  41.]
 [ 72.   0.  15.   0. 210.   2.]
 [  1.  20.  54.  54.   5. 247.]]
epoch: 21, train_loss: 8.132699966430664, train_acc: 73.44, train_fscore: 73.15, valid_loss: 6.761099815368652, valid_acc: 67.77, valid_fscore: 70.16, test_loss: 8.037599563598633, test_acc: 63.22, test_fscore: 64.19, time: 4.49 sec
epoch: 22, train_loss: 8.093700408935547, train_acc: 72.77, train_fscore: 72.58, valid_loss: 6.768199920654297, valid_acc: 68.07, valid_fscore: 70.0, test_loss: 8.019200325012207, test_acc: 64.76, test_fscore: 65.63, time: 3.65 sec
epoch: 23, train_loss: 8.034700393676758, train_acc: 73.24, train_fscore: 72.99, valid_loss: 6.711599826812744, valid_acc: 70.63, valid_fscore: 71.37, test_loss: 7.991199970245361, test_acc: 66.36, test_fscore: 66.9, time: 4.45 sec
epoch: 24, train_loss: 7.970699787139893, train_acc: 74.7, train_fscore: 74.42, valid_loss: 6.654399871826172, valid_acc: 70.03, valid_fscore: 71.3, test_loss: 7.957900047302246, test_acc: 66.11, test_fscore: 66.79, time: 4.0 sec
epoch: 25, train_loss: 7.912899971008301, train_acc: 75.71, train_fscore: 75.54, valid_loss: 6.648200035095215, valid_acc: 68.67, valid_fscore: 70.14, test_loss: 7.8933000564575195, test_acc: 66.24, test_fscore: 67.03, time: 3.84 sec
epoch: 26, train_loss: 7.909800052642822, train_acc: 75.09, train_fscore: 74.89, valid_loss: 6.61959981918335, valid_acc: 70.18, valid_fscore: 71.34, test_loss: 7.855599880218506, test_acc: 67.1, test_fscore: 67.72, time: 4.2 sec
epoch: 27, train_loss: 7.843400001525879, train_acc: 74.6, train_fscore: 74.29, valid_loss: 6.633500099182129, valid_acc: 70.78, valid_fscore: 72.33, test_loss: 7.904600143432617, test_acc: 66.73, test_fscore: 67.39, time: 4.23 sec
epoch: 28, train_loss: 7.816699981689453, train_acc: 75.38, train_fscore: 75.19, valid_loss: 6.619200229644775, valid_acc: 70.78, valid_fscore: 72.24, test_loss: 7.905300140380859, test_acc: 66.79, test_fscore: 67.46, time: 4.22 sec
epoch: 29, train_loss: 7.767899990081787, train_acc: 75.79, train_fscore: 75.61, valid_loss: 6.602099895477295, valid_acc: 69.88, valid_fscore: 71.05, test_loss: 7.801300048828125, test_acc: 67.59, test_fscore: 68.2, time: 4.51 sec
epoch: 30, train_loss: 7.7129998207092285, train_acc: 75.96, train_fscore: 75.77, valid_loss: 6.589600086212158, valid_acc: 70.33, valid_fscore: 71.91, test_loss: 7.745800018310547, test_acc: 67.59, test_fscore: 68.22, time: 4.54 sec
              precision    recall  f1-score   support

           0     0.4315    0.7222    0.5403     144.0
           1     0.7860    0.7347    0.7595     245.0
           2     0.6899    0.6432    0.6658     384.0
           3     0.6186    0.7059    0.6593     170.0
           4     0.8789    0.6555    0.7510     299.0
           5     0.6614    0.6562    0.6588     381.0

    accuracy                         0.6759    1623.0
   macro avg     0.6777    0.6863    0.6724    1623.0
weighted avg     0.7022    0.6759    0.6822    1623.0

[[104.   7.  13.   3.  15.   2.]
 [  4. 180.  26.   1.   0.  34.]
 [ 43.  26. 247.  18.   6.  44.]
 [  0.   0.   3. 120.   0.  47.]
 [ 90.   0.  12.   0. 196.   1.]
 [  0.  16.  57.  52.   6. 250.]]
epoch: 31, train_loss: 7.699100017547607, train_acc: 76.41, train_fscore: 76.22, valid_loss: 6.552299976348877, valid_acc: 70.03, valid_fscore: 71.43, test_loss: 7.723999977111816, test_acc: 67.53, test_fscore: 68.13, time: 4.42 sec
epoch: 32, train_loss: 7.678299903869629, train_acc: 76.37, train_fscore: 76.14, valid_loss: 6.5269999504089355, valid_acc: 71.39, valid_fscore: 72.47, test_loss: 7.741600036621094, test_acc: 67.96, test_fscore: 68.51, time: 4.5 sec
epoch: 33, train_loss: 7.64769983291626, train_acc: 77.4, train_fscore: 77.2, valid_loss: 6.567200183868408, valid_acc: 70.03, valid_fscore: 71.64, test_loss: 7.743899822235107, test_acc: 67.59, test_fscore: 68.24, time: 4.15 sec
epoch: 34, train_loss: 7.585599899291992, train_acc: 76.66, train_fscore: 76.51, valid_loss: 6.564300060272217, valid_acc: 69.73, valid_fscore: 71.38, test_loss: 7.723199844360352, test_acc: 66.85, test_fscore: 67.52, time: 4.65 sec
epoch: 35, train_loss: 7.565700054168701, train_acc: 77.28, train_fscore: 77.07, valid_loss: 6.527299880981445, valid_acc: 71.08, valid_fscore: 72.08, test_loss: 7.688499927520752, test_acc: 67.96, test_fscore: 68.54, time: 4.51 sec
epoch: 36, train_loss: 7.531199932098389, train_acc: 78.6, train_fscore: 78.5, valid_loss: 6.523900032043457, valid_acc: 72.29, valid_fscore: 73.35, test_loss: 7.6743998527526855, test_acc: 67.71, test_fscore: 68.34, time: 4.46 sec
epoch: 37, train_loss: 7.50629997253418, train_acc: 78.37, train_fscore: 78.19, valid_loss: 6.495800018310547, valid_acc: 71.39, valid_fscore: 72.42, test_loss: 7.640500068664551, test_acc: 67.78, test_fscore: 68.34, time: 3.31 sec
epoch: 38, train_loss: 7.484099864959717, train_acc: 78.1, train_fscore: 77.9, valid_loss: 6.49560022354126, valid_acc: 72.74, valid_fscore: 73.64, test_loss: 7.629799842834473, test_acc: 68.21, test_fscore: 68.78, time: 4.12 sec
epoch: 39, train_loss: 7.450500011444092, train_acc: 79.54, train_fscore: 79.4, valid_loss: 6.502600193023682, valid_acc: 70.93, valid_fscore: 71.95, test_loss: 7.635900020599365, test_acc: 68.02, test_fscore: 68.62, time: 3.28 sec
epoch: 40, train_loss: 7.423799991607666, train_acc: 79.38, train_fscore: 79.26, valid_loss: 6.503200054168701, valid_acc: 70.03, valid_fscore: 71.1, test_loss: 7.646900177001953, test_acc: 67.59, test_fscore: 68.22, time: 4.55 sec
              precision    recall  f1-score   support

           0     0.4303    0.7292    0.5412     144.0
           1     0.7872    0.7551    0.7708     245.0
           2     0.7273    0.6250    0.6723     384.0
           3     0.5804    0.7647    0.6599     170.0
           4     0.8829    0.6555    0.7524     299.0
           5     0.6549    0.6325    0.6435     381.0

    accuracy                         0.6759    1623.0
   macro avg     0.6772    0.6937    0.6734    1623.0
weighted avg     0.7063    0.6759    0.6822    1623.0

[[105.   7.  13.   2.  15.   2.]
 [  3. 185.  21.   2.   0.  34.]
 [ 45.  24. 240.  18.   5.  52.]
 [  0.   0.   3. 130.   0.  37.]
 [ 90.   1.  10.   0. 196.   2.]
 [  1.  18.  43.  72.   6. 241.]]
epoch: 41, train_loss: 7.390900135040283, train_acc: 78.95, train_fscore: 78.79, valid_loss: 6.4893999099731445, valid_acc: 70.48, valid_fscore: 71.6, test_loss: 7.6128997802734375, test_acc: 67.96, test_fscore: 68.54, time: 4.07 sec
epoch: 42, train_loss: 7.372300148010254, train_acc: 80.06, train_fscore: 79.93, valid_loss: 6.5279998779296875, valid_acc: 70.78, valid_fscore: 72.06, test_loss: 7.599299907684326, test_acc: 68.02, test_fscore: 68.68, time: 4.42 sec
epoch: 43, train_loss: 7.335999965667725, train_acc: 80.02, train_fscore: 79.9, valid_loss: 6.5258002281188965, valid_acc: 70.78, valid_fscore: 72.0, test_loss: 7.609099864959717, test_acc: 67.59, test_fscore: 68.24, time: 4.36 sec
epoch: 44, train_loss: 7.3267998695373535, train_acc: 80.39, train_fscore: 80.28, valid_loss: 6.484300136566162, valid_acc: 72.14, valid_fscore: 73.02, test_loss: 7.607399940490723, test_acc: 67.9, test_fscore: 68.49, time: 4.54 sec
epoch: 45, train_loss: 7.298099994659424, train_acc: 80.0, train_fscore: 79.85, valid_loss: 6.481400012969971, valid_acc: 71.69, valid_fscore: 72.69, test_loss: 7.582300186157227, test_acc: 68.02, test_fscore: 68.63, time: 4.5 sec
epoch: 46, train_loss: 7.268099784851074, train_acc: 81.07, train_fscore: 80.97, valid_loss: 6.507299900054932, valid_acc: 71.23, valid_fscore: 72.49, test_loss: 7.587699890136719, test_acc: 67.41, test_fscore: 68.01, time: 4.54 sec
epoch: 47, train_loss: 7.256999969482422, train_acc: 80.99, train_fscore: 80.84, valid_loss: 6.479899883270264, valid_acc: 71.84, valid_fscore: 72.72, test_loss: 7.548699855804443, test_acc: 68.88, test_fscore: 69.45, time: 4.24 sec
epoch: 48, train_loss: 7.235499858856201, train_acc: 81.13, train_fscore: 81.03, valid_loss: 6.4695000648498535, valid_acc: 71.69, valid_fscore: 72.38, test_loss: 7.528299808502197, test_acc: 69.25, test_fscore: 69.84, time: 4.37 sec
epoch: 49, train_loss: 7.213900089263916, train_acc: 81.19, train_fscore: 81.07, valid_loss: 6.494100093841553, valid_acc: 70.78, valid_fscore: 71.88, test_loss: 7.57889986038208, test_acc: 67.47, test_fscore: 68.11, time: 2.79 sec
epoch: 50, train_loss: 7.189300060272217, train_acc: 81.34, train_fscore: 81.2, valid_loss: 6.447199821472168, valid_acc: 71.84, valid_fscore: 72.81, test_loss: 7.549900054931641, test_acc: 68.58, test_fscore: 69.19, time: 4.22 sec
              precision    recall  f1-score   support

           0     0.4378    0.7569    0.5547     144.0
           1     0.7949    0.7592    0.7766     245.0
           2     0.7167    0.6589    0.6866     384.0
           3     0.6302    0.7118    0.6685     170.0
           4     0.8910    0.6288    0.7373     299.0
           5     0.6667    0.6719    0.6693     381.0

    accuracy                         0.6858    1623.0
   macro avg     0.6895    0.6979    0.6822    1623.0
weighted avg     0.7151    0.6858    0.6919    1623.0

[[109.   7.  13.   0.  13.   2.]
 [  2. 186.  24.   2.   0.  31.]
 [ 43.  23. 253.  14.   4.  47.]
 [  0.   0.   3. 121.   0.  46.]
 [ 94.   1.  14.   0. 188.   2.]
 [  1.  17.  46.  55.   6. 256.]]
epoch: 51, train_loss: 7.173799991607666, train_acc: 81.75, train_fscore: 81.63, valid_loss: 6.475399971008301, valid_acc: 72.44, valid_fscore: 73.24, test_loss: 7.559100151062012, test_acc: 68.45, test_fscore: 69.03, time: 4.57 sec
epoch: 52, train_loss: 7.1493000984191895, train_acc: 82.3, train_fscore: 82.18, valid_loss: 6.476900100708008, valid_acc: 72.14, valid_fscore: 72.92, test_loss: 7.518400192260742, test_acc: 68.76, test_fscore: 69.3, time: 4.31 sec
epoch: 53, train_loss: 7.125199794769287, train_acc: 81.71, train_fscore: 81.61, valid_loss: 6.5295000076293945, valid_acc: 71.23, valid_fscore: 72.19, test_loss: 7.529300212860107, test_acc: 68.58, test_fscore: 69.21, time: 4.12 sec
epoch: 54, train_loss: 7.12470006942749, train_acc: 81.56, train_fscore: 81.44, valid_loss: 6.551400184631348, valid_acc: 70.63, valid_fscore: 71.59, test_loss: 7.526899814605713, test_acc: 68.27, test_fscore: 68.82, time: 4.56 sec
epoch: 55, train_loss: 7.115600109100342, train_acc: 82.2, train_fscore: 82.02, valid_loss: 6.5295000076293945, valid_acc: 72.14, valid_fscore: 73.05, test_loss: 7.533599853515625, test_acc: 69.32, test_fscore: 69.83, time: 4.29 sec
epoch: 56, train_loss: 7.073299884796143, train_acc: 83.37, train_fscore: 83.28, valid_loss: 6.500500202178955, valid_acc: 71.84, valid_fscore: 72.8, test_loss: 7.5680999755859375, test_acc: 68.52, test_fscore: 69.11, time: 4.32 sec
epoch: 57, train_loss: 7.072700023651123, train_acc: 82.26, train_fscore: 82.14, valid_loss: 6.478099822998047, valid_acc: 72.29, valid_fscore: 72.87, test_loss: 7.5366997718811035, test_acc: 69.13, test_fscore: 69.71, time: 4.6 sec
epoch: 58, train_loss: 7.042600154876709, train_acc: 82.96, train_fscore: 82.81, valid_loss: 6.53380012512207, valid_acc: 71.69, valid_fscore: 72.5, test_loss: 7.480199813842773, test_acc: 70.36, test_fscore: 70.95, time: 4.48 sec
epoch: 59, train_loss: 7.028299808502197, train_acc: 83.58, train_fscore: 83.52, valid_loss: 6.547500133514404, valid_acc: 71.84, valid_fscore: 72.96, test_loss: 7.541800022125244, test_acc: 67.84, test_fscore: 68.43, time: 3.68 sec
epoch: 60, train_loss: 6.997300148010254, train_acc: 83.89, train_fscore: 83.77, valid_loss: 6.482999801635742, valid_acc: 73.49, valid_fscore: 74.01, test_loss: 7.539400100708008, test_acc: 69.01, test_fscore: 69.51, time: 4.29 sec
              precision    recall  f1-score   support

           0     0.4564    0.7639    0.5714     144.0
           1     0.8093    0.7796    0.7942     245.0
           2     0.6997    0.6797    0.6896     384.0
           3     0.6085    0.7588    0.6754     170.0
           4     0.8889    0.6421    0.7456     299.0
           5     0.6870    0.6220    0.6529     381.0

    accuracy                         0.6901    1623.0
   macro avg     0.6916    0.7077    0.6882    1623.0
weighted avg     0.7170    0.6901    0.6951    1623.0

[[110.   5.  14.   0.  14.   1.]
 [  2. 191.  22.   2.   0.  28.]
 [ 43.  23. 261.  13.   4.  40.]
 [  0.   0.   3. 129.   0.  38.]
 [ 86.   1.  19.   0. 192.   1.]
 [  0.  16.  54.  68.   6. 237.]]
epoch: 61, train_loss: 6.994800090789795, train_acc: 83.89, train_fscore: 83.75, valid_loss: 6.488399982452393, valid_acc: 73.19, valid_fscore: 73.74, test_loss: 7.523900032043457, test_acc: 70.36, test_fscore: 70.91, time: 3.51 sec
epoch: 62, train_loss: 6.989699840545654, train_acc: 83.85, train_fscore: 83.76, valid_loss: 6.497300148010254, valid_acc: 72.44, valid_fscore: 73.04, test_loss: 7.505899906158447, test_acc: 69.75, test_fscore: 70.27, time: 4.49 sec
epoch: 63, train_loss: 6.972799777984619, train_acc: 83.87, train_fscore: 83.73, valid_loss: 6.530900001525879, valid_acc: 71.99, valid_fscore: 72.93, test_loss: 7.509799957275391, test_acc: 69.62, test_fscore: 70.19, time: 4.44 sec
epoch: 64, train_loss: 6.951300144195557, train_acc: 84.3, train_fscore: 84.24, valid_loss: 6.529399871826172, valid_acc: 72.74, valid_fscore: 73.52, test_loss: 7.515500068664551, test_acc: 69.62, test_fscore: 70.14, time: 4.55 sec
epoch: 65, train_loss: 6.940199851989746, train_acc: 84.3, train_fscore: 84.22, valid_loss: 6.495699882507324, valid_acc: 73.34, valid_fscore: 73.89, test_loss: 7.549099922180176, test_acc: 69.01, test_fscore: 69.44, time: 4.41 sec
epoch: 66, train_loss: 6.894000053405762, train_acc: 84.71, train_fscore: 84.53, valid_loss: 6.4944000244140625, valid_acc: 72.89, valid_fscore: 73.49, test_loss: 7.522200107574463, test_acc: 69.38, test_fscore: 69.88, time: 3.83 sec
epoch: 67, train_loss: 6.921500205993652, train_acc: 84.9, train_fscore: 84.78, valid_loss: 6.529300212860107, valid_acc: 73.19, valid_fscore: 73.99, test_loss: 7.537899971008301, test_acc: 69.5, test_fscore: 70.07, time: 4.56 sec
epoch: 68, train_loss: 6.886499881744385, train_acc: 84.88, train_fscore: 84.81, valid_loss: 6.537199974060059, valid_acc: 72.74, valid_fscore: 73.52, test_loss: 7.530099868774414, test_acc: 69.5, test_fscore: 69.99, time: 4.78 sec
epoch: 69, train_loss: 6.8607001304626465, train_acc: 85.15, train_fscore: 85.03, valid_loss: 6.557700157165527, valid_acc: 71.99, valid_fscore: 72.55, test_loss: 7.5121002197265625, test_acc: 69.99, test_fscore: 70.53, time: 4.44 sec
epoch: 70, train_loss: 6.833000183105469, train_acc: 85.54, train_fscore: 85.45, valid_loss: 6.578400135040283, valid_acc: 72.44, valid_fscore: 73.01, test_loss: 7.4984002113342285, test_acc: 70.18, test_fscore: 70.74, time: 4.19 sec
              precision    recall  f1-score   support

           0     0.4711    0.7917    0.5907     144.0
           1     0.8416    0.7592    0.7983     245.0
           2     0.7265    0.6849    0.7051     384.0
           3     0.6413    0.6941    0.6667     170.0
           4     0.8869    0.6555    0.7538     299.0
           5     0.6667    0.6877    0.6770     381.0

    accuracy                         0.7018    1623.0
   macro avg     0.7057    0.7122    0.6986    1623.0
weighted avg     0.7278    0.7018    0.7074    1623.0

[[114.   4.  11.   0.  14.   1.]
 [  4. 186.  23.   1.   0.  31.]
 [ 40.  17. 263.  11.   4.  49.]
 [  0.   0.   4. 118.   0.  48.]
 [ 83.   2.  16.   0. 196.   2.]
 [  1.  12.  45.  54.   7. 262.]]
epoch: 71, train_loss: 6.8277997970581055, train_acc: 85.6, train_fscore: 85.52, valid_loss: 6.559500217437744, valid_acc: 72.59, valid_fscore: 73.43, test_loss: 7.5777997970581055, test_acc: 68.95, test_fscore: 69.39, time: 1.96 sec
epoch: 72, train_loss: 6.814300060272217, train_acc: 84.88, train_fscore: 84.73, valid_loss: 6.537600040435791, valid_acc: 72.89, valid_fscore: 73.47, test_loss: 7.565000057220459, test_acc: 69.56, test_fscore: 70.05, time: 1.98 sec
epoch: 73, train_loss: 6.801499843597412, train_acc: 85.95, train_fscore: 85.87, valid_loss: 6.567699909210205, valid_acc: 73.04, valid_fscore: 73.66, test_loss: 7.565199851989746, test_acc: 70.36, test_fscore: 70.88, time: 1.95 sec
epoch: 74, train_loss: 6.786600112915039, train_acc: 85.97, train_fscore: 85.89, valid_loss: 6.5472002029418945, valid_acc: 73.34, valid_fscore: 73.84, test_loss: 7.520699977874756, test_acc: 70.18, test_fscore: 70.64, time: 1.99 sec
epoch: 75, train_loss: 6.791500091552734, train_acc: 86.09, train_fscore: 85.98, valid_loss: 6.561200141906738, valid_acc: 73.19, valid_fscore: 73.62, test_loss: 7.507900238037109, test_acc: 70.67, test_fscore: 71.14, time: 1.96 sec
epoch: 76, train_loss: 6.768499851226807, train_acc: 86.11, train_fscore: 86.02, valid_loss: 6.610300064086914, valid_acc: 72.44, valid_fscore: 73.28, test_loss: 7.555500030517578, test_acc: 70.18, test_fscore: 70.67, time: 1.9 sec
epoch: 77, train_loss: 6.743800163269043, train_acc: 86.53, train_fscore: 86.43, valid_loss: 6.60290002822876, valid_acc: 73.19, valid_fscore: 73.81, test_loss: 7.556000232696533, test_acc: 69.87, test_fscore: 70.32, time: 1.96 sec
epoch: 78, train_loss: 6.742599964141846, train_acc: 86.77, train_fscore: 86.67, valid_loss: 6.616600036621094, valid_acc: 72.14, valid_fscore: 72.91, test_loss: 7.618599891662598, test_acc: 69.25, test_fscore: 69.8, time: 1.95 sec
epoch: 79, train_loss: 6.742499828338623, train_acc: 86.36, train_fscore: 86.29, valid_loss: 6.61359977722168, valid_acc: 72.59, valid_fscore: 73.12, test_loss: 7.552000045776367, test_acc: 70.12, test_fscore: 70.56, time: 1.89 sec
epoch: 80, train_loss: 6.715000152587891, train_acc: 87.04, train_fscore: 86.92, valid_loss: 6.628399848937988, valid_acc: 73.34, valid_fscore: 73.95, test_loss: 7.517499923706055, test_acc: 70.86, test_fscore: 71.28, time: 1.97 sec
              precision    recall  f1-score   support

           0     0.4957    0.7917    0.6096     144.0
           1     0.8378    0.7592    0.7966     245.0
           2     0.6963    0.7344    0.7148     384.0
           3     0.6410    0.7353    0.6849     170.0
           4     0.8955    0.6589    0.7592     299.0
           5     0.7009    0.6457    0.6721     381.0

    accuracy                         0.7086    1623.0
   macro avg     0.7112    0.7208    0.7062    1623.0
weighted avg     0.7318    0.7086    0.7128    1623.0

[[114.   4.  13.   0.  12.   1.]
 [  3. 186.  25.   3.   0.  28.]
 [ 35.  17. 282.  10.   4.  36.]
 [  0.   0.   6. 125.   0.  39.]
 [ 78.   2.  21.   0. 197.   1.]
 [  0.  13.  58.  57.   7. 246.]]
epoch: 81, train_loss: 6.7144999504089355, train_acc: 87.56, train_fscore: 87.48, valid_loss: 6.626299858093262, valid_acc: 71.84, valid_fscore: 72.68, test_loss: 7.525100231170654, test_acc: 70.06, test_fscore: 70.6, time: 1.93 sec
epoch: 82, train_loss: 6.683800220489502, train_acc: 87.0, train_fscore: 86.9, valid_loss: 6.627200126647949, valid_acc: 72.44, valid_fscore: 72.99, test_loss: 7.519400119781494, test_acc: 70.67, test_fscore: 71.15, time: 1.9 sec
epoch: 83, train_loss: 6.710000038146973, train_acc: 87.1, train_fscore: 86.98, valid_loss: 6.647299766540527, valid_acc: 74.1, valid_fscore: 74.69, test_loss: 7.585599899291992, test_acc: 70.55, test_fscore: 71.03, time: 1.92 sec
epoch: 84, train_loss: 6.670100212097168, train_acc: 87.19, train_fscore: 87.12, valid_loss: 6.655399799346924, valid_acc: 73.19, valid_fscore: 73.86, test_loss: 7.5742998123168945, test_acc: 70.3, test_fscore: 70.78, time: 1.98 sec
epoch: 85, train_loss: 6.6579999923706055, train_acc: 87.39, train_fscore: 87.29, valid_loss: 6.664999961853027, valid_acc: 73.04, valid_fscore: 73.53, test_loss: 7.5254998207092285, test_acc: 70.67, test_fscore: 71.14, time: 1.98 sec
epoch: 86, train_loss: 6.64169979095459, train_acc: 88.01, train_fscore: 87.93, valid_loss: 6.712800025939941, valid_acc: 72.59, valid_fscore: 73.42, test_loss: 7.622300148010254, test_acc: 69.75, test_fscore: 70.28, time: 2.03 sec
epoch: 87, train_loss: 6.621500015258789, train_acc: 87.89, train_fscore: 87.86, valid_loss: 6.645699977874756, valid_acc: 73.95, valid_fscore: 74.26, test_loss: 7.597700119018555, test_acc: 70.61, test_fscore: 71.06, time: 1.98 sec
epoch: 88, train_loss: 6.621500015258789, train_acc: 88.3, train_fscore: 88.2, valid_loss: 6.634900093078613, valid_acc: 73.64, valid_fscore: 74.05, test_loss: 7.583799839019775, test_acc: 71.41, test_fscore: 71.86, time: 1.94 sec
epoch: 89, train_loss: 6.596499919891357, train_acc: 87.84, train_fscore: 87.74, valid_loss: 6.640399932861328, valid_acc: 74.1, valid_fscore: 74.68, test_loss: 7.614999771118164, test_acc: 70.12, test_fscore: 70.63, time: 1.96 sec
epoch: 90, train_loss: 6.608799934387207, train_acc: 88.17, train_fscore: 88.09, valid_loss: 6.667699813842773, valid_acc: 73.8, valid_fscore: 74.31, test_loss: 7.576700210571289, test_acc: 70.12, test_fscore: 70.58, time: 1.91 sec
              precision    recall  f1-score   support

           0     0.4914    0.7917    0.6064     144.0
           1     0.8512    0.7469    0.7957     245.0
           2     0.6915    0.7240    0.7074     384.0
           3     0.6345    0.7353    0.6812     170.0
           4     0.9038    0.6288    0.7416     299.0
           5     0.6775    0.6562    0.6667     381.0

    accuracy                         0.7012    1623.0
   macro avg     0.7083    0.7138    0.6998    1623.0
weighted avg     0.7277    0.7012    0.7058    1623.0

[[114.   4.  15.   0.  10.   1.]
 [  3. 183.  25.   2.   0.  32.]
 [ 32.  17. 278.  10.   4.  43.]
 [  0.   0.   3. 125.   0.  42.]
 [ 83.   1.  26.   0. 188.   1.]
 [  0.  10.  55.  60.   6. 250.]]
epoch: 91, train_loss: 6.591100215911865, train_acc: 88.48, train_fscore: 88.4, valid_loss: 6.693999767303467, valid_acc: 72.29, valid_fscore: 73.02, test_loss: 7.553599834442139, test_acc: 71.29, test_fscore: 71.75, time: 1.92 sec
epoch: 92, train_loss: 6.5696001052856445, train_acc: 88.79, train_fscore: 88.72, valid_loss: 6.637800216674805, valid_acc: 72.14, valid_fscore: 72.83, test_loss: 7.604700088500977, test_acc: 70.36, test_fscore: 70.84, time: 2.1 sec
epoch: 93, train_loss: 6.541999816894531, train_acc: 88.87, train_fscore: 88.77, valid_loss: 6.610400199890137, valid_acc: 73.95, valid_fscore: 74.27, test_loss: 7.619900226593018, test_acc: 70.12, test_fscore: 70.58, time: 2.03 sec
epoch: 94, train_loss: 6.54640007019043, train_acc: 88.67, train_fscore: 88.59, valid_loss: 6.692500114440918, valid_acc: 73.95, valid_fscore: 74.24, test_loss: 7.582900047302246, test_acc: 71.16, test_fscore: 71.61, time: 1.93 sec
epoch: 95, train_loss: 6.532899856567383, train_acc: 89.53, train_fscore: 89.48, valid_loss: 6.752399921417236, valid_acc: 72.29, valid_fscore: 73.09, test_loss: 7.619999885559082, test_acc: 70.18, test_fscore: 70.69, time: 1.93 sec
epoch: 96, train_loss: 6.530200004577637, train_acc: 88.59, train_fscore: 88.5, valid_loss: 6.697700023651123, valid_acc: 74.25, valid_fscore: 74.6, test_loss: 7.624000072479248, test_acc: 70.3, test_fscore: 70.74, time: 1.97 sec
epoch: 97, train_loss: 6.539100170135498, train_acc: 89.33, train_fscore: 89.26, valid_loss: 6.69890022277832, valid_acc: 74.1, valid_fscore: 74.5, test_loss: 7.655399799346924, test_acc: 70.3, test_fscore: 70.75, time: 1.97 sec
epoch: 98, train_loss: 6.477200031280518, train_acc: 88.96, train_fscore: 88.88, valid_loss: 6.757999897003174, valid_acc: 73.49, valid_fscore: 73.94, test_loss: 7.62939977645874, test_acc: 70.98, test_fscore: 71.38, time: 1.96 sec
epoch: 99, train_loss: 6.4633002281188965, train_acc: 89.47, train_fscore: 89.39, valid_loss: 6.730500221252441, valid_acc: 73.8, valid_fscore: 74.09, test_loss: 7.609499931335449, test_acc: 71.16, test_fscore: 71.56, time: 2.31 sec
epoch: 100, train_loss: 6.4770002365112305, train_acc: 89.78, train_fscore: 89.71, valid_loss: 6.694799900054932, valid_acc: 73.95, valid_fscore: 74.41, test_loss: 7.716700077056885, test_acc: 69.81, test_fscore: 70.26, time: 2.08 sec
              precision    recall  f1-score   support

           0     0.4797    0.8194    0.6051     144.0
           1     0.8333    0.7551    0.7923     245.0
           2     0.6939    0.7083    0.7010     384.0
           3     0.6593    0.7059    0.6818     170.0
           4     0.9095    0.6054    0.7269     299.0
           5     0.6728    0.6745    0.6737     381.0

    accuracy                         0.6981    1623.0
   macro avg     0.7081    0.7114    0.6968    1623.0
weighted avg     0.7271    0.6981    0.7026    1623.0

[[118.   4.  12.   0.   9.   1.]
 [  3. 185.  23.   2.   0.  32.]
 [ 38.  17. 272.   8.   3.  46.]
 [  0.   1.   5. 120.   0.  44.]
 [ 87.   2.  27.   0. 181.   2.]
 [  0.  13.  53.  52.   6. 257.]]
epoch: 101, train_loss: 6.480400085449219, train_acc: 89.66, train_fscore: 89.59, valid_loss: 6.714099884033203, valid_acc: 73.8, valid_fscore: 74.2, test_loss: 7.696599960327148, test_acc: 70.24, test_fscore: 70.72, time: 3.16 sec
epoch: 102, train_loss: 6.487800121307373, train_acc: 90.17, train_fscore: 90.1, valid_loss: 6.716400146484375, valid_acc: 73.8, valid_fscore: 74.13, test_loss: 7.659599781036377, test_acc: 70.92, test_fscore: 71.34, time: 2.2 sec
epoch: 103, train_loss: 6.454699993133545, train_acc: 90.28, train_fscore: 90.22, valid_loss: 6.7058000564575195, valid_acc: 73.64, valid_fscore: 74.03, test_loss: 7.651199817657471, test_acc: 70.67, test_fscore: 71.11, time: 1.97 sec
epoch: 104, train_loss: 6.452099800109863, train_acc: 90.19, train_fscore: 90.11, valid_loss: 6.750800132751465, valid_acc: 73.95, valid_fscore: 74.26, test_loss: 7.6290998458862305, test_acc: 70.73, test_fscore: 71.19, time: 1.95 sec
epoch: 105, train_loss: 6.446000099182129, train_acc: 90.03, train_fscore: 89.97, valid_loss: 6.741600036621094, valid_acc: 74.1, valid_fscore: 74.32, test_loss: 7.593800067901611, test_acc: 71.35, test_fscore: 71.74, time: 2.92 sec
epoch: 106, train_loss: 6.422800064086914, train_acc: 90.83, train_fscore: 90.77, valid_loss: 6.742700099945068, valid_acc: 74.55, valid_fscore: 74.94, test_loss: 7.627200126647949, test_acc: 71.1, test_fscore: 71.49, time: 4.5 sec
epoch: 107, train_loss: 6.433499813079834, train_acc: 90.4, train_fscore: 90.33, valid_loss: 6.78249979019165, valid_acc: 73.04, valid_fscore: 73.38, test_loss: 7.676300048828125, test_acc: 71.47, test_fscore: 71.92, time: 2.86 sec
epoch: 108, train_loss: 6.410099983215332, train_acc: 90.69, train_fscore: 90.64, valid_loss: 6.7729997634887695, valid_acc: 73.8, valid_fscore: 74.16, test_loss: 7.7129998207092285, test_acc: 71.04, test_fscore: 71.46, time: 4.57 sec
epoch: 109, train_loss: 6.3734002113342285, train_acc: 90.96, train_fscore: 90.91, valid_loss: 6.780700206756592, valid_acc: 74.7, valid_fscore: 74.92, test_loss: 7.651500225067139, test_acc: 70.86, test_fscore: 71.25, time: 4.56 sec
epoch: 110, train_loss: 6.410900115966797, train_acc: 90.63, train_fscore: 90.55, valid_loss: 6.803800106048584, valid_acc: 73.8, valid_fscore: 74.08, test_loss: 7.629000186920166, test_acc: 71.78, test_fscore: 72.15, time: 4.48 sec
              precision    recall  f1-score   support

           0     0.5283    0.7778    0.6292     144.0
           1     0.8409    0.7551    0.7957     245.0
           2     0.7032    0.7344    0.7185     384.0
           3     0.6667    0.7294    0.6966     170.0
           4     0.8943    0.6789    0.7719     299.0
           5     0.6870    0.6798    0.6834     381.0

    accuracy                         0.7178    1623.0
   macro avg     0.7201    0.7259    0.7159    1623.0
weighted avg     0.7361    0.7178    0.7215    1623.0

[[112.   4.  13.   0.  14.   1.]
 [  2. 185.  25.   2.   0.  31.]
 [ 31.  17. 282.   8.   4.  42.]
 [  0.   0.   3. 124.   0.  43.]
 [ 67.   2.  26.   0. 203.   1.]
 [  0.  12.  52.  52.   6. 259.]]
epoch: 111, train_loss: 6.3815999031066895, train_acc: 91.02, train_fscore: 90.96, valid_loss: 6.73199987411499, valid_acc: 73.8, valid_fscore: 74.03, test_loss: 7.671000003814697, test_acc: 71.47, test_fscore: 71.86, time: 4.38 sec
epoch: 112, train_loss: 6.364099979400635, train_acc: 91.33, train_fscore: 91.28, valid_loss: 6.776500225067139, valid_acc: 73.49, valid_fscore: 73.72, test_loss: 7.667300224304199, test_acc: 71.9, test_fscore: 72.32, time: 4.47 sec
epoch: 113, train_loss: 6.370800018310547, train_acc: 91.0, train_fscore: 90.94, valid_loss: 6.837900161743164, valid_acc: 73.49, valid_fscore: 73.76, test_loss: 7.635200023651123, test_acc: 72.4, test_fscore: 72.77, time: 4.25 sec
epoch: 114, train_loss: 6.365600109100342, train_acc: 91.12, train_fscore: 91.06, valid_loss: 6.766900062561035, valid_acc: 74.25, valid_fscore: 74.48, test_loss: 7.659599781036377, test_acc: 71.84, test_fscore: 72.19, time: 3.62 sec
epoch: 115, train_loss: 6.329999923706055, train_acc: 91.45, train_fscore: 91.39, valid_loss: 6.7891998291015625, valid_acc: 73.49, valid_fscore: 73.71, test_loss: 7.695700168609619, test_acc: 71.41, test_fscore: 71.76, time: 4.26 sec
epoch: 116, train_loss: 6.347599983215332, train_acc: 91.45, train_fscore: 91.4, valid_loss: 6.834799766540527, valid_acc: 73.19, valid_fscore: 73.47, test_loss: 7.609899997711182, test_acc: 72.15, test_fscore: 72.54, time: 4.5 sec
epoch: 117, train_loss: 6.332300186157227, train_acc: 91.27, train_fscore: 91.22, valid_loss: 6.826300144195557, valid_acc: 73.8, valid_fscore: 74.11, test_loss: 7.696000099182129, test_acc: 71.04, test_fscore: 71.47, time: 4.04 sec
epoch: 118, train_loss: 6.322800159454346, train_acc: 91.31, train_fscore: 91.26, valid_loss: 6.7993998527526855, valid_acc: 74.55, valid_fscore: 74.73, test_loss: 7.785200119018555, test_acc: 70.67, test_fscore: 71.05, time: 4.49 sec
epoch: 119, train_loss: 6.304500102996826, train_acc: 92.01, train_fscore: 91.96, valid_loss: 6.819900035858154, valid_acc: 73.64, valid_fscore: 73.9, test_loss: 7.7530999183654785, test_acc: 71.23, test_fscore: 71.62, time: 4.52 sec
epoch: 120, train_loss: 6.289999961853027, train_acc: 91.92, train_fscore: 91.86, valid_loss: 6.899899959564209, valid_acc: 73.19, valid_fscore: 73.3, test_loss: 7.690800189971924, test_acc: 72.09, test_fscore: 72.43, time: 4.28 sec
              precision    recall  f1-score   support

           0     0.5357    0.7292    0.6176     144.0
           1     0.8378    0.7592    0.7966     245.0
           2     0.7128    0.7240    0.7183     384.0
           3     0.6580    0.7471    0.6997     170.0
           4     0.8782    0.6990    0.7784     299.0
           5     0.6901    0.6955    0.6928     381.0

    accuracy                         0.7209    1623.0
   macro avg     0.7188    0.7257    0.7173    1623.0
weighted avg     0.7354    0.7209    0.7243    1623.0

[[105.   4.  15.   0.  19.   1.]
 [  2. 186.  24.   3.   0.  30.]
 [ 29.  17. 278.   9.   4.  47.]
 [  0.   1.   3. 127.   0.  39.]
 [ 60.   2.  26.   0. 209.   2.]
 [  0.  12.  44.  54.   6. 265.]]
epoch: 121, train_loss: 6.287899971008301, train_acc: 91.97, train_fscore: 91.92, valid_loss: 6.913899898529053, valid_acc: 73.64, valid_fscore: 73.88, test_loss: 7.706900119781494, test_acc: 71.6, test_fscore: 71.95, time: 4.58 sec
epoch: 122, train_loss: 6.271100044250488, train_acc: 91.74, train_fscore: 91.7, valid_loss: 6.885700225830078, valid_acc: 74.25, valid_fscore: 74.53, test_loss: 7.739500045776367, test_acc: 71.35, test_fscore: 71.69, time: 4.3 sec
epoch: 123, train_loss: 6.289899826049805, train_acc: 92.05, train_fscore: 91.99, valid_loss: 6.9217000007629395, valid_acc: 73.49, valid_fscore: 73.52, test_loss: 7.722499847412109, test_acc: 71.6, test_fscore: 71.92, time: 4.53 sec
epoch: 124, train_loss: 6.259099960327148, train_acc: 92.21, train_fscore: 92.17, valid_loss: 6.957799911499023, valid_acc: 73.64, valid_fscore: 73.97, test_loss: 7.787300109863281, test_acc: 71.16, test_fscore: 71.54, time: 4.14 sec
epoch: 125, train_loss: 6.261099815368652, train_acc: 92.38, train_fscore: 92.32, valid_loss: 6.990699768066406, valid_acc: 72.89, valid_fscore: 73.36, test_loss: 7.779300212860107, test_acc: 71.35, test_fscore: 71.75, time: 4.48 sec
epoch: 126, train_loss: 6.261600017547607, train_acc: 91.92, train_fscore: 91.87, valid_loss: 7.010000228881836, valid_acc: 73.34, valid_fscore: 73.51, test_loss: 7.751699924468994, test_acc: 71.97, test_fscore: 72.35, time: 3.86 sec
epoch: 127, train_loss: 6.263899803161621, train_acc: 92.4, train_fscore: 92.36, valid_loss: 6.9532999992370605, valid_acc: 74.1, valid_fscore: 74.28, test_loss: 7.823299884796143, test_acc: 70.79, test_fscore: 71.14, time: 4.55 sec
epoch: 128, train_loss: 6.240699768066406, train_acc: 92.25, train_fscore: 92.19, valid_loss: 6.997300148010254, valid_acc: 72.29, valid_fscore: 72.71, test_loss: 7.7621002197265625, test_acc: 71.78, test_fscore: 72.2, time: 4.42 sec
epoch: 129, train_loss: 6.219200134277344, train_acc: 92.5, train_fscore: 92.46, valid_loss: 7.021599769592285, valid_acc: 72.59, valid_fscore: 72.67, test_loss: 7.7154998779296875, test_acc: 72.21, test_fscore: 72.57, time: 4.09 sec
epoch: 130, train_loss: 6.239699840545654, train_acc: 92.46, train_fscore: 92.41, valid_loss: 6.973100185394287, valid_acc: 73.34, valid_fscore: 73.55, test_loss: 7.803800106048584, test_acc: 71.66, test_fscore: 72.01, time: 4.53 sec
              precision    recall  f1-score   support

           0     0.5280    0.7847    0.6313     144.0
           1     0.8472    0.7469    0.7939     245.0
           2     0.6940    0.7500    0.7209     384.0
           3     0.6776    0.7294    0.7025     170.0
           4     0.8919    0.6622    0.7601     299.0
           5     0.6890    0.6745    0.6817     381.0

    accuracy                         0.7166    1623.0
   macro avg     0.7213    0.7246    0.7151    1623.0
weighted avg     0.7360    0.7166    0.7201    1623.0

[[113.   4.  12.   0.  14.   1.]
 [  2. 183.  28.   1.   0.  31.]
 [ 30.  14. 288.   5.   5.  42.]
 [  0.   1.   5. 124.   0.  40.]
 [ 69.   2.  28.   0. 198.   2.]
 [  0.  12.  54.  53.   5. 257.]]
epoch: 131, train_loss: 6.218400001525879, train_acc: 92.93, train_fscore: 92.89, valid_loss: 6.945000171661377, valid_acc: 74.4, valid_fscore: 74.7, test_loss: 7.8755998611450195, test_acc: 70.61, test_fscore: 70.95, time: 4.6 sec
epoch: 132, train_loss: 6.194200038909912, train_acc: 92.89, train_fscore: 92.83, valid_loss: 6.973800182342529, valid_acc: 73.34, valid_fscore: 73.49, test_loss: 7.761600017547607, test_acc: 71.72, test_fscore: 72.07, time: 4.28 sec
epoch: 133, train_loss: 6.198299884796143, train_acc: 93.22, train_fscore: 93.18, valid_loss: 7.0441999435424805, valid_acc: 72.74, valid_fscore: 72.86, test_loss: 7.7657999992370605, test_acc: 72.21, test_fscore: 72.52, time: 4.49 sec
epoch: 134, train_loss: 6.196499824523926, train_acc: 92.89, train_fscore: 92.84, valid_loss: 6.975800037384033, valid_acc: 72.59, valid_fscore: 73.01, test_loss: 7.807799816131592, test_acc: 71.6, test_fscore: 71.95, time: 4.54 sec
epoch: 135, train_loss: 6.184299945831299, train_acc: 93.16, train_fscore: 93.12, valid_loss: 7.008500099182129, valid_acc: 72.44, valid_fscore: 72.85, test_loss: 7.782599925994873, test_acc: 71.97, test_fscore: 72.3, time: 4.58 sec
epoch: 136, train_loss: 6.17579984664917, train_acc: 92.91, train_fscore: 92.87, valid_loss: 7.01140022277832, valid_acc: 73.19, valid_fscore: 73.38, test_loss: 7.80679988861084, test_acc: 72.03, test_fscore: 72.36, time: 4.56 sec
epoch: 137, train_loss: 6.193699836730957, train_acc: 92.77, train_fscore: 92.73, valid_loss: 7.009200096130371, valid_acc: 73.34, valid_fscore: 73.65, test_loss: 7.914899826049805, test_acc: 71.53, test_fscore: 71.91, time: 4.65 sec
epoch: 138, train_loss: 6.16480016708374, train_acc: 93.82, train_fscore: 93.8, valid_loss: 7.059899806976318, valid_acc: 72.29, valid_fscore: 72.52, test_loss: 7.81820011138916, test_acc: 72.15, test_fscore: 72.5, time: 3.31 sec
epoch: 139, train_loss: 6.156400203704834, train_acc: 93.51, train_fscore: 93.47, valid_loss: 7.035699844360352, valid_acc: 72.44, valid_fscore: 72.72, test_loss: 7.819699764251709, test_acc: 71.9, test_fscore: 72.24, time: 1.94 sec
epoch: 140, train_loss: 6.1722002029418945, train_acc: 93.06, train_fscore: 93.01, valid_loss: 7.00439977645874, valid_acc: 74.4, valid_fscore: 74.62, test_loss: 7.857699871063232, test_acc: 71.35, test_fscore: 71.67, time: 1.87 sec
              precision    recall  f1-score   support

           0     0.5182    0.7917    0.6264     144.0
           1     0.8333    0.7551    0.7923     245.0
           2     0.6830    0.7630    0.7208     384.0
           3     0.6720    0.7353    0.7022     170.0
           4     0.8972    0.6421    0.7485     299.0
           5     0.7074    0.6535    0.6794     381.0

    accuracy                         0.7135    1623.0
   macro avg     0.7185    0.7235    0.7116    1623.0
weighted avg     0.7351    0.7135    0.7167    1623.0

[[114.   4.  13.   0.  12.   1.]
 [  2. 185.  29.   3.   0.  26.]
 [ 30.  16. 293.   5.   5.  35.]
 [  0.   1.   5. 125.   0.  39.]
 [ 74.   2.  29.   0. 192.   2.]
 [  0.  14.  60.  53.   5. 249.]]
epoch: 141, train_loss: 6.150700092315674, train_acc: 93.63, train_fscore: 93.58, valid_loss: 7.026199817657471, valid_acc: 73.04, valid_fscore: 73.19, test_loss: 7.830399990081787, test_acc: 71.78, test_fscore: 72.13, time: 1.99 sec
epoch: 142, train_loss: 6.157800197601318, train_acc: 93.63, train_fscore: 93.6, valid_loss: 7.008699893951416, valid_acc: 73.34, valid_fscore: 73.48, test_loss: 7.77869987487793, test_acc: 71.97, test_fscore: 72.26, time: 2.0 sec
epoch: 143, train_loss: 6.131100177764893, train_acc: 93.55, train_fscore: 93.51, valid_loss: 7.03879976272583, valid_acc: 73.8, valid_fscore: 74.1, test_loss: 7.85860013961792, test_acc: 70.98, test_fscore: 71.29, time: 1.98 sec
epoch: 144, train_loss: 6.1305999755859375, train_acc: 93.53, train_fscore: 93.48, valid_loss: 6.9781999588012695, valid_acc: 73.34, valid_fscore: 73.44, test_loss: 7.822299957275391, test_acc: 72.15, test_fscore: 72.47, time: 2.0 sec
epoch: 145, train_loss: 6.117800235748291, train_acc: 93.45, train_fscore: 93.41, valid_loss: 7.01230001449585, valid_acc: 72.59, valid_fscore: 72.65, test_loss: 7.82289981842041, test_acc: 71.72, test_fscore: 72.05, time: 2.05 sec
epoch: 146, train_loss: 6.112299919128418, train_acc: 93.74, train_fscore: 93.71, valid_loss: 7.062099933624268, valid_acc: 73.95, valid_fscore: 74.22, test_loss: 7.892899990081787, test_acc: 71.35, test_fscore: 71.67, time: 1.92 sec
epoch: 147, train_loss: 6.116099834442139, train_acc: 93.78, train_fscore: 93.75, valid_loss: 7.045499801635742, valid_acc: 73.49, valid_fscore: 73.68, test_loss: 7.920599937438965, test_acc: 71.41, test_fscore: 71.79, time: 1.93 sec
epoch: 148, train_loss: 6.092700004577637, train_acc: 94.09, train_fscore: 94.06, valid_loss: 7.0117998123168945, valid_acc: 72.89, valid_fscore: 73.0, test_loss: 7.935800075531006, test_acc: 72.03, test_fscore: 72.33, time: 1.95 sec
epoch: 149, train_loss: 6.0971999168396, train_acc: 94.05, train_fscore: 94.02, valid_loss: 7.067200183868408, valid_acc: 73.8, valid_fscore: 73.89, test_loss: 7.90339994430542, test_acc: 71.66, test_fscore: 71.92, time: 1.92 sec
epoch: 150, train_loss: 6.090099811553955, train_acc: 94.15, train_fscore: 94.11, valid_loss: 7.071199893951416, valid_acc: 73.19, valid_fscore: 73.54, test_loss: 7.9095001220703125, test_acc: 71.41, test_fscore: 71.78, time: 1.94 sec
              precision    recall  f1-score   support

           0     0.5135    0.7917    0.6230     144.0
           1     0.8486    0.7551    0.7991     245.0
           2     0.6944    0.7396    0.7163     384.0
           3     0.6755    0.7471    0.7095     170.0
           4     0.9043    0.6321    0.7441     299.0
           5     0.6897    0.6824    0.6860     381.0

    accuracy                         0.7141    1623.0
   macro avg     0.7210    0.7247    0.7130    1623.0
weighted avg     0.7372    0.7141    0.7178    1623.0

[[114.   4.  13.   0.  12.   1.]
 [  2. 185.  26.   2.   0.  30.]
 [ 30.  16. 284.   6.   3.  45.]
 [  0.   0.   4. 127.   0.  39.]
 [ 76.   2.  30.   0. 189.   2.]
 [  0.  11.  52.  53.   5. 260.]]
Best validation F-Score: 71.78
Test performance..
F-Score: 71.78
Accuracy: 71.41
Loss: 7.9095001220703125
--- 7 ---
loss_mask: [True, True, True, True]
Namespace(no_cuda=False, lr=0.0001, l2=1e-05, dropout=0.5, batch_size=64, hidden_dim=1024, n_head=8, epochs=150, temp=2, tensorboard=False, class_weight=True, Dataset='IEMOCAP', loss_mask='1111')
Running on GPU
temp 2
total parameters: 97535000
training parameters: 97535000
epoch: 1, train_loss: 12.376700401306152, train_acc: 21.45, train_fscore: 20.78, valid_loss: 10.281000137329102, valid_acc: 38.55, valid_fscore: 38.65, test_loss: 11.209699630737305, test_acc: 37.34, test_fscore: 33.9, time: 3.51 sec
epoch: 2, train_loss: 11.609600067138672, train_acc: 37.47, train_fscore: 35.41, valid_loss: 9.689900398254395, valid_acc: 45.03, valid_fscore: 46.14, test_loss: 10.679699897766113, test_acc: 42.21, test_fscore: 41.5, time: 2.02 sec
epoch: 3, train_loss: 11.118900299072266, train_acc: 45.3, train_fscore: 43.9, valid_loss: 9.203499794006348, valid_acc: 53.46, valid_fscore: 52.5, test_loss: 10.351499557495117, test_acc: 44.73, test_fscore: 42.14, time: 1.98 sec
epoch: 4, train_loss: 10.711899757385254, train_acc: 50.35, train_fscore: 47.4, valid_loss: 8.9173002243042, valid_acc: 56.93, valid_fscore: 56.91, test_loss: 10.116000175476074, test_acc: 50.28, test_fscore: 49.53, time: 2.02 sec
epoch: 5, train_loss: 10.388400077819824, train_acc: 57.21, train_fscore: 55.66, valid_loss: 8.710100173950195, valid_acc: 61.14, valid_fscore: 62.1, test_loss: 9.906000137329102, test_acc: 55.51, test_fscore: 55.91, time: 1.98 sec
epoch: 6, train_loss: 10.073699951171875, train_acc: 60.63, train_fscore: 59.79, valid_loss: 8.492799758911133, valid_acc: 64.46, valid_fscore: 65.39, test_loss: 9.648500442504883, test_acc: 59.89, test_fscore: 60.19, time: 2.0 sec
epoch: 7, train_loss: 9.804300308227539, train_acc: 64.19, train_fscore: 63.9, valid_loss: 8.219499588012695, valid_acc: 65.36, valid_fscore: 66.82, test_loss: 9.381600379943848, test_acc: 60.07, test_fscore: 60.76, time: 1.96 sec
epoch: 8, train_loss: 9.500200271606445, train_acc: 65.78, train_fscore: 65.78, valid_loss: 8.0201997756958, valid_acc: 65.21, valid_fscore: 66.55, test_loss: 9.186300277709961, test_acc: 59.21, test_fscore: 59.73, time: 2.05 sec
epoch: 9, train_loss: 9.17389965057373, train_acc: 66.11, train_fscore: 65.82, valid_loss: 7.563499927520752, valid_acc: 66.11, valid_fscore: 67.52, test_loss: 8.792099952697754, test_acc: 60.81, test_fscore: 61.61, time: 2.01 sec
epoch: 10, train_loss: 8.934700012207031, train_acc: 67.57, train_fscore: 67.26, valid_loss: 7.367000102996826, valid_acc: 67.92, valid_fscore: 69.26, test_loss: 8.641799926757812, test_acc: 62.6, test_fscore: 63.57, time: 2.06 sec
              precision    recall  f1-score   support

           0     0.3216    0.6319    0.4262     144.0
           1     0.7933    0.6735    0.7285     245.0
           2     0.6450    0.5156    0.5731     384.0
           3     0.5962    0.7294    0.6561     170.0
           4     0.8227    0.6054    0.6975     299.0
           5     0.6474    0.6745    0.6607     381.0

    accuracy                         0.6260    1623.0
   macro avg     0.6377    0.6384    0.6237    1623.0
weighted avg     0.6669    0.6260    0.6357    1623.0

[[ 91.   7.  10.   3.  32.   1.]
 [ 16. 165.  32.   2.   0.  30.]
 [ 67.  25. 198.  25.   2.  67.]
 [  0.   0.   6. 124.   0.  40.]
 [ 98.   0.  16.   2. 181.   2.]
 [ 11.  11.  45.  52.   5. 257.]]
epoch: 11, train_loss: 8.839699745178223, train_acc: 67.24, train_fscore: 66.87, valid_loss: 7.328700065612793, valid_acc: 67.17, valid_fscore: 68.74, test_loss: 8.640000343322754, test_acc: 60.32, test_fscore: 61.56, time: 2.02 sec
epoch: 12, train_loss: 8.795499801635742, train_acc: 68.05, train_fscore: 67.77, valid_loss: 7.269100189208984, valid_acc: 67.17, valid_fscore: 68.24, test_loss: 8.544500350952148, test_acc: 63.83, test_fscore: 64.83, time: 1.98 sec
epoch: 13, train_loss: 8.65719985961914, train_acc: 69.14, train_fscore: 68.97, valid_loss: 7.1168999671936035, valid_acc: 66.87, valid_fscore: 68.29, test_loss: 8.378399848937988, test_acc: 63.28, test_fscore: 64.2, time: 1.9 sec
epoch: 14, train_loss: 8.566200256347656, train_acc: 69.1, train_fscore: 68.78, valid_loss: 6.984799861907959, valid_acc: 66.87, valid_fscore: 68.21, test_loss: 8.23069953918457, test_acc: 64.02, test_fscore: 64.91, time: 1.94 sec
epoch: 15, train_loss: 8.4975004196167, train_acc: 70.25, train_fscore: 69.96, valid_loss: 6.860499858856201, valid_acc: 69.88, valid_fscore: 70.92, test_loss: 8.137800216674805, test_acc: 64.82, test_fscore: 65.43, time: 1.96 sec
epoch: 16, train_loss: 8.415200233459473, train_acc: 70.87, train_fscore: 70.4, valid_loss: 6.842899799346924, valid_acc: 68.07, valid_fscore: 69.49, test_loss: 8.139599800109863, test_acc: 64.02, test_fscore: 64.76, time: 2.0 sec
epoch: 17, train_loss: 8.374099731445312, train_acc: 69.65, train_fscore: 69.3, valid_loss: 6.877799987792969, valid_acc: 66.27, valid_fscore: 68.57, test_loss: 8.172300338745117, test_acc: 62.6, test_fscore: 63.45, time: 2.05 sec
epoch: 18, train_loss: 8.280599594116211, train_acc: 71.57, train_fscore: 71.26, valid_loss: 6.822999954223633, valid_acc: 68.52, valid_fscore: 69.39, test_loss: 8.105899810791016, test_acc: 65.68, test_fscore: 66.24, time: 2.11 sec
epoch: 19, train_loss: 8.2431001663208, train_acc: 72.11, train_fscore: 71.72, valid_loss: 6.747600078582764, valid_acc: 67.77, valid_fscore: 69.39, test_loss: 8.027799606323242, test_acc: 64.33, test_fscore: 65.16, time: 1.94 sec
epoch: 20, train_loss: 8.124899864196777, train_acc: 73.32, train_fscore: 73.04, valid_loss: 6.670599937438965, valid_acc: 69.88, valid_fscore: 71.15, test_loss: 7.982900142669678, test_acc: 65.06, test_fscore: 65.84, time: 1.98 sec
              precision    recall  f1-score   support

           0     0.3701    0.6528    0.4724     144.0
           1     0.7706    0.7265    0.7479     245.0
           2     0.6638    0.5964    0.6283     384.0
           3     0.6374    0.6824    0.6591     170.0
           4     0.8430    0.6288    0.7203     299.0
           5     0.6469    0.6588    0.6528     381.0

    accuracy                         0.6506    1623.0
   macro avg     0.6553    0.6576    0.6468    1623.0
weighted avg     0.6801    0.6506    0.6584    1623.0

[[ 94.   8.  13.   2.  25.   2.]
 [  5. 178.  29.   1.   0.  32.]
 [ 56.  25. 229.  17.   5.  52.]
 [  0.   0.   5. 116.   0.  49.]
 [ 94.   0.  15.   0. 188.   2.]
 [  5.  20.  54.  46.   5. 251.]]
epoch: 21, train_loss: 8.092399597167969, train_acc: 73.73, train_fscore: 73.46, valid_loss: 6.666900157928467, valid_acc: 69.43, valid_fscore: 70.49, test_loss: 8.008500099182129, test_acc: 65.93, test_fscore: 66.51, time: 2.03 sec
epoch: 22, train_loss: 8.023699760437012, train_acc: 73.8, train_fscore: 73.49, valid_loss: 6.71019983291626, valid_acc: 67.32, valid_fscore: 69.1, test_loss: 7.9899001121521, test_acc: 65.06, test_fscore: 65.9, time: 2.03 sec
epoch: 23, train_loss: 7.9822001457214355, train_acc: 74.04, train_fscore: 73.83, valid_loss: 6.688399791717529, valid_acc: 69.43, valid_fscore: 70.95, test_loss: 7.95389986038208, test_acc: 66.05, test_fscore: 66.74, time: 2.23 sec
epoch: 24, train_loss: 7.92579984664917, train_acc: 74.91, train_fscore: 74.72, valid_loss: 6.633200168609619, valid_acc: 70.33, valid_fscore: 71.06, test_loss: 7.915800094604492, test_acc: 67.59, test_fscore: 68.1, time: 1.94 sec
epoch: 25, train_loss: 7.904300212860107, train_acc: 74.7, train_fscore: 74.4, valid_loss: 6.61460018157959, valid_acc: 69.28, valid_fscore: 70.67, test_loss: 7.864500045776367, test_acc: 67.22, test_fscore: 67.87, time: 1.97 sec
epoch: 26, train_loss: 7.836299896240234, train_acc: 75.42, train_fscore: 75.18, valid_loss: 6.615499973297119, valid_acc: 69.28, valid_fscore: 70.93, test_loss: 7.887400150299072, test_acc: 66.54, test_fscore: 67.25, time: 2.0 sec
epoch: 27, train_loss: 7.787799835205078, train_acc: 75.07, train_fscore: 74.84, valid_loss: 6.605999946594238, valid_acc: 71.84, valid_fscore: 72.93, test_loss: 7.924499988555908, test_acc: 67.04, test_fscore: 67.61, time: 1.99 sec
epoch: 28, train_loss: 7.748199939727783, train_acc: 75.94, train_fscore: 75.75, valid_loss: 6.6107001304626465, valid_acc: 70.48, valid_fscore: 71.94, test_loss: 7.907599925994873, test_acc: 66.48, test_fscore: 67.16, time: 2.02 sec
epoch: 29, train_loss: 7.732600212097168, train_acc: 76.2, train_fscore: 75.98, valid_loss: 6.546000003814697, valid_acc: 70.78, valid_fscore: 72.07, test_loss: 7.774400234222412, test_acc: 67.04, test_fscore: 67.7, time: 2.01 sec
epoch: 30, train_loss: 7.690299987792969, train_acc: 76.21, train_fscore: 76.01, valid_loss: 6.494100093841553, valid_acc: 70.63, valid_fscore: 71.62, test_loss: 7.697500228881836, test_acc: 68.39, test_fscore: 68.93, time: 2.01 sec
              precision    recall  f1-score   support

           0     0.4404    0.6667    0.5304     144.0
           1     0.7826    0.7347    0.7579     245.0
           2     0.7097    0.6302    0.6676     384.0
           3     0.6256    0.7176    0.6685     170.0
           4     0.8672    0.6990    0.7741     299.0
           5     0.6558    0.6850    0.6701     381.0

    accuracy                         0.6839    1623.0
   macro avg     0.6802    0.6889    0.6781    1623.0
weighted avg     0.7044    0.6839    0.6893    1623.0

[[ 96.   7.  14.   3.  21.   3.]
 [  3. 180.  25.   1.   0.  36.]
 [ 42.  26. 242.  18.   5.  51.]
 [  0.   0.   3. 122.   0.  45.]
 [ 77.   0.  11.   0. 209.   2.]
 [  0.  17.  46.  51.   6. 261.]]
epoch: 31, train_loss: 7.668399810791016, train_acc: 76.56, train_fscore: 76.35, valid_loss: 6.493000030517578, valid_acc: 72.14, valid_fscore: 73.31, test_loss: 7.753799915313721, test_acc: 67.1, test_fscore: 67.73, time: 1.97 sec
epoch: 32, train_loss: 7.616099834442139, train_acc: 77.34, train_fscore: 77.13, valid_loss: 6.5329999923706055, valid_acc: 71.69, valid_fscore: 73.18, test_loss: 7.811399936676025, test_acc: 66.54, test_fscore: 67.21, time: 2.04 sec
epoch: 33, train_loss: 7.6092000007629395, train_acc: 77.32, train_fscore: 77.24, valid_loss: 6.535699844360352, valid_acc: 70.63, valid_fscore: 71.9, test_loss: 7.737599849700928, test_acc: 67.9, test_fscore: 68.56, time: 2.03 sec
epoch: 34, train_loss: 7.55109977722168, train_acc: 77.26, train_fscore: 77.07, valid_loss: 6.459700107574463, valid_acc: 71.84, valid_fscore: 72.85, test_loss: 7.679900169372559, test_acc: 67.47, test_fscore: 68.04, time: 2.02 sec
epoch: 35, train_loss: 7.538000106811523, train_acc: 78.06, train_fscore: 77.86, valid_loss: 6.451399803161621, valid_acc: 72.89, valid_fscore: 73.82, test_loss: 7.676700115203857, test_acc: 68.02, test_fscore: 68.6, time: 2.0 sec
epoch: 36, train_loss: 7.501100063323975, train_acc: 78.78, train_fscore: 78.62, valid_loss: 6.474800109863281, valid_acc: 71.99, valid_fscore: 73.0, test_loss: 7.662799835205078, test_acc: 67.47, test_fscore: 68.07, time: 2.06 sec
epoch: 37, train_loss: 7.474699974060059, train_acc: 78.16, train_fscore: 77.98, valid_loss: 6.522900104522705, valid_acc: 71.84, valid_fscore: 73.18, test_loss: 7.707799911499023, test_acc: 67.65, test_fscore: 68.33, time: 2.06 sec
epoch: 38, train_loss: 7.453100204467773, train_acc: 79.13, train_fscore: 78.98, valid_loss: 6.493100166320801, valid_acc: 73.04, valid_fscore: 74.16, test_loss: 7.734899997711182, test_acc: 67.47, test_fscore: 68.13, time: 2.12 sec
epoch: 39, train_loss: 7.426700115203857, train_acc: 79.34, train_fscore: 79.21, valid_loss: 6.5071001052856445, valid_acc: 71.99, valid_fscore: 73.26, test_loss: 7.705900192260742, test_acc: 66.73, test_fscore: 67.42, time: 2.01 sec
epoch: 40, train_loss: 7.40500020980835, train_acc: 78.78, train_fscore: 78.68, valid_loss: 6.515999794006348, valid_acc: 71.99, valid_fscore: 73.49, test_loss: 7.6697001457214355, test_acc: 67.59, test_fscore: 68.19, time: 1.95 sec
              precision    recall  f1-score   support

           0     0.4241    0.7569    0.5436     144.0
           1     0.7866    0.7673    0.7769     245.0
           2     0.7114    0.6354    0.6713     384.0
           3     0.6263    0.7294    0.6739     170.0
           4     0.8950    0.5987    0.7174     299.0
           5     0.6554    0.6640    0.6597     381.0

    accuracy                         0.6759    1623.0
   macro avg     0.6831    0.6920    0.6738    1623.0
weighted avg     0.7090    0.6759    0.6819    1623.0

[[109.   7.  16.   0.  11.   1.]
 [  1. 188.  21.   2.   0.  33.]
 [ 42.  26. 244.  14.   4.  54.]
 [  0.   0.   3. 124.   0.  43.]
 [105.   1.  12.   0. 179.   2.]
 [  0.  17.  47.  58.   6. 253.]]
epoch: 41, train_loss: 7.3790998458862305, train_acc: 79.46, train_fscore: 79.28, valid_loss: 6.467599868774414, valid_acc: 73.19, valid_fscore: 74.05, test_loss: 7.629899978637695, test_acc: 68.82, test_fscore: 69.36, time: 1.94 sec
epoch: 42, train_loss: 7.357999801635742, train_acc: 80.55, train_fscore: 80.41, valid_loss: 6.506100177764893, valid_acc: 72.14, valid_fscore: 73.42, test_loss: 7.651599884033203, test_acc: 67.71, test_fscore: 68.36, time: 1.94 sec
epoch: 43, train_loss: 7.301199913024902, train_acc: 80.24, train_fscore: 80.15, valid_loss: 6.50439977645874, valid_acc: 72.44, valid_fscore: 73.69, test_loss: 7.632199764251709, test_acc: 67.47, test_fscore: 68.12, time: 1.93 sec
epoch: 44, train_loss: 7.288700103759766, train_acc: 80.43, train_fscore: 80.27, valid_loss: 6.451300144195557, valid_acc: 73.19, valid_fscore: 74.01, test_loss: 7.627500057220459, test_acc: 68.15, test_fscore: 68.77, time: 1.99 sec
epoch: 45, train_loss: 7.27239990234375, train_acc: 80.94, train_fscore: 80.83, valid_loss: 6.5065999031066895, valid_acc: 72.29, valid_fscore: 73.65, test_loss: 7.653600215911865, test_acc: 67.65, test_fscore: 68.28, time: 2.01 sec
epoch: 46, train_loss: 7.277200222015381, train_acc: 81.15, train_fscore: 81.02, valid_loss: 6.48360013961792, valid_acc: 72.44, valid_fscore: 73.32, test_loss: 7.600399971008301, test_acc: 67.78, test_fscore: 68.37, time: 2.05 sec
epoch: 47, train_loss: 7.231500148773193, train_acc: 80.72, train_fscore: 80.52, valid_loss: 6.449399948120117, valid_acc: 73.04, valid_fscore: 73.58, test_loss: 7.550899982452393, test_acc: 69.32, test_fscore: 69.86, time: 1.98 sec
epoch: 48, train_loss: 7.222700119018555, train_acc: 81.54, train_fscore: 81.44, valid_loss: 6.531899929046631, valid_acc: 71.99, valid_fscore: 73.31, test_loss: 7.621600151062012, test_acc: 67.59, test_fscore: 68.18, time: 2.49 sec
epoch: 49, train_loss: 7.179200172424316, train_acc: 81.07, train_fscore: 80.95, valid_loss: 6.505899906158447, valid_acc: 72.44, valid_fscore: 73.69, test_loss: 7.660399913787842, test_acc: 67.41, test_fscore: 67.92, time: 2.04 sec
epoch: 50, train_loss: 7.156899929046631, train_acc: 81.34, train_fscore: 81.16, valid_loss: 6.475900173187256, valid_acc: 71.69, valid_fscore: 72.34, test_loss: 7.558300018310547, test_acc: 69.13, test_fscore: 69.71, time: 2.04 sec
              precision    recall  f1-score   support

           0     0.4557    0.7500    0.5669     144.0
           1     0.8230    0.7592    0.7898     245.0
           2     0.7243    0.6432    0.6814     384.0
           3     0.6269    0.7118    0.6667     170.0
           4     0.8739    0.6722    0.7599     299.0
           5     0.6540    0.6798    0.6667     381.0

    accuracy                         0.6913    1623.0
   macro avg     0.6930    0.7027    0.6886    1623.0
weighted avg     0.7163    0.6913    0.6971    1623.0

[[108.   4.  11.   0.  19.   2.]
 [  2. 186.  22.   2.   0.  33.]
 [ 43.  21. 247.  14.   4.  55.]
 [  0.   0.   4. 121.   0.  45.]
 [ 83.   1.  12.   0. 201.   2.]
 [  1.  14.  45.  56.   6. 259.]]
epoch: 51, train_loss: 7.144700050354004, train_acc: 82.37, train_fscore: 82.27, valid_loss: 6.497499942779541, valid_acc: 72.14, valid_fscore: 73.19, test_loss: 7.5543999671936035, test_acc: 68.7, test_fscore: 69.33, time: 1.97 sec
epoch: 52, train_loss: 7.124899864196777, train_acc: 81.89, train_fscore: 81.76, valid_loss: 6.461699962615967, valid_acc: 72.44, valid_fscore: 73.28, test_loss: 7.577700138092041, test_acc: 68.27, test_fscore: 68.86, time: 2.01 sec
epoch: 53, train_loss: 7.096199989318848, train_acc: 82.72, train_fscore: 82.6, valid_loss: 6.492800235748291, valid_acc: 71.84, valid_fscore: 72.9, test_loss: 7.618199825286865, test_acc: 68.21, test_fscore: 68.77, time: 1.93 sec
epoch: 54, train_loss: 7.076200008392334, train_acc: 82.39, train_fscore: 82.31, valid_loss: 6.561100006103516, valid_acc: 71.69, valid_fscore: 72.9, test_loss: 7.654799938201904, test_acc: 67.53, test_fscore: 68.08, time: 2.06 sec
epoch: 55, train_loss: 7.080399990081787, train_acc: 83.05, train_fscore: 82.93, valid_loss: 6.497499942779541, valid_acc: 73.8, valid_fscore: 74.48, test_loss: 7.576600074768066, test_acc: 69.44, test_fscore: 69.99, time: 2.01 sec
epoch: 56, train_loss: 7.070899963378906, train_acc: 82.94, train_fscore: 82.83, valid_loss: 6.474599838256836, valid_acc: 73.34, valid_fscore: 73.99, test_loss: 7.572700023651123, test_acc: 69.07, test_fscore: 69.64, time: 2.17 sec
epoch: 57, train_loss: 7.013500213623047, train_acc: 82.84, train_fscore: 82.73, valid_loss: 6.551700115203857, valid_acc: 71.69, valid_fscore: 73.04, test_loss: 7.62060022354126, test_acc: 67.22, test_fscore: 67.76, time: 2.04 sec
epoch: 58, train_loss: 7.00540018081665, train_acc: 83.17, train_fscore: 83.07, valid_loss: 6.5055999755859375, valid_acc: 73.95, valid_fscore: 74.78, test_loss: 7.589399814605713, test_acc: 68.88, test_fscore: 69.4, time: 1.99 sec
epoch: 59, train_loss: 7.009900093078613, train_acc: 83.68, train_fscore: 83.55, valid_loss: 6.482800006866455, valid_acc: 74.1, valid_fscore: 74.72, test_loss: 7.585100173950195, test_acc: 69.44, test_fscore: 69.97, time: 2.02 sec
epoch: 60, train_loss: 7.000500202178955, train_acc: 83.73, train_fscore: 83.61, valid_loss: 6.5177998542785645, valid_acc: 72.89, valid_fscore: 73.82, test_loss: 7.594900131225586, test_acc: 68.52, test_fscore: 69.11, time: 2.05 sec
              precision    recall  f1-score   support

           0     0.4291    0.7986    0.5583     144.0
           1     0.8326    0.7714    0.8008     245.0
           2     0.7067    0.6901    0.6983     384.0
           3     0.6289    0.7176    0.6703     170.0
           4     0.8953    0.5719    0.6980     299.0
           5     0.6793    0.6562    0.6676     381.0

    accuracy                         0.6852    1623.0
   macro avg     0.6953    0.7010    0.6822    1623.0
weighted avg     0.7212    0.6852    0.6911    1623.0

[[115.   4.  14.   0.  10.   1.]
 [  3. 189.  20.   2.   0.  31.]
 [ 43.  19. 265.  11.   4.  42.]
 [  0.   0.   5. 122.   0.  43.]
 [106.   1.  20.   0. 171.   1.]
 [  1.  14.  51.  59.   6. 250.]]
epoch: 61, train_loss: 6.954800128936768, train_acc: 84.59, train_fscore: 84.51, valid_loss: 6.492599964141846, valid_acc: 73.49, valid_fscore: 74.28, test_loss: 7.5644001960754395, test_acc: 69.32, test_fscore: 69.86, time: 2.03 sec
epoch: 62, train_loss: 6.946100234985352, train_acc: 84.38, train_fscore: 84.29, valid_loss: 6.507199764251709, valid_acc: 73.64, valid_fscore: 74.54, test_loss: 7.606500148773193, test_acc: 68.27, test_fscore: 68.81, time: 2.02 sec
epoch: 63, train_loss: 6.940100193023682, train_acc: 84.08, train_fscore: 83.97, valid_loss: 6.469699859619141, valid_acc: 75.3, valid_fscore: 75.7, test_loss: 7.598400115966797, test_acc: 69.07, test_fscore: 69.61, time: 2.02 sec
epoch: 64, train_loss: 6.92710018157959, train_acc: 84.55, train_fscore: 84.47, valid_loss: 6.485300064086914, valid_acc: 72.44, valid_fscore: 72.99, test_loss: 7.551199913024902, test_acc: 69.99, test_fscore: 70.53, time: 2.02 sec
epoch: 65, train_loss: 6.895299911499023, train_acc: 84.78, train_fscore: 84.69, valid_loss: 6.474400043487549, valid_acc: 73.8, valid_fscore: 74.52, test_loss: 7.544899940490723, test_acc: 69.62, test_fscore: 70.14, time: 2.0 sec
epoch: 66, train_loss: 6.877399921417236, train_acc: 85.6, train_fscore: 85.5, valid_loss: 6.51609992980957, valid_acc: 73.8, valid_fscore: 74.58, test_loss: 7.604100227355957, test_acc: 68.88, test_fscore: 69.44, time: 1.99 sec
epoch: 67, train_loss: 6.86929988861084, train_acc: 85.0, train_fscore: 84.91, valid_loss: 6.535200119018555, valid_acc: 73.49, valid_fscore: 74.1, test_loss: 7.611499786376953, test_acc: 69.62, test_fscore: 70.17, time: 2.01 sec
epoch: 68, train_loss: 6.855100154876709, train_acc: 84.61, train_fscore: 84.49, valid_loss: 6.53439998626709, valid_acc: 73.95, valid_fscore: 74.49, test_loss: 7.5970001220703125, test_acc: 70.24, test_fscore: 70.74, time: 1.96 sec
epoch: 69, train_loss: 6.82390022277832, train_acc: 85.48, train_fscore: 85.38, valid_loss: 6.560800075531006, valid_acc: 74.1, valid_fscore: 74.77, test_loss: 7.598400115966797, test_acc: 69.62, test_fscore: 70.11, time: 2.0 sec
epoch: 70, train_loss: 6.851900100708008, train_acc: 85.87, train_fscore: 85.8, valid_loss: 6.560200214385986, valid_acc: 73.8, valid_fscore: 74.39, test_loss: 7.5980000495910645, test_acc: 69.13, test_fscore: 69.67, time: 1.94 sec
              precision    recall  f1-score   support

           0     0.4578    0.7917    0.5802     144.0
           1     0.8363    0.7714    0.8025     245.0
           2     0.7021    0.6875    0.6947     384.0
           3     0.6250    0.7353    0.6757     170.0
           4     0.8942    0.6221    0.7337     299.0
           5     0.6703    0.6404    0.6550     381.0

    accuracy                         0.6913    1623.0
   macro avg     0.6976    0.7081    0.6903    1623.0
weighted avg     0.7206    0.6913    0.6967    1623.0

[[114.   4.  14.   0.  11.   1.]
 [  3. 189.  21.   2.   0.  30.]
 [ 40.  18. 264.  10.   4.  48.]
 [  0.   0.   5. 125.   0.  40.]
 [ 91.   1.  20.   0. 186.   1.]
 [  1.  14.  52.  63.   7. 244.]]
epoch: 71, train_loss: 6.817399978637695, train_acc: 85.76, train_fscore: 85.65, valid_loss: 6.576099872589111, valid_acc: 72.74, valid_fscore: 73.25, test_loss: 7.575900077819824, test_acc: 70.36, test_fscore: 70.84, time: 2.04 sec
epoch: 72, train_loss: 6.813199996948242, train_acc: 85.74, train_fscore: 85.63, valid_loss: 6.5706000328063965, valid_acc: 73.49, valid_fscore: 74.29, test_loss: 7.670199871063232, test_acc: 69.01, test_fscore: 69.53, time: 1.93 sec
epoch: 73, train_loss: 6.781400203704834, train_acc: 86.2, train_fscore: 86.12, valid_loss: 6.541500091552734, valid_acc: 73.95, valid_fscore: 74.51, test_loss: 7.589600086212158, test_acc: 69.25, test_fscore: 69.72, time: 1.93 sec
epoch: 74, train_loss: 6.787799835205078, train_acc: 86.3, train_fscore: 86.2, valid_loss: 6.568299770355225, valid_acc: 73.8, valid_fscore: 74.56, test_loss: 7.622700214385986, test_acc: 69.5, test_fscore: 70.02, time: 1.98 sec
epoch: 75, train_loss: 6.75, train_acc: 85.52, train_fscore: 85.44, valid_loss: 6.551700115203857, valid_acc: 73.95, valid_fscore: 74.61, test_loss: 7.653500080108643, test_acc: 68.7, test_fscore: 69.16, time: 2.03 sec
epoch: 76, train_loss: 6.734600067138672, train_acc: 86.42, train_fscore: 86.3, valid_loss: 6.560400009155273, valid_acc: 75.3, valid_fscore: 75.67, test_loss: 7.592800140380859, test_acc: 70.79, test_fscore: 71.27, time: 2.0 sec
epoch: 77, train_loss: 6.721099853515625, train_acc: 86.79, train_fscore: 86.72, valid_loss: 6.633600234985352, valid_acc: 72.89, valid_fscore: 73.95, test_loss: 7.673099994659424, test_acc: 69.38, test_fscore: 69.91, time: 1.97 sec
epoch: 78, train_loss: 6.730800151824951, train_acc: 86.51, train_fscore: 86.45, valid_loss: 6.554800033569336, valid_acc: 74.7, valid_fscore: 75.1, test_loss: 7.59089994430542, test_acc: 70.43, test_fscore: 70.88, time: 1.94 sec
epoch: 79, train_loss: 6.695199966430664, train_acc: 86.84, train_fscore: 86.73, valid_loss: 6.573200225830078, valid_acc: 74.25, valid_fscore: 74.63, test_loss: 7.586299896240234, test_acc: 71.16, test_fscore: 71.61, time: 2.0 sec
epoch: 80, train_loss: 6.69189977645874, train_acc: 87.39, train_fscore: 87.3, valid_loss: 6.573299884796143, valid_acc: 73.04, valid_fscore: 73.82, test_loss: 7.644999980926514, test_acc: 69.32, test_fscore: 69.77, time: 2.13 sec
              precision    recall  f1-score   support

           0     0.4474    0.8264    0.5805     144.0
           1     0.8276    0.7837    0.8050     245.0
           2     0.6974    0.7083    0.7028     384.0
           3     0.6528    0.7412    0.6942     170.0
           4     0.8989    0.5652    0.6940     299.0
           5     0.6977    0.6483    0.6721     381.0

    accuracy                         0.6932    1623.0
   macro avg     0.7037    0.7122    0.6915    1623.0
weighted avg     0.7274    0.6932    0.6977    1623.0

[[119.   4.  11.   0.   9.   1.]
 [  3. 192.  22.   3.   0.  25.]
 [ 40.  19. 272.   9.   4.  40.]
 [  0.   0.   4. 126.   0.  40.]
 [104.   2.  23.   0. 169.   1.]
 [  0.  15.  58.  55.   6. 247.]]
epoch: 81, train_loss: 6.6656999588012695, train_acc: 87.43, train_fscore: 87.33, valid_loss: 6.568299770355225, valid_acc: 73.64, valid_fscore: 74.09, test_loss: 7.613100051879883, test_acc: 70.79, test_fscore: 71.27, time: 1.99 sec
epoch: 82, train_loss: 6.662600040435791, train_acc: 87.78, train_fscore: 87.7, valid_loss: 6.592299938201904, valid_acc: 74.1, valid_fscore: 74.49, test_loss: 7.6143999099731445, test_acc: 70.67, test_fscore: 71.16, time: 2.0 sec
epoch: 83, train_loss: 6.647600173950195, train_acc: 88.03, train_fscore: 87.95, valid_loss: 6.566299915313721, valid_acc: 74.25, valid_fscore: 74.92, test_loss: 7.658599853515625, test_acc: 69.69, test_fscore: 70.15, time: 2.02 sec
epoch: 84, train_loss: 6.62470006942749, train_acc: 87.52, train_fscore: 87.41, valid_loss: 6.57859992980957, valid_acc: 74.55, valid_fscore: 75.11, test_loss: 7.673399925231934, test_acc: 69.69, test_fscore: 70.2, time: 2.07 sec
epoch: 85, train_loss: 6.649600028991699, train_acc: 87.56, train_fscore: 87.48, valid_loss: 6.61299991607666, valid_acc: 74.4, valid_fscore: 74.86, test_loss: 7.67140007019043, test_acc: 70.3, test_fscore: 70.82, time: 2.02 sec
epoch: 86, train_loss: 6.607900142669678, train_acc: 87.91, train_fscore: 87.84, valid_loss: 6.593500137329102, valid_acc: 73.8, valid_fscore: 74.41, test_loss: 7.72189998626709, test_acc: 69.99, test_fscore: 70.45, time: 2.03 sec
epoch: 87, train_loss: 6.592599868774414, train_acc: 88.26, train_fscore: 88.17, valid_loss: 6.593800067901611, valid_acc: 74.25, valid_fscore: 74.81, test_loss: 7.666600227355957, test_acc: 70.73, test_fscore: 71.19, time: 2.0 sec
epoch: 88, train_loss: 6.599100112915039, train_acc: 88.53, train_fscore: 88.46, valid_loss: 6.5808000564575195, valid_acc: 73.34, valid_fscore: 73.74, test_loss: 7.655600070953369, test_acc: 70.61, test_fscore: 71.05, time: 1.96 sec
epoch: 89, train_loss: 6.5970001220703125, train_acc: 88.38, train_fscore: 88.28, valid_loss: 6.628200054168701, valid_acc: 73.49, valid_fscore: 74.14, test_loss: 7.744800090789795, test_acc: 69.81, test_fscore: 70.36, time: 2.03 sec
epoch: 90, train_loss: 6.566299915313721, train_acc: 88.83, train_fscore: 88.77, valid_loss: 6.621200084686279, valid_acc: 73.8, valid_fscore: 74.23, test_loss: 7.6722002029418945, test_acc: 71.04, test_fscore: 71.53, time: 1.96 sec
              precision    recall  f1-score   support

           0     0.4703    0.7708    0.5842     144.0
           1     0.8312    0.8041    0.8174     245.0
           2     0.7228    0.6927    0.7074     384.0
           3     0.6758    0.7235    0.6989     170.0
           4     0.8935    0.6455    0.7495     299.0
           5     0.6849    0.6903    0.6876     381.0

    accuracy                         0.7104    1623.0
   macro avg     0.7131    0.7212    0.7075    1623.0
weighted avg     0.7344    0.7104    0.7153    1623.0

[[111.   5.  14.   0.  13.   1.]
 [  3. 197.  15.   3.   0.  27.]
 [ 41.  17. 266.   8.   4.  48.]
 [  0.   1.   3. 123.   0.  43.]
 [ 81.   2.  21.   0. 193.   2.]
 [  0.  15.  49.  48.   6. 263.]]
epoch: 91, train_loss: 6.545400142669678, train_acc: 88.79, train_fscore: 88.69, valid_loss: 6.667300224304199, valid_acc: 73.95, valid_fscore: 74.32, test_loss: 7.60230016708374, test_acc: 71.29, test_fscore: 71.75, time: 2.03 sec
epoch: 92, train_loss: 6.561600208282471, train_acc: 89.04, train_fscore: 88.97, valid_loss: 6.7256999015808105, valid_acc: 72.59, valid_fscore: 73.53, test_loss: 7.775300025939941, test_acc: 69.19, test_fscore: 69.66, time: 2.01 sec
epoch: 93, train_loss: 6.5416998863220215, train_acc: 88.81, train_fscore: 88.75, valid_loss: 6.61460018157959, valid_acc: 73.95, valid_fscore: 74.29, test_loss: 7.661200046539307, test_acc: 71.16, test_fscore: 71.54, time: 1.95 sec
epoch: 94, train_loss: 6.522900104522705, train_acc: 89.2, train_fscore: 89.12, valid_loss: 6.635300159454346, valid_acc: 74.55, valid_fscore: 74.74, test_loss: 7.6859002113342285, test_acc: 70.73, test_fscore: 71.15, time: 1.99 sec
epoch: 95, train_loss: 6.5142998695373535, train_acc: 89.25, train_fscore: 89.14, valid_loss: 6.7170000076293945, valid_acc: 73.64, valid_fscore: 74.14, test_loss: 7.7519001960754395, test_acc: 69.81, test_fscore: 70.26, time: 2.02 sec
epoch: 96, train_loss: 6.5289998054504395, train_acc: 89.06, train_fscore: 89.0, valid_loss: 6.7027997970581055, valid_acc: 73.19, valid_fscore: 73.4, test_loss: 7.660600185394287, test_acc: 71.23, test_fscore: 71.66, time: 2.0 sec
epoch: 97, train_loss: 6.487599849700928, train_acc: 89.6, train_fscore: 89.53, valid_loss: 6.728400230407715, valid_acc: 74.4, valid_fscore: 74.76, test_loss: 7.72189998626709, test_acc: 71.6, test_fscore: 71.95, time: 2.04 sec
epoch: 98, train_loss: 6.484300136566162, train_acc: 89.86, train_fscore: 89.79, valid_loss: 6.784200191497803, valid_acc: 74.25, valid_fscore: 74.76, test_loss: 7.748199939727783, test_acc: 70.49, test_fscore: 70.96, time: 1.92 sec
epoch: 99, train_loss: 6.507299900054932, train_acc: 89.49, train_fscore: 89.42, valid_loss: 6.730800151824951, valid_acc: 73.8, valid_fscore: 74.23, test_loss: 7.722799777984619, test_acc: 70.43, test_fscore: 70.93, time: 2.26 sec
epoch: 100, train_loss: 6.4567999839782715, train_acc: 89.8, train_fscore: 89.72, valid_loss: 6.673500061035156, valid_acc: 74.55, valid_fscore: 74.81, test_loss: 7.732600212097168, test_acc: 70.55, test_fscore: 70.89, time: 2.05 sec
              precision    recall  f1-score   support

           0     0.4911    0.7639    0.5978     144.0
           1     0.8170    0.7837    0.8000     245.0
           2     0.6866    0.7474    0.7157     384.0
           3     0.6595    0.7176    0.6873     170.0
           4     0.8837    0.6355    0.7393     299.0
           5     0.7052    0.6404    0.6713     381.0

    accuracy                         0.7055    1623.0
   macro avg     0.7072    0.7147    0.7019    1623.0
weighted avg     0.7268    0.7055    0.7089    1623.0

[[110.   5.  14.   0.  14.   1.]
 [  3. 192.  21.   3.   0.  26.]
 [ 31.  19. 287.   8.   4.  35.]
 [  0.   2.   7. 122.   0.  39.]
 [ 80.   1.  27.   0. 190.   1.]
 [  0.  16.  62.  52.   7. 244.]]
epoch: 101, train_loss: 6.434500217437744, train_acc: 90.26, train_fscore: 90.17, valid_loss: 6.708700180053711, valid_acc: 74.55, valid_fscore: 74.95, test_loss: 7.730299949645996, test_acc: 71.16, test_fscore: 71.54, time: 1.94 sec
epoch: 102, train_loss: 6.4471001625061035, train_acc: 90.11, train_fscore: 90.04, valid_loss: 6.750999927520752, valid_acc: 73.95, valid_fscore: 74.36, test_loss: 7.765999794006348, test_acc: 70.24, test_fscore: 70.67, time: 1.91 sec
epoch: 103, train_loss: 6.434999942779541, train_acc: 90.19, train_fscore: 90.14, valid_loss: 6.7505998611450195, valid_acc: 74.1, valid_fscore: 74.49, test_loss: 7.771100044250488, test_acc: 70.43, test_fscore: 70.82, time: 1.99 sec
epoch: 104, train_loss: 6.432499885559082, train_acc: 89.97, train_fscore: 89.89, valid_loss: 6.701000213623047, valid_acc: 75.0, valid_fscore: 75.34, test_loss: 7.740900039672852, test_acc: 71.16, test_fscore: 71.57, time: 2.83 sec
epoch: 105, train_loss: 6.41540002822876, train_acc: 90.24, train_fscore: 90.16, valid_loss: 6.697000026702881, valid_acc: 75.15, valid_fscore: 75.48, test_loss: 7.799099922180176, test_acc: 70.55, test_fscore: 70.96, time: 3.17 sec
epoch: 106, train_loss: 6.404099941253662, train_acc: 90.89, train_fscore: 90.83, valid_loss: 6.750400066375732, valid_acc: 73.95, valid_fscore: 74.24, test_loss: 7.736299991607666, test_acc: 70.73, test_fscore: 71.08, time: 3.61 sec
epoch: 107, train_loss: 6.402599811553955, train_acc: 90.54, train_fscore: 90.47, valid_loss: 6.761199951171875, valid_acc: 72.29, valid_fscore: 72.58, test_loss: 7.686800003051758, test_acc: 71.53, test_fscore: 71.93, time: 3.61 sec
epoch: 108, train_loss: 6.3892998695373535, train_acc: 90.73, train_fscore: 90.67, valid_loss: 6.7230000495910645, valid_acc: 73.95, valid_fscore: 74.44, test_loss: 7.827700138092041, test_acc: 70.36, test_fscore: 70.8, time: 5.03 sec
epoch: 109, train_loss: 6.37939977645874, train_acc: 91.12, train_fscore: 91.05, valid_loss: 6.7581000328063965, valid_acc: 74.85, valid_fscore: 75.13, test_loss: 7.805600166320801, test_acc: 70.12, test_fscore: 70.41, time: 4.83 sec
epoch: 110, train_loss: 6.377999782562256, train_acc: 91.49, train_fscore: 91.45, valid_loss: 6.830599784851074, valid_acc: 73.34, valid_fscore: 73.46, test_loss: 7.734099864959717, test_acc: 71.72, test_fscore: 72.06, time: 4.64 sec
              precision    recall  f1-score   support

           0     0.5354    0.7361    0.6199     144.0
           1     0.8341    0.7388    0.7835     245.0
           2     0.7114    0.7318    0.7214     384.0
           3     0.6778    0.7176    0.6971     170.0
           4     0.8761    0.6856    0.7692     299.0
           5     0.6742    0.7060    0.6897     381.0

    accuracy                         0.7172    1623.0
   macro avg     0.7181    0.7193    0.7135    1623.0
weighted avg     0.7324    0.7172    0.7206    1623.0

[[106.   4.  15.   0.  18.   1.]
 [  3. 181.  25.   3.   0.  33.]
 [ 24.  17. 281.   7.   6.  49.]
 [  0.   0.   3. 122.   0.  45.]
 [ 65.   1.  26.   0. 205.   2.]
 [  0.  14.  45.  48.   5. 269.]]
epoch: 111, train_loss: 6.3572998046875, train_acc: 91.27, train_fscore: 91.23, valid_loss: 6.781000137329102, valid_acc: 73.19, valid_fscore: 73.73, test_loss: 7.859099864959717, test_acc: 70.36, test_fscore: 70.74, time: 4.53 sec
epoch: 112, train_loss: 6.3516998291015625, train_acc: 90.79, train_fscore: 90.73, valid_loss: 6.805799961090088, valid_acc: 73.34, valid_fscore: 73.87, test_loss: 7.950500011444092, test_acc: 69.01, test_fscore: 69.33, time: 4.64 sec
epoch: 113, train_loss: 6.314000129699707, train_acc: 91.31, train_fscore: 91.25, valid_loss: 6.826499938964844, valid_acc: 73.04, valid_fscore: 73.25, test_loss: 7.83489990234375, test_acc: 71.1, test_fscore: 71.43, time: 3.85 sec
epoch: 114, train_loss: 6.342700004577637, train_acc: 91.39, train_fscore: 91.33, valid_loss: 6.778200149536133, valid_acc: 72.44, valid_fscore: 72.7, test_loss: 7.831600189208984, test_acc: 71.16, test_fscore: 71.6, time: 4.48 sec
epoch: 115, train_loss: 6.334499835968018, train_acc: 91.35, train_fscore: 91.3, valid_loss: 6.787899971008301, valid_acc: 73.34, valid_fscore: 73.81, test_loss: 7.8668999671936035, test_acc: 70.06, test_fscore: 70.48, time: 3.94 sec
epoch: 116, train_loss: 6.32420015335083, train_acc: 91.84, train_fscore: 91.79, valid_loss: 6.8231000900268555, valid_acc: 73.95, valid_fscore: 74.16, test_loss: 7.823800086975098, test_acc: 70.98, test_fscore: 71.29, time: 4.4 sec
epoch: 117, train_loss: 6.307199954986572, train_acc: 91.37, train_fscore: 91.32, valid_loss: 6.764599800109863, valid_acc: 74.1, valid_fscore: 74.21, test_loss: 7.766300201416016, test_acc: 71.72, test_fscore: 72.06, time: 4.45 sec
epoch: 118, train_loss: 6.277900218963623, train_acc: 91.68, train_fscore: 91.62, valid_loss: 6.770400047302246, valid_acc: 73.64, valid_fscore: 73.89, test_loss: 7.789999961853027, test_acc: 70.92, test_fscore: 71.34, time: 4.7 sec
epoch: 119, train_loss: 6.304500102996826, train_acc: 91.66, train_fscore: 91.6, valid_loss: 6.7729997634887695, valid_acc: 73.64, valid_fscore: 73.85, test_loss: 7.7515997886657715, test_acc: 71.78, test_fscore: 72.13, time: 4.78 sec
epoch: 120, train_loss: 6.279799938201904, train_acc: 92.07, train_fscore: 92.02, valid_loss: 6.764800071716309, valid_acc: 73.19, valid_fscore: 73.39, test_loss: 7.856800079345703, test_acc: 71.04, test_fscore: 71.38, time: 4.71 sec
              precision    recall  f1-score   support

           0     0.5231    0.7847    0.6278     144.0
           1     0.8362    0.7918    0.8134     245.0
           2     0.6992    0.7083    0.7038     384.0
           3     0.6631    0.7294    0.6947     170.0
           4     0.9005    0.6355    0.7451     299.0
           5     0.6701    0.6824    0.6762     381.0

    accuracy                         0.7104    1623.0
   macro avg     0.7154    0.7220    0.7102    1623.0
weighted avg     0.7307    0.7104    0.7138    1623.0

[[113.   5.  14.   0.  11.   1.]
 [  2. 194.  16.   3.   0.  30.]
 [ 28.  18. 272.   8.   5.  53.]
 [  0.   0.   3. 124.   0.  43.]
 [ 73.   2.  33.   0. 190.   1.]
 [  0.  13.  51.  52.   5. 260.]]
epoch: 121, train_loss: 6.282700061798096, train_acc: 91.64, train_fscore: 91.59, valid_loss: 6.7758002281188965, valid_acc: 73.19, valid_fscore: 73.55, test_loss: 7.926599979400635, test_acc: 69.93, test_fscore: 70.3, time: 4.61 sec
epoch: 122, train_loss: 6.262899875640869, train_acc: 92.36, train_fscore: 92.31, valid_loss: 6.85260009765625, valid_acc: 72.74, valid_fscore: 72.93, test_loss: 7.827300071716309, test_acc: 71.84, test_fscore: 72.16, time: 4.5 sec
epoch: 123, train_loss: 6.23859977722168, train_acc: 92.23, train_fscore: 92.17, valid_loss: 6.931000232696533, valid_acc: 73.34, valid_fscore: 73.63, test_loss: 7.847400188446045, test_acc: 71.47, test_fscore: 71.84, time: 4.66 sec
epoch: 124, train_loss: 6.267000198364258, train_acc: 92.01, train_fscore: 91.97, valid_loss: 6.86329984664917, valid_acc: 73.8, valid_fscore: 74.06, test_loss: 7.926199913024902, test_acc: 70.3, test_fscore: 70.68, time: 4.1 sec
epoch: 125, train_loss: 6.222099781036377, train_acc: 92.23, train_fscore: 92.17, valid_loss: 6.819399833679199, valid_acc: 73.8, valid_fscore: 74.13, test_loss: 7.980100154876709, test_acc: 70.61, test_fscore: 71.0, time: 4.32 sec
epoch: 126, train_loss: 6.2281999588012695, train_acc: 92.48, train_fscore: 92.42, valid_loss: 6.891900062561035, valid_acc: 73.64, valid_fscore: 73.77, test_loss: 7.854499816894531, test_acc: 71.72, test_fscore: 72.09, time: 4.45 sec
epoch: 127, train_loss: 6.23960018157959, train_acc: 92.42, train_fscore: 92.39, valid_loss: 6.875500202178955, valid_acc: 73.49, valid_fscore: 73.67, test_loss: 7.82919979095459, test_acc: 71.97, test_fscore: 72.25, time: 4.47 sec
epoch: 128, train_loss: 6.2083001136779785, train_acc: 92.95, train_fscore: 92.91, valid_loss: 6.8317999839782715, valid_acc: 73.95, valid_fscore: 74.32, test_loss: 7.878300189971924, test_acc: 70.55, test_fscore: 70.87, time: 3.58 sec
epoch: 129, train_loss: 6.20550012588501, train_acc: 92.71, train_fscore: 92.66, valid_loss: 6.8769001960754395, valid_acc: 73.49, valid_fscore: 73.61, test_loss: 7.865799903869629, test_acc: 71.78, test_fscore: 72.13, time: 4.2 sec
epoch: 130, train_loss: 6.189499855041504, train_acc: 92.79, train_fscore: 92.75, valid_loss: 6.863500118255615, valid_acc: 73.49, valid_fscore: 73.61, test_loss: 7.913000106811523, test_acc: 71.1, test_fscore: 71.46, time: 4.37 sec
              precision    recall  f1-score   support

           0     0.5183    0.7847    0.6243     144.0
           1     0.8319    0.7673    0.7983     245.0
           2     0.7005    0.7188    0.7095     384.0
           3     0.6703    0.7294    0.6986     170.0
           4     0.8935    0.6455    0.7495     299.0
           5     0.6771    0.6824    0.6797     381.0

    accuracy                         0.7110    1623.0
   macro avg     0.7153    0.7214    0.7100    1623.0
weighted avg     0.7311    0.7110    0.7146    1623.0

[[113.   4.  13.   0.  13.   1.]
 [  2. 188.  24.   3.   0.  28.]
 [ 28.  18. 276.   6.   5.  51.]
 [  0.   0.   3. 124.   0.  43.]
 [ 75.   2.  28.   0. 193.   1.]
 [  0.  14.  50.  52.   5. 260.]]
epoch: 131, train_loss: 6.171800136566162, train_acc: 92.79, train_fscore: 92.75, valid_loss: 6.855299949645996, valid_acc: 74.25, valid_fscore: 74.53, test_loss: 7.984000205993652, test_acc: 70.79, test_fscore: 71.07, time: 4.17 sec
epoch: 132, train_loss: 6.15310001373291, train_acc: 93.37, train_fscore: 93.32, valid_loss: 6.9141998291015625, valid_acc: 73.49, valid_fscore: 73.64, test_loss: 7.833199977874756, test_acc: 71.66, test_fscore: 71.96, time: 4.43 sec
epoch: 133, train_loss: 6.18120002746582, train_acc: 93.1, train_fscore: 93.07, valid_loss: 6.9710001945495605, valid_acc: 73.04, valid_fscore: 73.31, test_loss: 7.911300182342529, test_acc: 71.41, test_fscore: 71.79, time: 4.55 sec
epoch: 134, train_loss: 6.165200233459473, train_acc: 92.95, train_fscore: 92.91, valid_loss: 6.8942999839782715, valid_acc: 73.19, valid_fscore: 73.62, test_loss: 7.996300220489502, test_acc: 70.73, test_fscore: 71.05, time: 4.65 sec
epoch: 135, train_loss: 6.162399768829346, train_acc: 93.2, train_fscore: 93.14, valid_loss: 6.900599956512451, valid_acc: 73.49, valid_fscore: 73.63, test_loss: 7.936200141906738, test_acc: 71.04, test_fscore: 71.33, time: 4.54 sec
epoch: 136, train_loss: 6.146599769592285, train_acc: 93.18, train_fscore: 93.13, valid_loss: 7.048900127410889, valid_acc: 72.74, valid_fscore: 72.95, test_loss: 7.944399833679199, test_acc: 71.9, test_fscore: 72.25, time: 4.35 sec
epoch: 137, train_loss: 6.163000106811523, train_acc: 93.72, train_fscore: 93.71, valid_loss: 7.006999969482422, valid_acc: 73.64, valid_fscore: 73.94, test_loss: 7.9232001304626465, test_acc: 71.53, test_fscore: 71.83, time: 4.19 sec
epoch: 138, train_loss: 6.154600143432617, train_acc: 93.72, train_fscore: 93.68, valid_loss: 6.927599906921387, valid_acc: 73.8, valid_fscore: 74.02, test_loss: 8.003499984741211, test_acc: 71.29, test_fscore: 71.61, time: 4.73 sec
epoch: 139, train_loss: 6.125100135803223, train_acc: 93.41, train_fscore: 93.38, valid_loss: 6.960999965667725, valid_acc: 73.95, valid_fscore: 74.06, test_loss: 8.023900032043457, test_acc: 70.73, test_fscore: 71.08, time: 4.63 sec
epoch: 140, train_loss: 6.1350998878479, train_acc: 93.84, train_fscore: 93.81, valid_loss: 7.014999866485596, valid_acc: 73.8, valid_fscore: 73.94, test_loss: 7.99970006942749, test_acc: 70.98, test_fscore: 71.35, time: 4.6 sec
              precision    recall  f1-score   support

           0     0.5189    0.7639    0.6180     144.0
           1     0.8378    0.7592    0.7966     245.0
           2     0.6787    0.7318    0.7043     384.0
           3     0.6816    0.7176    0.6991     170.0
           4     0.8950    0.6555    0.7568     299.0
           5     0.6817    0.6745    0.6781     381.0

    accuracy                         0.7098    1623.0
   macro avg     0.7156    0.7171    0.7088    1623.0
weighted avg     0.7294    0.7098    0.7135    1623.0

[[110.   5.  15.   0.  13.   1.]
 [  3. 186.  25.   3.   0.  28.]
 [ 31.  17. 281.   4.   5.  46.]
 [  0.   0.   5. 122.   0.  43.]
 [ 68.   1.  32.   0. 196.   2.]
 [  0.  13.  56.  50.   5. 257.]]
epoch: 141, train_loss: 6.120500087738037, train_acc: 94.07, train_fscore: 94.04, valid_loss: 6.968500137329102, valid_acc: 73.8, valid_fscore: 73.95, test_loss: 7.979400157928467, test_acc: 71.35, test_fscore: 71.7, time: 4.58 sec
epoch: 142, train_loss: 6.098700046539307, train_acc: 94.21, train_fscore: 94.16, valid_loss: 6.954599857330322, valid_acc: 73.8, valid_fscore: 73.78, test_loss: 7.97790002822876, test_acc: 71.53, test_fscore: 71.83, time: 4.62 sec
epoch: 143, train_loss: 6.107699871063232, train_acc: 94.17, train_fscore: 94.13, valid_loss: 7.025000095367432, valid_acc: 73.19, valid_fscore: 73.52, test_loss: 8.05519962310791, test_acc: 71.16, test_fscore: 71.49, time: 4.58 sec
epoch: 144, train_loss: 6.104700088500977, train_acc: 94.0, train_fscore: 93.96, valid_loss: 7.037399768829346, valid_acc: 73.04, valid_fscore: 73.41, test_loss: 8.077400207519531, test_acc: 70.79, test_fscore: 71.16, time: 4.41 sec
epoch: 145, train_loss: 6.10699987411499, train_acc: 94.29, train_fscore: 94.25, valid_loss: 7.066800117492676, valid_acc: 74.25, valid_fscore: 74.28, test_loss: 8.057299613952637, test_acc: 70.98, test_fscore: 71.27, time: 4.13 sec
epoch: 146, train_loss: 6.080399990081787, train_acc: 94.27, train_fscore: 94.24, valid_loss: 7.074900150299072, valid_acc: 73.95, valid_fscore: 73.91, test_loss: 7.948500156402588, test_acc: 71.41, test_fscore: 71.69, time: 4.48 sec
epoch: 147, train_loss: 6.076200008392334, train_acc: 93.74, train_fscore: 93.7, valid_loss: 7.065199851989746, valid_acc: 72.29, valid_fscore: 72.65, test_loss: 8.075699806213379, test_acc: 70.06, test_fscore: 70.39, time: 4.17 sec
epoch: 148, train_loss: 6.082499980926514, train_acc: 94.27, train_fscore: 94.24, valid_loss: 7.045599937438965, valid_acc: 73.34, valid_fscore: 73.5, test_loss: 8.047800064086914, test_acc: 70.86, test_fscore: 71.13, time: 4.58 sec
epoch: 149, train_loss: 6.0467000007629395, train_acc: 94.75, train_fscore: 94.72, valid_loss: 7.040800094604492, valid_acc: 73.04, valid_fscore: 73.04, test_loss: 8.005900382995605, test_acc: 71.53, test_fscore: 71.8, time: 4.66 sec
epoch: 150, train_loss: 6.098800182342529, train_acc: 94.13, train_fscore: 94.09, valid_loss: 7.031300067901611, valid_acc: 72.44, valid_fscore: 72.71, test_loss: 8.127099990844727, test_acc: 69.99, test_fscore: 70.37, time: 4.66 sec
              precision    recall  f1-score   support

           0     0.4956    0.7778    0.6054     144.0
           1     0.8311    0.7633    0.7957     245.0
           2     0.6699    0.7292    0.6983     384.0
           3     0.6860    0.6941    0.6901     170.0
           4     0.9010    0.6087    0.7265     299.0
           5     0.6763    0.6745    0.6754     381.0

    accuracy                         0.6999    1623.0
   macro avg     0.7100    0.7079    0.6986    1623.0
weighted avg     0.7245    0.6999    0.7037    1623.0

[[112.   5.  15.   0.  11.   1.]
 [  3. 187.  24.   2.   0.  29.]
 [ 31.  18. 280.   4.   4.  47.]
 [  0.   0.   7. 118.   0.  45.]
 [ 80.   1.  35.   0. 182.   1.]
 [  0.  14.  57.  48.   5. 257.]]
Best validation F-Score: 70.37
Test performance..
F-Score: 70.37
Accuracy: 69.99
Loss: 8.127099990844727
--- 8 ---
loss_mask: [True, True, True, True]
Namespace(no_cuda=False, lr=0.0001, l2=1e-05, dropout=0.5, batch_size=64, hidden_dim=1024, n_head=8, epochs=150, temp=2, tensorboard=False, class_weight=True, Dataset='IEMOCAP', loss_mask='1111')
Running on GPU
temp 2
total parameters: 97535000
training parameters: 97535000
epoch: 1, train_loss: 12.305899620056152, train_acc: 18.25, train_fscore: 18.49, valid_loss: 10.164199829101562, valid_acc: 39.91, valid_fscore: 37.68, test_loss: 11.160300254821777, test_acc: 35.8, test_fscore: 32.71, time: 5.68 sec
epoch: 2, train_loss: 11.542799949645996, train_acc: 38.96, train_fscore: 35.29, valid_loss: 9.746299743652344, valid_acc: 46.23, valid_fscore: 45.0, test_loss: 10.72189998626709, test_acc: 39.8, test_fscore: 38.73, time: 4.57 sec
epoch: 3, train_loss: 11.06149959564209, train_acc: 46.4, train_fscore: 44.21, valid_loss: 9.333100318908691, valid_acc: 50.3, valid_fscore: 51.25, test_loss: 10.360400199890137, test_acc: 46.27, test_fscore: 45.13, time: 4.34 sec
epoch: 4, train_loss: 10.645500183105469, train_acc: 53.3, train_fscore: 51.67, valid_loss: 8.915599822998047, valid_acc: 60.84, valid_fscore: 60.82, test_loss: 9.998600006103516, test_acc: 54.28, test_fscore: 53.55, time: 3.41 sec
epoch: 5, train_loss: 10.368399620056152, train_acc: 58.12, train_fscore: 57.04, valid_loss: 8.726400375366211, valid_acc: 62.35, valid_fscore: 63.09, test_loss: 9.878299713134766, test_acc: 55.88, test_fscore: 56.11, time: 4.28 sec
epoch: 6, train_loss: 10.120699882507324, train_acc: 60.65, train_fscore: 60.01, valid_loss: 8.576299667358398, valid_acc: 63.4, valid_fscore: 64.43, test_loss: 9.743499755859375, test_acc: 56.44, test_fscore: 56.87, time: 4.64 sec
epoch: 7, train_loss: 9.837800025939941, train_acc: 62.59, train_fscore: 62.17, valid_loss: 8.238900184631348, valid_acc: 65.81, valid_fscore: 66.91, test_loss: 9.480799674987793, test_acc: 59.4, test_fscore: 59.79, time: 4.67 sec
epoch: 8, train_loss: 9.509900093078613, train_acc: 65.29, train_fscore: 64.86, valid_loss: 7.833899974822998, valid_acc: 65.66, valid_fscore: 67.36, test_loss: 9.139200210571289, test_acc: 59.46, test_fscore: 60.05, time: 4.57 sec
epoch: 9, train_loss: 9.196100234985352, train_acc: 66.32, train_fscore: 66.03, valid_loss: 7.571300029754639, valid_acc: 64.46, valid_fscore: 66.9, test_loss: 8.833700180053711, test_acc: 59.77, test_fscore: 60.6, time: 4.49 sec
epoch: 10, train_loss: 8.986000061035156, train_acc: 66.98, train_fscore: 66.74, valid_loss: 7.49970006942749, valid_acc: 65.96, valid_fscore: 68.34, test_loss: 8.71619987487793, test_acc: 61.74, test_fscore: 62.91, time: 4.52 sec
              precision    recall  f1-score   support

           0     0.3178    0.7083    0.4387     144.0
           1     0.8122    0.6531    0.7240     245.0
           2     0.6327    0.5339    0.5791     384.0
           3     0.6173    0.7118    0.6612     170.0
           4     0.8095    0.5686    0.6680     299.0
           5     0.6507    0.6404    0.6455     381.0

    accuracy                         0.6174    1623.0
   macro avg     0.6400    0.6360    0.6194    1623.0
weighted avg     0.6670    0.6174    0.6291    1623.0

[[102.   5.   7.   0.  28.   2.]
 [ 19. 160.  36.   2.   2.  26.]
 [ 72.  20. 205.  24.   2.  61.]
 [  0.   0.   8. 121.   0.  41.]
 [117.   0.   9.   2. 170.   1.]
 [ 11.  12.  59.  47.   8. 244.]]
epoch: 11, train_loss: 8.88290023803711, train_acc: 67.8, train_fscore: 67.71, valid_loss: 7.3678998947143555, valid_acc: 66.87, valid_fscore: 68.24, test_loss: 8.607600212097168, test_acc: 62.91, test_fscore: 63.87, time: 4.6 sec
epoch: 12, train_loss: 8.798299789428711, train_acc: 68.62, train_fscore: 68.25, valid_loss: 7.216400146484375, valid_acc: 66.87, valid_fscore: 68.27, test_loss: 8.50160026550293, test_acc: 63.89, test_fscore: 64.74, time: 3.44 sec
epoch: 13, train_loss: 8.669400215148926, train_acc: 69.67, train_fscore: 69.46, valid_loss: 7.009399890899658, valid_acc: 67.17, valid_fscore: 68.87, test_loss: 8.312100410461426, test_acc: 62.72, test_fscore: 63.7, time: 4.27 sec
epoch: 14, train_loss: 8.573699951171875, train_acc: 68.36, train_fscore: 67.91, valid_loss: 6.986000061035156, valid_acc: 67.92, valid_fscore: 69.84, test_loss: 8.24590015411377, test_acc: 62.23, test_fscore: 63.27, time: 4.65 sec
epoch: 15, train_loss: 8.48960018157959, train_acc: 68.93, train_fscore: 68.56, valid_loss: 7.008900165557861, valid_acc: 68.52, valid_fscore: 70.83, test_loss: 8.291199684143066, test_acc: 60.44, test_fscore: 61.2, time: 4.56 sec
epoch: 16, train_loss: 8.455499649047852, train_acc: 68.77, train_fscore: 68.51, valid_loss: 6.935299873352051, valid_acc: 70.78, valid_fscore: 71.71, test_loss: 8.233799934387207, test_acc: 64.39, test_fscore: 65.05, time: 4.61 sec
epoch: 17, train_loss: 8.37600040435791, train_acc: 70.79, train_fscore: 70.27, valid_loss: 6.785099983215332, valid_acc: 69.73, valid_fscore: 70.61, test_loss: 8.097100257873535, test_acc: 65.5, test_fscore: 65.96, time: 4.62 sec
epoch: 18, train_loss: 8.307499885559082, train_acc: 71.75, train_fscore: 71.29, valid_loss: 6.777200222015381, valid_acc: 68.83, valid_fscore: 70.9, test_loss: 8.076399803161621, test_acc: 63.4, test_fscore: 64.42, time: 4.27 sec
epoch: 19, train_loss: 8.22760009765625, train_acc: 72.62, train_fscore: 72.4, valid_loss: 6.768799781799316, valid_acc: 70.18, valid_fscore: 71.48, test_loss: 8.1003999710083, test_acc: 64.76, test_fscore: 65.54, time: 4.43 sec
epoch: 20, train_loss: 8.173199653625488, train_acc: 72.87, train_fscore: 72.54, valid_loss: 6.76800012588501, valid_acc: 71.08, valid_fscore: 71.99, test_loss: 8.105899810791016, test_acc: 65.99, test_fscore: 66.61, time: 4.56 sec
              precision    recall  f1-score   support

           0     0.4053    0.6389    0.4960     144.0
           1     0.7860    0.6898    0.7348     245.0
           2     0.6629    0.6094    0.6350     384.0
           3     0.6059    0.7235    0.6595     170.0
           4     0.8375    0.6722    0.7458     299.0
           5     0.6545    0.6614    0.6580     381.0

    accuracy                         0.6599    1623.0
   macro avg     0.6587    0.6659    0.6548    1623.0
weighted avg     0.6829    0.6599    0.6661    1623.0

[[ 92.   6.  10.   3.  29.   4.]
 [  6. 169.  38.   1.   0.  31.]
 [ 46.  24. 234.  21.   4.  55.]
 [  0.   0.   5. 123.   0.  42.]
 [ 81.   0.  16.   0. 201.   1.]
 [  2.  16.  50.  55.   6. 252.]]
epoch: 21, train_loss: 8.141200065612793, train_acc: 72.58, train_fscore: 72.36, valid_loss: 6.7779998779296875, valid_acc: 67.02, valid_fscore: 68.78, test_loss: 8.06980037689209, test_acc: 63.89, test_fscore: 64.81, time: 4.55 sec
epoch: 22, train_loss: 8.081100463867188, train_acc: 72.64, train_fscore: 72.46, valid_loss: 6.67549991607666, valid_acc: 69.58, valid_fscore: 71.14, test_loss: 7.974599838256836, test_acc: 65.68, test_fscore: 66.44, time: 4.56 sec
epoch: 23, train_loss: 8.028300285339355, train_acc: 73.86, train_fscore: 73.59, valid_loss: 6.639999866485596, valid_acc: 71.84, valid_fscore: 72.11, test_loss: 7.942800045013428, test_acc: 67.59, test_fscore: 67.8, time: 4.45 sec
epoch: 24, train_loss: 7.994900226593018, train_acc: 74.31, train_fscore: 74.05, valid_loss: 6.6346001625061035, valid_acc: 70.93, valid_fscore: 72.29, test_loss: 7.945700168609619, test_acc: 65.8, test_fscore: 66.54, time: 4.6 sec
epoch: 25, train_loss: 7.92519998550415, train_acc: 74.89, train_fscore: 74.67, valid_loss: 6.632199764251709, valid_acc: 70.03, valid_fscore: 72.03, test_loss: 7.969900131225586, test_acc: 64.57, test_fscore: 65.41, time: 4.66 sec
epoch: 26, train_loss: 7.890699863433838, train_acc: 74.19, train_fscore: 74.0, valid_loss: 6.594099998474121, valid_acc: 71.84, valid_fscore: 72.77, test_loss: 7.908899784088135, test_acc: 67.53, test_fscore: 68.09, time: 4.47 sec
epoch: 27, train_loss: 7.8394999504089355, train_acc: 75.44, train_fscore: 75.14, valid_loss: 6.569399833679199, valid_acc: 71.84, valid_fscore: 72.71, test_loss: 7.841899871826172, test_acc: 67.71, test_fscore: 68.14, time: 4.48 sec
epoch: 28, train_loss: 7.801499843597412, train_acc: 75.11, train_fscore: 74.86, valid_loss: 6.564300060272217, valid_acc: 69.88, valid_fscore: 71.53, test_loss: 7.850900173187256, test_acc: 65.93, test_fscore: 66.7, time: 4.73 sec
epoch: 29, train_loss: 7.77209997177124, train_acc: 75.18, train_fscore: 75.11, valid_loss: 6.5279998779296875, valid_acc: 71.39, valid_fscore: 72.9, test_loss: 7.819399833679199, test_acc: 65.74, test_fscore: 66.46, time: 4.6 sec
epoch: 30, train_loss: 7.7133002281188965, train_acc: 76.1, train_fscore: 75.85, valid_loss: 6.517600059509277, valid_acc: 71.99, valid_fscore: 72.68, test_loss: 7.765600204467773, test_acc: 67.22, test_fscore: 67.6, time: 4.41 sec
              precision    recall  f1-score   support

           0     0.4421    0.5833    0.5030     144.0
           1     0.7743    0.7143    0.7431     245.0
           2     0.6722    0.6354    0.6533     384.0
           3     0.5830    0.7647    0.6616     170.0
           4     0.8346    0.7425    0.7858     299.0
           5     0.6648    0.6194    0.6413     381.0

    accuracy                         0.6722    1623.0
   macro avg     0.6618    0.6766    0.6647    1623.0
weighted avg     0.6860    0.6722    0.6760    1623.0

[[ 84.   7.  17.   3.  30.   3.]
 [  3. 175.  32.   2.   0.  33.]
 [ 39.  26. 244.  22.   8.  45.]
 [  0.   0.   3. 130.   0.  37.]
 [ 64.   0.  12.   0. 222.   1.]
 [  0.  18.  55.  66.   6. 236.]]
epoch: 31, train_loss: 7.678899765014648, train_acc: 76.58, train_fscore: 76.28, valid_loss: 6.532400131225586, valid_acc: 70.63, valid_fscore: 71.86, test_loss: 7.77239990234375, test_acc: 66.73, test_fscore: 67.39, time: 4.63 sec
epoch: 32, train_loss: 7.639599800109863, train_acc: 76.64, train_fscore: 76.53, valid_loss: 6.5625, valid_acc: 70.48, valid_fscore: 72.45, test_loss: 7.849299907684326, test_acc: 64.88, test_fscore: 65.55, time: 4.54 sec
epoch: 33, train_loss: 7.6118998527526855, train_acc: 76.86, train_fscore: 76.74, valid_loss: 6.503399848937988, valid_acc: 71.23, valid_fscore: 72.24, test_loss: 7.773099899291992, test_acc: 67.41, test_fscore: 68.01, time: 4.56 sec
epoch: 34, train_loss: 7.573299884796143, train_acc: 77.57, train_fscore: 77.43, valid_loss: 6.537099838256836, valid_acc: 70.63, valid_fscore: 71.58, test_loss: 7.713699817657471, test_acc: 67.96, test_fscore: 68.53, time: 4.49 sec
epoch: 35, train_loss: 7.568900108337402, train_acc: 77.48, train_fscore: 77.29, valid_loss: 6.564599990844727, valid_acc: 70.18, valid_fscore: 71.7, test_loss: 7.754899978637695, test_acc: 65.06, test_fscore: 65.81, time: 4.53 sec
epoch: 36, train_loss: 7.538099765777588, train_acc: 77.36, train_fscore: 77.24, valid_loss: 6.5278000831604, valid_acc: 71.69, valid_fscore: 72.96, test_loss: 7.7617998123168945, test_acc: 65.87, test_fscore: 66.6, time: 4.59 sec
epoch: 37, train_loss: 7.477099895477295, train_acc: 78.35, train_fscore: 78.23, valid_loss: 6.480400085449219, valid_acc: 72.29, valid_fscore: 73.2, test_loss: 7.690100193023682, test_acc: 67.28, test_fscore: 67.83, time: 4.32 sec
epoch: 38, train_loss: 7.462299823760986, train_acc: 78.97, train_fscore: 78.8, valid_loss: 6.483799934387207, valid_acc: 70.93, valid_fscore: 72.08, test_loss: 7.645899772644043, test_acc: 66.91, test_fscore: 67.55, time: 4.03 sec
epoch: 39, train_loss: 7.445000171661377, train_acc: 78.68, train_fscore: 78.53, valid_loss: 6.52839994430542, valid_acc: 71.39, valid_fscore: 72.69, test_loss: 7.698599815368652, test_acc: 66.36, test_fscore: 67.1, time: 4.61 sec
epoch: 40, train_loss: 7.429100036621094, train_acc: 78.97, train_fscore: 78.89, valid_loss: 6.504700183868408, valid_acc: 72.44, valid_fscore: 73.35, test_loss: 7.698500156402588, test_acc: 67.22, test_fscore: 67.8, time: 4.53 sec
              precision    recall  f1-score   support

           0     0.4310    0.7153    0.5379     144.0
           1     0.7964    0.7184    0.7554     245.0
           2     0.6731    0.6328    0.6523     384.0
           3     0.6332    0.7412    0.6829     170.0
           4     0.8810    0.6187    0.7269     299.0
           5     0.6565    0.6772    0.6667     381.0

    accuracy                         0.6722    1623.0
   macro avg     0.6785    0.6839    0.6703    1623.0
weighted avg     0.7004    0.6722    0.6780    1623.0

[[103.   6.  15.   1.  15.   4.]
 [  3. 176.  31.   2.   0.  33.]
 [ 41.  23. 243.  16.   5.  56.]
 [  0.   0.   3. 126.   0.  41.]
 [ 92.   1.  20.   0. 185.   1.]
 [  0.  15.  49.  54.   5. 258.]]
epoch: 41, train_loss: 7.390200138092041, train_acc: 79.65, train_fscore: 79.55, valid_loss: 6.473800182342529, valid_acc: 72.74, valid_fscore: 73.74, test_loss: 7.645599842071533, test_acc: 67.65, test_fscore: 68.28, time: 4.48 sec
epoch: 42, train_loss: 7.3520002365112305, train_acc: 79.56, train_fscore: 79.41, valid_loss: 6.484899997711182, valid_acc: 71.23, valid_fscore: 72.3, test_loss: 7.638299942016602, test_acc: 67.04, test_fscore: 67.71, time: 4.68 sec
epoch: 43, train_loss: 7.334799766540527, train_acc: 79.75, train_fscore: 79.58, valid_loss: 6.452300071716309, valid_acc: 72.29, valid_fscore: 73.23, test_loss: 7.612500190734863, test_acc: 67.65, test_fscore: 68.3, time: 4.46 sec
epoch: 44, train_loss: 7.313399791717529, train_acc: 80.41, train_fscore: 80.28, valid_loss: 6.4496002197265625, valid_acc: 72.89, valid_fscore: 73.68, test_loss: 7.624800205230713, test_acc: 67.84, test_fscore: 68.43, time: 4.72 sec
epoch: 45, train_loss: 7.310100078582764, train_acc: 80.31, train_fscore: 80.17, valid_loss: 6.499499797821045, valid_acc: 71.84, valid_fscore: 72.82, test_loss: 7.611999988555908, test_acc: 67.78, test_fscore: 68.42, time: 4.23 sec
epoch: 46, train_loss: 7.254199981689453, train_acc: 80.7, train_fscore: 80.6, valid_loss: 6.509699821472168, valid_acc: 71.23, valid_fscore: 72.34, test_loss: 7.629499912261963, test_acc: 67.41, test_fscore: 68.08, time: 3.95 sec
epoch: 47, train_loss: 7.2480998039245605, train_acc: 80.66, train_fscore: 80.55, valid_loss: 6.477399826049805, valid_acc: 71.99, valid_fscore: 72.87, test_loss: 7.610599994659424, test_acc: 68.21, test_fscore: 68.84, time: 4.13 sec
epoch: 48, train_loss: 7.233699798583984, train_acc: 81.21, train_fscore: 81.09, valid_loss: 6.481599807739258, valid_acc: 72.59, valid_fscore: 73.5, test_loss: 7.578199863433838, test_acc: 67.1, test_fscore: 67.69, time: 4.22 sec
epoch: 49, train_loss: 7.184899806976318, train_acc: 81.44, train_fscore: 81.31, valid_loss: 6.507800102233887, valid_acc: 71.99, valid_fscore: 73.08, test_loss: 7.601099967956543, test_acc: 67.9, test_fscore: 68.52, time: 3.52 sec
epoch: 50, train_loss: 7.1875, train_acc: 81.56, train_fscore: 81.45, valid_loss: 6.508699893951416, valid_acc: 72.44, valid_fscore: 73.33, test_loss: 7.578000068664551, test_acc: 68.33, test_fscore: 68.96, time: 4.52 sec
              precision    recall  f1-score   support

           0     0.4398    0.7361    0.5506     144.0
           1     0.8219    0.7347    0.7759     245.0
           2     0.7019    0.6562    0.6783     384.0
           3     0.6354    0.7176    0.6740     170.0
           4     0.8802    0.6388    0.7403     299.0
           5     0.6532    0.6772    0.6649     381.0

    accuracy                         0.6833    1623.0
   macro avg     0.6887    0.6934    0.6807    1623.0
weighted avg     0.7112    0.6833    0.6896    1623.0

[[106.   6.  14.   0.  15.   3.]
 [  3. 180.  26.   2.   0.  34.]
 [ 41.  19. 252.  13.   5.  54.]
 [  0.   0.   3. 122.   0.  45.]
 [ 91.   0.  16.   0. 191.   1.]
 [  0.  14.  48.  55.   6. 258.]]
epoch: 51, train_loss: 7.186600208282471, train_acc: 81.79, train_fscore: 81.71, valid_loss: 6.511300086975098, valid_acc: 73.19, valid_fscore: 74.03, test_loss: 7.593400001525879, test_acc: 67.9, test_fscore: 68.52, time: 4.54 sec
epoch: 52, train_loss: 7.161399841308594, train_acc: 82.43, train_fscore: 82.33, valid_loss: 6.508600234985352, valid_acc: 73.04, valid_fscore: 74.07, test_loss: 7.601099967956543, test_acc: 67.47, test_fscore: 68.06, time: 4.27 sec
epoch: 53, train_loss: 7.126800060272217, train_acc: 82.47, train_fscore: 82.38, valid_loss: 6.493100166320801, valid_acc: 73.19, valid_fscore: 74.09, test_loss: 7.576000213623047, test_acc: 68.21, test_fscore: 68.8, time: 4.39 sec
epoch: 54, train_loss: 7.067599773406982, train_acc: 82.67, train_fscore: 82.53, valid_loss: 6.520299911499023, valid_acc: 72.74, valid_fscore: 73.55, test_loss: 7.558599948883057, test_acc: 68.76, test_fscore: 69.33, time: 4.54 sec
epoch: 55, train_loss: 7.072199821472168, train_acc: 82.9, train_fscore: 82.8, valid_loss: 6.5808000564575195, valid_acc: 72.59, valid_fscore: 73.51, test_loss: 7.576499938964844, test_acc: 68.52, test_fscore: 69.13, time: 4.68 sec
epoch: 56, train_loss: 7.086599826812744, train_acc: 82.86, train_fscore: 82.76, valid_loss: 6.579599857330322, valid_acc: 72.89, valid_fscore: 73.98, test_loss: 7.617199897766113, test_acc: 68.21, test_fscore: 68.81, time: 4.61 sec
epoch: 57, train_loss: 7.03980016708374, train_acc: 83.46, train_fscore: 83.35, valid_loss: 6.539400100708008, valid_acc: 72.89, valid_fscore: 73.62, test_loss: 7.576200008392334, test_acc: 68.7, test_fscore: 69.25, time: 4.61 sec
epoch: 58, train_loss: 7.018899917602539, train_acc: 83.29, train_fscore: 83.16, valid_loss: 6.573400020599365, valid_acc: 72.59, valid_fscore: 73.35, test_loss: 7.546599864959717, test_acc: 68.21, test_fscore: 68.79, time: 4.11 sec
epoch: 59, train_loss: 7.002699851989746, train_acc: 83.79, train_fscore: 83.7, valid_loss: 6.607100009918213, valid_acc: 71.84, valid_fscore: 72.95, test_loss: 7.595900058746338, test_acc: 67.96, test_fscore: 68.57, time: 3.83 sec
epoch: 60, train_loss: 6.994900226593018, train_acc: 83.89, train_fscore: 83.8, valid_loss: 6.577199935913086, valid_acc: 72.59, valid_fscore: 73.28, test_loss: 7.545000076293945, test_acc: 68.95, test_fscore: 69.49, time: 4.62 sec
              precision    recall  f1-score   support

           0     0.4615    0.7500    0.5714     144.0
           1     0.8296    0.7551    0.7906     245.0
           2     0.7088    0.6719    0.6898     384.0
           3     0.6224    0.7176    0.6667     170.0
           4     0.8652    0.6656    0.7524     299.0
           5     0.6569    0.6483    0.6526     381.0

    accuracy                         0.6895    1623.0
   macro avg     0.6908    0.7014    0.6872    1623.0
weighted avg     0.7127    0.6895    0.6949    1623.0

[[108.   4.  12.   0.  18.   2.]
 [  2. 185.  23.   2.   1.  32.]
 [ 42.  19. 258.  12.   5.  48.]
 [  0.   0.   3. 122.   0.  45.]
 [ 82.   1.  15.   0. 199.   2.]
 [  0.  14.  53.  60.   7. 247.]]
epoch: 61, train_loss: 6.979499816894531, train_acc: 84.42, train_fscore: 84.31, valid_loss: 6.592400074005127, valid_acc: 72.44, valid_fscore: 73.18, test_loss: 7.554200172424316, test_acc: 69.25, test_fscore: 69.87, time: 4.58 sec
epoch: 62, train_loss: 6.963900089263916, train_acc: 84.24, train_fscore: 84.16, valid_loss: 6.5904998779296875, valid_acc: 73.04, valid_fscore: 73.86, test_loss: 7.60230016708374, test_acc: 67.96, test_fscore: 68.53, time: 4.59 sec
epoch: 63, train_loss: 6.942999839782715, train_acc: 84.67, train_fscore: 84.57, valid_loss: 6.55109977722168, valid_acc: 72.89, valid_fscore: 73.5, test_loss: 7.5441999435424805, test_acc: 69.01, test_fscore: 69.53, time: 4.48 sec
epoch: 64, train_loss: 6.9197001457214355, train_acc: 84.61, train_fscore: 84.48, valid_loss: 6.598299980163574, valid_acc: 72.89, valid_fscore: 73.44, test_loss: 7.526500225067139, test_acc: 69.25, test_fscore: 69.81, time: 4.3 sec
epoch: 65, train_loss: 6.911399841308594, train_acc: 84.65, train_fscore: 84.56, valid_loss: 6.612800121307373, valid_acc: 73.34, valid_fscore: 73.99, test_loss: 7.556600093841553, test_acc: 68.64, test_fscore: 69.21, time: 4.58 sec
epoch: 66, train_loss: 6.899400234222412, train_acc: 84.92, train_fscore: 84.81, valid_loss: 6.636099815368652, valid_acc: 72.89, valid_fscore: 73.65, test_loss: 7.583899974822998, test_acc: 68.45, test_fscore: 69.03, time: 2.41 sec
epoch: 67, train_loss: 6.873300075531006, train_acc: 84.92, train_fscore: 84.86, valid_loss: 6.619100093841553, valid_acc: 72.74, valid_fscore: 73.36, test_loss: 7.572400093078613, test_acc: 69.13, test_fscore: 69.71, time: 3.47 sec
epoch: 68, train_loss: 6.853000164031982, train_acc: 85.52, train_fscore: 85.4, valid_loss: 6.618100166320801, valid_acc: 73.04, valid_fscore: 73.59, test_loss: 7.550300121307373, test_acc: 69.13, test_fscore: 69.69, time: 2.78 sec
epoch: 69, train_loss: 6.859000205993652, train_acc: 85.48, train_fscore: 85.37, valid_loss: 6.694300174713135, valid_acc: 73.19, valid_fscore: 73.94, test_loss: 7.594399929046631, test_acc: 68.39, test_fscore: 68.96, time: 2.79 sec
epoch: 70, train_loss: 6.844299793243408, train_acc: 85.62, train_fscore: 85.56, valid_loss: 6.656000137329102, valid_acc: 72.89, valid_fscore: 73.47, test_loss: 7.5524001121521, test_acc: 69.25, test_fscore: 69.82, time: 2.18 sec
              precision    recall  f1-score   support

           0     0.4531    0.7708    0.5707     144.0
           1     0.8371    0.7551    0.7940     245.0
           2     0.7116    0.6875    0.6993     384.0
           3     0.6256    0.7471    0.6810     170.0
           4     0.8821    0.6254    0.7319     299.0
           5     0.6739    0.6562    0.6649     381.0

    accuracy                         0.6925    1623.0
   macro avg     0.6972    0.7070    0.6903    1623.0
weighted avg     0.7211    0.6925    0.6982    1623.0

[[111.   4.  13.   0.  15.   1.]
 [  2. 185.  24.   3.   1.  30.]
 [ 40.  17. 264.  11.   4.  48.]
 [  0.   0.   3. 127.   0.  40.]
 [ 92.   1.  17.   0. 187.   2.]
 [  0.  14.  50.  62.   5. 250.]]
epoch: 71, train_loss: 6.837800025939941, train_acc: 85.66, train_fscore: 85.54, valid_loss: 6.642600059509277, valid_acc: 72.59, valid_fscore: 73.28, test_loss: 7.597899913787842, test_acc: 69.13, test_fscore: 69.73, time: 2.64 sec
epoch: 72, train_loss: 6.791399955749512, train_acc: 85.93, train_fscore: 85.85, valid_loss: 6.653600215911865, valid_acc: 73.64, valid_fscore: 74.29, test_loss: 7.606800079345703, test_acc: 68.7, test_fscore: 69.29, time: 4.31 sec
epoch: 73, train_loss: 6.791999816894531, train_acc: 86.34, train_fscore: 86.26, valid_loss: 6.631199836730957, valid_acc: 74.25, valid_fscore: 74.76, test_loss: 7.537700176239014, test_acc: 69.32, test_fscore: 69.85, time: 4.52 sec
epoch: 74, train_loss: 6.781000137329102, train_acc: 86.14, train_fscore: 86.03, valid_loss: 6.641600131988525, valid_acc: 73.49, valid_fscore: 74.17, test_loss: 7.5625, test_acc: 69.5, test_fscore: 70.07, time: 4.62 sec
epoch: 75, train_loss: 6.7754998207092285, train_acc: 86.79, train_fscore: 86.7, valid_loss: 6.645199775695801, valid_acc: 73.19, valid_fscore: 73.91, test_loss: 7.625999927520752, test_acc: 68.39, test_fscore: 68.94, time: 4.52 sec
epoch: 76, train_loss: 6.765999794006348, train_acc: 86.42, train_fscore: 86.32, valid_loss: 6.644100189208984, valid_acc: 73.34, valid_fscore: 73.85, test_loss: 7.587900161743164, test_acc: 69.13, test_fscore: 69.7, time: 4.49 sec
epoch: 77, train_loss: 6.739500045776367, train_acc: 86.9, train_fscore: 86.82, valid_loss: 6.698400020599365, valid_acc: 71.84, valid_fscore: 72.49, test_loss: 7.584499835968018, test_acc: 69.25, test_fscore: 69.86, time: 4.21 sec
epoch: 78, train_loss: 6.7266998291015625, train_acc: 86.38, train_fscore: 86.29, valid_loss: 6.718800067901611, valid_acc: 72.29, valid_fscore: 73.03, test_loss: 7.603400230407715, test_acc: 68.39, test_fscore: 68.96, time: 4.65 sec
epoch: 79, train_loss: 6.679699897766113, train_acc: 87.27, train_fscore: 87.15, valid_loss: 6.750400066375732, valid_acc: 73.04, valid_fscore: 73.63, test_loss: 7.6234002113342285, test_acc: 69.19, test_fscore: 69.76, time: 4.18 sec
epoch: 80, train_loss: 6.693299770355225, train_acc: 87.25, train_fscore: 87.18, valid_loss: 6.78000020980835, valid_acc: 73.34, valid_fscore: 73.99, test_loss: 7.669400215148926, test_acc: 69.01, test_fscore: 69.59, time: 4.55 sec
              precision    recall  f1-score   support

           0     0.4440    0.7708    0.5635     144.0
           1     0.8440    0.7510    0.7948     245.0
           2     0.7086    0.6901    0.6992     384.0
           3     0.6406    0.7235    0.6796     170.0
           4     0.8818    0.5987    0.7131     299.0
           5     0.6684    0.6772    0.6728     381.0

    accuracy                         0.6901    1623.0
   macro avg     0.6979    0.7019    0.6872    1623.0
weighted avg     0.7209    0.6901    0.6959    1623.0

[[111.   4.  14.   0.  14.   1.]
 [  2. 184.  24.   1.   0.  34.]
 [ 41.  17. 265.  10.   4.  47.]
 [  0.   0.   3. 123.   0.  44.]
 [ 95.   1.  22.   0. 179.   2.]
 [  1.  12.  46.  58.   6. 258.]]
epoch: 81, train_loss: 6.687099933624268, train_acc: 87.23, train_fscore: 87.14, valid_loss: 6.77370023727417, valid_acc: 73.19, valid_fscore: 73.78, test_loss: 7.674600124359131, test_acc: 68.95, test_fscore: 69.43, time: 4.65 sec
epoch: 82, train_loss: 6.668300151824951, train_acc: 87.33, train_fscore: 87.23, valid_loss: 6.7758002281188965, valid_acc: 73.34, valid_fscore: 73.96, test_loss: 7.653200149536133, test_acc: 69.32, test_fscore: 69.82, time: 4.62 sec
epoch: 83, train_loss: 6.6757001876831055, train_acc: 87.29, train_fscore: 87.22, valid_loss: 6.76170015335083, valid_acc: 73.64, valid_fscore: 74.07, test_loss: 7.646100044250488, test_acc: 69.62, test_fscore: 70.16, time: 3.82 sec
epoch: 84, train_loss: 6.637199878692627, train_acc: 87.95, train_fscore: 87.87, valid_loss: 6.736800193786621, valid_acc: 73.8, valid_fscore: 74.33, test_loss: 7.664000034332275, test_acc: 69.01, test_fscore: 69.54, time: 4.63 sec
epoch: 85, train_loss: 6.64139986038208, train_acc: 88.24, train_fscore: 88.17, valid_loss: 6.718100070953369, valid_acc: 73.8, valid_fscore: 74.25, test_loss: 7.639599800109863, test_acc: 70.24, test_fscore: 70.73, time: 4.58 sec
epoch: 86, train_loss: 6.610099792480469, train_acc: 88.13, train_fscore: 88.03, valid_loss: 6.726500034332275, valid_acc: 73.8, valid_fscore: 74.15, test_loss: 7.690899848937988, test_acc: 69.13, test_fscore: 69.7, time: 3.45 sec
epoch: 87, train_loss: 6.608399868011475, train_acc: 88.36, train_fscore: 88.28, valid_loss: 6.756800174713135, valid_acc: 73.49, valid_fscore: 73.72, test_loss: 7.654600143432617, test_acc: 69.81, test_fscore: 70.35, time: 4.55 sec
epoch: 88, train_loss: 6.595200061798096, train_acc: 88.38, train_fscore: 88.3, valid_loss: 6.783999919891357, valid_acc: 73.04, valid_fscore: 73.74, test_loss: 7.680099964141846, test_acc: 68.82, test_fscore: 69.33, time: 3.81 sec
epoch: 89, train_loss: 6.582600116729736, train_acc: 88.63, train_fscore: 88.53, valid_loss: 6.776299953460693, valid_acc: 73.04, valid_fscore: 73.57, test_loss: 7.699900150299072, test_acc: 68.82, test_fscore: 69.29, time: 3.19 sec
epoch: 90, train_loss: 6.577099800109863, train_acc: 88.69, train_fscore: 88.63, valid_loss: 6.819799900054932, valid_acc: 73.95, valid_fscore: 74.08, test_loss: 7.647600173950195, test_acc: 70.36, test_fscore: 70.85, time: 2.28 sec
              precision    recall  f1-score   support

           0     0.4773    0.7292    0.5769     144.0
           1     0.8491    0.7347    0.7877     245.0
           2     0.6980    0.7161    0.7069     384.0
           3     0.6722    0.7118    0.6914     170.0
           4     0.8646    0.6622    0.7500     299.0
           5     0.6778    0.6903    0.6840     381.0

    accuracy                         0.7036    1623.0
   macro avg     0.7065    0.7074    0.6995    1623.0
weighted avg     0.7245    0.7036    0.7085    1623.0

[[105.   4.  14.   0.  20.   1.]
 [  2. 180.  29.   2.   0.  32.]
 [ 36.  15. 275.   7.   6.  45.]
 [  0.   0.   4. 121.   0.  45.]
 [ 77.   1.  21.   0. 198.   2.]
 [  0.  12.  51.  50.   5. 263.]]
epoch: 91, train_loss: 6.55649995803833, train_acc: 88.59, train_fscore: 88.5, valid_loss: 6.861100196838379, valid_acc: 73.34, valid_fscore: 73.79, test_loss: 7.627999782562256, test_acc: 70.12, test_fscore: 70.64, time: 2.53 sec
epoch: 92, train_loss: 6.5482001304626465, train_acc: 88.87, train_fscore: 88.78, valid_loss: 6.847099781036377, valid_acc: 72.29, valid_fscore: 73.06, test_loss: 7.723700046539307, test_acc: 68.82, test_fscore: 69.35, time: 2.84 sec
epoch: 93, train_loss: 6.553100109100342, train_acc: 89.08, train_fscore: 89.01, valid_loss: 6.842199802398682, valid_acc: 73.49, valid_fscore: 73.66, test_loss: 7.702700138092041, test_acc: 69.69, test_fscore: 70.11, time: 1.96 sec
epoch: 94, train_loss: 6.54010009765625, train_acc: 89.23, train_fscore: 89.16, valid_loss: 6.849800109863281, valid_acc: 72.89, valid_fscore: 73.23, test_loss: 7.723700046539307, test_acc: 69.07, test_fscore: 69.61, time: 2.97 sec
epoch: 95, train_loss: 6.519800186157227, train_acc: 89.31, train_fscore: 89.26, valid_loss: 6.8719000816345215, valid_acc: 72.44, valid_fscore: 73.03, test_loss: 7.69920015335083, test_acc: 70.06, test_fscore: 70.62, time: 4.54 sec
epoch: 96, train_loss: 6.513299942016602, train_acc: 89.21, train_fscore: 89.14, valid_loss: 6.859399795532227, valid_acc: 73.34, valid_fscore: 73.55, test_loss: 7.6595001220703125, test_acc: 70.55, test_fscore: 71.01, time: 4.23 sec
epoch: 97, train_loss: 6.497499942779541, train_acc: 89.6, train_fscore: 89.53, valid_loss: 6.893099784851074, valid_acc: 73.34, valid_fscore: 73.72, test_loss: 7.735799789428711, test_acc: 69.75, test_fscore: 70.25, time: 4.31 sec
epoch: 98, train_loss: 6.494200229644775, train_acc: 89.41, train_fscore: 89.35, valid_loss: 6.9141998291015625, valid_acc: 72.29, valid_fscore: 72.97, test_loss: 7.7718000411987305, test_acc: 68.64, test_fscore: 69.19, time: 4.61 sec
epoch: 99, train_loss: 6.4704999923706055, train_acc: 89.12, train_fscore: 89.04, valid_loss: 6.9191999435424805, valid_acc: 73.19, valid_fscore: 73.44, test_loss: 7.701700210571289, test_acc: 70.86, test_fscore: 71.33, time: 4.59 sec
epoch: 100, train_loss: 6.480000019073486, train_acc: 89.95, train_fscore: 89.9, valid_loss: 6.897900104522705, valid_acc: 73.49, valid_fscore: 73.58, test_loss: 7.69920015335083, test_acc: 70.36, test_fscore: 70.79, time: 4.09 sec
              precision    recall  f1-score   support

           0     0.4885    0.7361    0.5873     144.0
           1     0.8402    0.7510    0.7931     245.0
           2     0.6960    0.7214    0.7084     384.0
           3     0.6495    0.7412    0.6923     170.0
           4     0.8739    0.6488    0.7447     299.0
           5     0.6836    0.6693    0.6764     381.0

    accuracy                         0.7036    1623.0
   macro avg     0.7053    0.7113    0.7004    1623.0
weighted avg     0.7243    0.7036    0.7079    1623.0

[[106.   4.  15.   0.  18.   1.]
 [  2. 184.  26.   2.   0.  31.]
 [ 33.  17. 277.   8.   5.  44.]
 [  0.   0.   4. 126.   0.  40.]
 [ 76.   1.  26.   0. 194.   2.]
 [  0.  13.  50.  58.   5. 255.]]
epoch: 101, train_loss: 6.4492998123168945, train_acc: 89.99, train_fscore: 89.93, valid_loss: 6.89900016784668, valid_acc: 73.64, valid_fscore: 74.12, test_loss: 7.733399868011475, test_acc: 69.81, test_fscore: 70.31, time: 3.99 sec
epoch: 102, train_loss: 6.455999851226807, train_acc: 90.15, train_fscore: 90.09, valid_loss: 6.942500114440918, valid_acc: 72.89, valid_fscore: 73.25, test_loss: 7.708099842071533, test_acc: 70.43, test_fscore: 70.93, time: 4.54 sec
epoch: 103, train_loss: 6.437099933624268, train_acc: 90.77, train_fscore: 90.71, valid_loss: 6.919899940490723, valid_acc: 72.44, valid_fscore: 72.6, test_loss: 7.73199987411499, test_acc: 70.12, test_fscore: 70.58, time: 4.41 sec
epoch: 104, train_loss: 6.409999847412109, train_acc: 90.58, train_fscore: 90.51, valid_loss: 6.877099990844727, valid_acc: 73.8, valid_fscore: 74.11, test_loss: 7.787899971008301, test_acc: 69.87, test_fscore: 70.32, time: 4.64 sec
epoch: 105, train_loss: 6.4166998863220215, train_acc: 89.56, train_fscore: 89.47, valid_loss: 6.930799961090088, valid_acc: 73.95, valid_fscore: 74.08, test_loss: 7.755799770355225, test_acc: 70.06, test_fscore: 70.51, time: 4.12 sec
epoch: 106, train_loss: 6.426700115203857, train_acc: 90.54, train_fscore: 90.49, valid_loss: 6.992599964141846, valid_acc: 73.8, valid_fscore: 73.95, test_loss: 7.743299961090088, test_acc: 70.55, test_fscore: 70.99, time: 3.15 sec
epoch: 107, train_loss: 6.400100231170654, train_acc: 90.75, train_fscore: 90.71, valid_loss: 6.9653000831604, valid_acc: 71.54, valid_fscore: 72.06, test_loss: 7.793799877166748, test_acc: 69.75, test_fscore: 70.21, time: 4.34 sec
epoch: 108, train_loss: 6.39300012588501, train_acc: 90.63, train_fscore: 90.57, valid_loss: 6.959099769592285, valid_acc: 73.04, valid_fscore: 73.44, test_loss: 7.792399883270264, test_acc: 69.75, test_fscore: 70.22, time: 3.6 sec
epoch: 109, train_loss: 6.389400005340576, train_acc: 90.71, train_fscore: 90.65, valid_loss: 6.996500015258789, valid_acc: 73.34, valid_fscore: 73.47, test_loss: 7.735099792480469, test_acc: 71.1, test_fscore: 71.51, time: 4.63 sec
epoch: 110, train_loss: 6.345399856567383, train_acc: 90.87, train_fscore: 90.81, valid_loss: 6.968999862670898, valid_acc: 73.04, valid_fscore: 73.18, test_loss: 7.75629997253418, test_acc: 70.49, test_fscore: 70.91, time: 3.46 sec
              precision    recall  f1-score   support

           0     0.5091    0.7778    0.6154     144.0
           1     0.8394    0.7469    0.7905     245.0
           2     0.7147    0.6979    0.7062     384.0
           3     0.6510    0.7353    0.6906     170.0
           4     0.8869    0.6555    0.7538     299.0
           5     0.6549    0.6824    0.6684     381.0

    accuracy                         0.7049    1623.0
   macro avg     0.7093    0.7160    0.7042    1623.0
weighted avg     0.7263    0.7049    0.7091    1623.0

[[112.   5.  11.   1.  14.   1.]
 [  2. 183.  24.   1.   0.  35.]
 [ 30.  18. 268.   6.   6.  56.]
 [  0.   0.   3. 125.   0.  42.]
 [ 76.   0.  24.   0. 196.   3.]
 [  0.  12.  45.  59.   5. 260.]]
epoch: 111, train_loss: 6.3618998527526855, train_acc: 90.83, train_fscore: 90.77, valid_loss: 6.974999904632568, valid_acc: 72.74, valid_fscore: 73.13, test_loss: 7.816999912261963, test_acc: 69.99, test_fscore: 70.47, time: 4.13 sec
epoch: 112, train_loss: 6.334000110626221, train_acc: 91.49, train_fscore: 91.44, valid_loss: 6.983799934387207, valid_acc: 72.29, valid_fscore: 72.52, test_loss: 7.789999961853027, test_acc: 69.69, test_fscore: 70.13, time: 4.57 sec
epoch: 113, train_loss: 6.331099987030029, train_acc: 91.43, train_fscore: 91.37, valid_loss: 6.980299949645996, valid_acc: 73.49, valid_fscore: 73.73, test_loss: 7.774899959564209, test_acc: 70.49, test_fscore: 71.0, time: 3.99 sec
epoch: 114, train_loss: 6.316800117492676, train_acc: 91.18, train_fscore: 91.11, valid_loss: 7.001500129699707, valid_acc: 74.1, valid_fscore: 74.14, test_loss: 7.821000099182129, test_acc: 70.61, test_fscore: 71.02, time: 4.54 sec
epoch: 115, train_loss: 6.303999900817871, train_acc: 92.09, train_fscore: 92.04, valid_loss: 7.036300182342529, valid_acc: 73.49, valid_fscore: 73.63, test_loss: 7.817599773406982, test_acc: 70.18, test_fscore: 70.54, time: 4.34 sec
epoch: 116, train_loss: 6.317699909210205, train_acc: 91.95, train_fscore: 91.89, valid_loss: 7.069200038909912, valid_acc: 71.54, valid_fscore: 72.2, test_loss: 7.848700046539307, test_acc: 69.87, test_fscore: 70.3, time: 3.03 sec
epoch: 117, train_loss: 6.302999973297119, train_acc: 91.99, train_fscore: 91.95, valid_loss: 7.006499767303467, valid_acc: 73.95, valid_fscore: 74.01, test_loss: 7.851399898529053, test_acc: 70.24, test_fscore: 70.65, time: 1.98 sec
epoch: 118, train_loss: 6.292600154876709, train_acc: 92.21, train_fscore: 92.15, valid_loss: 7.050899982452393, valid_acc: 73.64, valid_fscore: 73.66, test_loss: 7.892399787902832, test_acc: 70.67, test_fscore: 71.07, time: 1.95 sec
epoch: 119, train_loss: 6.298500061035156, train_acc: 92.01, train_fscore: 91.96, valid_loss: 7.089099884033203, valid_acc: 73.19, valid_fscore: 73.26, test_loss: 7.859000205993652, test_acc: 71.04, test_fscore: 71.39, time: 1.99 sec
epoch: 120, train_loss: 6.29040002822876, train_acc: 92.32, train_fscore: 92.28, valid_loss: 7.1020002365112305, valid_acc: 72.59, valid_fscore: 72.96, test_loss: 7.867800235748291, test_acc: 70.18, test_fscore: 70.58, time: 2.02 sec
              precision    recall  f1-score   support

           0     0.4874    0.8056    0.6073     144.0
           1     0.8565    0.7551    0.8026     245.0
           2     0.6690    0.7422    0.7037     384.0
           3     0.6923    0.6882    0.6903     170.0
           4     0.8950    0.5987    0.7174     299.0
           5     0.6872    0.6745    0.6808     381.0

    accuracy                         0.7018    1623.0
   macro avg     0.7146    0.7107    0.7004    1623.0
weighted avg     0.7295    0.7018    0.7058    1623.0

[[116.   3.  14.   0.  10.   1.]
 [  2. 185.  27.   1.   0.  30.]
 [ 31.  17. 285.   6.   6.  39.]
 [  0.   0.   7. 117.   0.  46.]
 [ 89.   0.  30.   0. 179.   1.]
 [  0.  11.  63.  45.   5. 257.]]
epoch: 121, train_loss: 6.258299827575684, train_acc: 92.42, train_fscore: 92.36, valid_loss: 7.123199939727783, valid_acc: 73.64, valid_fscore: 73.81, test_loss: 7.894100189208984, test_acc: 69.87, test_fscore: 70.31, time: 2.09 sec
epoch: 122, train_loss: 6.265600204467773, train_acc: 92.07, train_fscore: 92.01, valid_loss: 7.1855998039245605, valid_acc: 73.34, valid_fscore: 73.31, test_loss: 7.851900100708008, test_acc: 70.86, test_fscore: 71.25, time: 2.09 sec
epoch: 123, train_loss: 6.276000022888184, train_acc: 92.21, train_fscore: 92.17, valid_loss: 7.161499977111816, valid_acc: 74.25, valid_fscore: 74.28, test_loss: 7.86299991607666, test_acc: 70.61, test_fscore: 71.02, time: 2.03 sec
epoch: 124, train_loss: 6.243800163269043, train_acc: 92.27, train_fscore: 92.21, valid_loss: 7.164000034332275, valid_acc: 72.59, valid_fscore: 73.13, test_loss: 7.921000003814697, test_acc: 69.93, test_fscore: 70.3, time: 2.14 sec
epoch: 125, train_loss: 6.226099967956543, train_acc: 92.17, train_fscore: 92.1, valid_loss: 7.2052998542785645, valid_acc: 73.04, valid_fscore: 73.12, test_loss: 7.914299964904785, test_acc: 70.61, test_fscore: 70.93, time: 3.1 sec
epoch: 126, train_loss: 6.234600067138672, train_acc: 93.22, train_fscore: 93.19, valid_loss: 7.207399845123291, valid_acc: 73.8, valid_fscore: 73.82, test_loss: 7.9045000076293945, test_acc: 70.86, test_fscore: 71.26, time: 2.68 sec
epoch: 127, train_loss: 6.219799995422363, train_acc: 92.77, train_fscore: 92.72, valid_loss: 7.11929988861084, valid_acc: 74.4, valid_fscore: 74.47, test_loss: 7.903200149536133, test_acc: 70.55, test_fscore: 70.97, time: 1.99 sec
epoch: 128, train_loss: 6.220200061798096, train_acc: 92.52, train_fscore: 92.47, valid_loss: 7.14870023727417, valid_acc: 72.14, valid_fscore: 72.48, test_loss: 7.929200172424316, test_acc: 69.99, test_fscore: 70.36, time: 2.26 sec
epoch: 129, train_loss: 6.217599868774414, train_acc: 92.83, train_fscore: 92.79, valid_loss: 7.193600177764893, valid_acc: 72.14, valid_fscore: 72.4, test_loss: 7.938899993896484, test_acc: 69.69, test_fscore: 70.03, time: 3.74 sec
epoch: 130, train_loss: 6.196100234985352, train_acc: 93.43, train_fscore: 93.39, valid_loss: 7.152299880981445, valid_acc: 73.19, valid_fscore: 73.2, test_loss: 7.868299961090088, test_acc: 71.1, test_fscore: 71.47, time: 4.15 sec
              precision    recall  f1-score   support

           0     0.5142    0.7569    0.6124     144.0
           1     0.8479    0.7510    0.7965     245.0
           2     0.6953    0.7370    0.7155     384.0
           3     0.6702    0.7412    0.7039     170.0
           4     0.8750    0.6555    0.7495     299.0
           5     0.6827    0.6719    0.6772     381.0

    accuracy                         0.7110    1623.0
   macro avg     0.7142    0.7189    0.7092    1623.0
weighted avg     0.7298    0.7110    0.7147    1623.0

[[109.   4.  13.   0.  17.   1.]
 [  2. 184.  29.   1.   0.  29.]
 [ 28.  16. 283.   5.   6.  46.]
 [  0.   0.   3. 126.   0.  41.]
 [ 73.   1.  27.   0. 196.   2.]
 [  0.  12.  52.  56.   5. 256.]]
epoch: 131, train_loss: 6.1722002029418945, train_acc: 93.45, train_fscore: 93.41, valid_loss: 7.138899803161621, valid_acc: 73.49, valid_fscore: 73.65, test_loss: 7.938199996948242, test_acc: 70.18, test_fscore: 70.61, time: 4.79 sec
epoch: 132, train_loss: 6.179599761962891, train_acc: 93.39, train_fscore: 93.36, valid_loss: 7.1631999015808105, valid_acc: 73.34, valid_fscore: 73.55, test_loss: 8.039600372314453, test_acc: 69.56, test_fscore: 69.94, time: 4.59 sec
epoch: 133, train_loss: 6.164299964904785, train_acc: 92.79, train_fscore: 92.74, valid_loss: 7.222799777984619, valid_acc: 73.04, valid_fscore: 73.09, test_loss: 7.946599960327148, test_acc: 70.3, test_fscore: 70.66, time: 4.27 sec
epoch: 134, train_loss: 6.186500072479248, train_acc: 93.22, train_fscore: 93.17, valid_loss: 7.254700183868408, valid_acc: 73.04, valid_fscore: 73.3, test_loss: 7.921500205993652, test_acc: 70.86, test_fscore: 71.22, time: 4.66 sec
epoch: 135, train_loss: 6.162199974060059, train_acc: 92.79, train_fscore: 92.74, valid_loss: 7.271500110626221, valid_acc: 72.89, valid_fscore: 73.1, test_loss: 7.9756999015808105, test_acc: 70.98, test_fscore: 71.35, time: 4.55 sec
epoch: 136, train_loss: 6.158999919891357, train_acc: 93.12, train_fscore: 93.09, valid_loss: 7.2530999183654785, valid_acc: 74.25, valid_fscore: 74.29, test_loss: 8.009300231933594, test_acc: 70.55, test_fscore: 70.89, time: 4.56 sec
epoch: 137, train_loss: 6.14769983291626, train_acc: 93.24, train_fscore: 93.2, valid_loss: 7.212299823760986, valid_acc: 74.25, valid_fscore: 74.27, test_loss: 7.941800117492676, test_acc: 70.98, test_fscore: 71.34, time: 4.68 sec
epoch: 138, train_loss: 6.137700080871582, train_acc: 93.2, train_fscore: 93.14, valid_loss: 7.275899887084961, valid_acc: 72.74, valid_fscore: 73.2, test_loss: 7.998000144958496, test_acc: 70.55, test_fscore: 70.9, time: 4.72 sec
epoch: 139, train_loss: 6.139699935913086, train_acc: 93.72, train_fscore: 93.69, valid_loss: 7.331699848175049, valid_acc: 72.89, valid_fscore: 73.08, test_loss: 8.026300430297852, test_acc: 70.86, test_fscore: 71.17, time: 4.56 sec
epoch: 140, train_loss: 6.128300189971924, train_acc: 94.15, train_fscore: 94.12, valid_loss: 7.264100074768066, valid_acc: 72.59, valid_fscore: 72.58, test_loss: 8.032699584960938, test_acc: 70.61, test_fscore: 70.96, time: 4.59 sec
              precision    recall  f1-score   support

           0     0.5000    0.7292    0.5932     144.0
           1     0.8416    0.7592    0.7983     245.0
           2     0.6886    0.7370    0.7119     384.0
           3     0.6597    0.7412    0.6981     170.0
           4     0.8670    0.6321    0.7311     299.0
           5     0.6909    0.6745    0.6826     381.0

    accuracy                         0.7061    1623.0
   macro avg     0.7080    0.7122    0.7025    1623.0
weighted avg     0.7253    0.7061    0.7096    1623.0

[[105.   4.  16.   0.  18.   1.]
 [  2. 186.  27.   3.   0.  27.]
 [ 29.  18. 283.   5.   6.  43.]
 [  0.   0.   3. 126.   0.  41.]
 [ 74.   1.  32.   0. 189.   3.]
 [  0.  12.  50.  57.   5. 257.]]
epoch: 141, train_loss: 6.131400108337402, train_acc: 93.47, train_fscore: 93.42, valid_loss: 7.2600998878479, valid_acc: 73.19, valid_fscore: 73.34, test_loss: 8.060400009155273, test_acc: 69.93, test_fscore: 70.34, time: 4.61 sec
epoch: 142, train_loss: 6.144899845123291, train_acc: 93.78, train_fscore: 93.75, valid_loss: 7.31879997253418, valid_acc: 73.04, valid_fscore: 73.1, test_loss: 7.943699836730957, test_acc: 70.79, test_fscore: 71.14, time: 3.07 sec
epoch: 143, train_loss: 6.0991997718811035, train_acc: 93.72, train_fscore: 93.69, valid_loss: 7.315700054168701, valid_acc: 73.19, valid_fscore: 73.27, test_loss: 7.965000152587891, test_acc: 70.98, test_fscore: 71.33, time: 2.04 sec
epoch: 144, train_loss: 6.119200229644775, train_acc: 93.68, train_fscore: 93.65, valid_loss: 7.314700126647949, valid_acc: 73.34, valid_fscore: 73.57, test_loss: 7.985199928283691, test_acc: 70.67, test_fscore: 71.04, time: 1.94 sec
epoch: 145, train_loss: 6.075200080871582, train_acc: 94.09, train_fscore: 94.06, valid_loss: 7.30810022354126, valid_acc: 73.64, valid_fscore: 73.85, test_loss: 7.996699810028076, test_acc: 70.86, test_fscore: 71.22, time: 1.9 sec
epoch: 146, train_loss: 6.076399803161621, train_acc: 94.21, train_fscore: 94.18, valid_loss: 7.287799835205078, valid_acc: 73.04, valid_fscore: 73.2, test_loss: 7.980299949645996, test_acc: 71.35, test_fscore: 71.66, time: 1.95 sec
epoch: 147, train_loss: 6.050099849700928, train_acc: 94.07, train_fscore: 94.04, valid_loss: 7.320499897003174, valid_acc: 73.19, valid_fscore: 73.2, test_loss: 8.030599594116211, test_acc: 71.6, test_fscore: 71.88, time: 1.92 sec
epoch: 148, train_loss: 6.064700126647949, train_acc: 94.15, train_fscore: 94.11, valid_loss: 7.313399791717529, valid_acc: 72.74, valid_fscore: 72.9, test_loss: 8.009200096130371, test_acc: 71.53, test_fscore: 71.86, time: 1.95 sec
epoch: 149, train_loss: 6.083099842071533, train_acc: 93.96, train_fscore: 93.92, valid_loss: 7.317999839782715, valid_acc: 72.89, valid_fscore: 73.05, test_loss: 8.033300399780273, test_acc: 71.23, test_fscore: 71.55, time: 1.97 sec
epoch: 150, train_loss: 6.059299945831299, train_acc: 94.42, train_fscore: 94.39, valid_loss: 7.309700012207031, valid_acc: 72.74, valid_fscore: 72.88, test_loss: 8.090700149536133, test_acc: 70.55, test_fscore: 70.84, time: 2.03 sec
              precision    recall  f1-score   support

           0     0.5146    0.7361    0.6057     144.0
           1     0.8416    0.7592    0.7983     245.0
           2     0.6682    0.7552    0.7090     384.0
           3     0.6798    0.7118    0.6954     170.0
           4     0.8685    0.6187    0.7227     299.0
           5     0.6927    0.6745    0.6835     381.0

    accuracy                         0.7055    1623.0
   macro avg     0.7109    0.7093    0.7024    1623.0
weighted avg     0.7246    0.7055    0.7084    1623.0

[[106.   4.  16.   0.  17.   1.]
 [  2. 186.  28.   3.   0.  26.]
 [ 25.  17. 290.   5.   6.  41.]
 [  0.   0.   5. 121.   0.  44.]
 [ 73.   2.  37.   0. 185.   2.]
 [  0.  12.  58.  49.   5. 257.]]
Best validation F-Score: 70.84
Test performance..
F-Score: 70.84
Accuracy: 70.55
Loss: 8.090700149536133
--- 9 ---
loss_mask: [True, True, True, True]
Namespace(no_cuda=False, lr=0.0001, l2=1e-05, dropout=0.5, batch_size=64, hidden_dim=1024, n_head=8, epochs=150, temp=2, tensorboard=False, class_weight=True, Dataset='IEMOCAP', loss_mask='1111')
Running on GPU
temp 2
total parameters: 97535000
training parameters: 97535000
epoch: 1, train_loss: 12.327799797058105, train_acc: 19.26, train_fscore: 19.71, valid_loss: 10.201000213623047, valid_acc: 33.58, valid_fscore: 27.53, test_loss: 11.241100311279297, test_acc: 28.71, test_fscore: 25.61, time: 3.48 sec
epoch: 2, train_loss: 11.55840015411377, train_acc: 36.71, train_fscore: 35.02, valid_loss: 9.692700386047363, valid_acc: 49.1, valid_fscore: 49.96, test_loss: 10.636099815368652, test_acc: 46.03, test_fscore: 44.73, time: 2.0 sec
epoch: 3, train_loss: 11.065500259399414, train_acc: 47.36, train_fscore: 45.15, valid_loss: 9.21679973602295, valid_acc: 42.32, valid_fscore: 41.41, test_loss: 10.229999542236328, test_acc: 43.5, test_fscore: 40.06, time: 2.02 sec
epoch: 4, train_loss: 10.693599700927734, train_acc: 50.1, train_fscore: 47.78, valid_loss: 8.948399543762207, valid_acc: 55.57, valid_fscore: 56.32, test_loss: 10.082599639892578, test_acc: 48.55, test_fscore: 48.19, time: 2.15 sec
epoch: 5, train_loss: 10.363800048828125, train_acc: 56.0, train_fscore: 54.16, valid_loss: 8.851099967956543, valid_acc: 60.24, valid_fscore: 61.47, test_loss: 10.034700393676758, test_acc: 53.23, test_fscore: 53.37, time: 1.98 sec
epoch: 6, train_loss: 10.096400260925293, train_acc: 60.36, train_fscore: 59.59, valid_loss: 8.562199592590332, valid_acc: 62.65, valid_fscore: 65.01, test_loss: 9.770600318908691, test_acc: 57.18, test_fscore: 57.9, time: 1.97 sec
epoch: 7, train_loss: 9.805899620056152, train_acc: 64.4, train_fscore: 64.41, valid_loss: 8.146400451660156, valid_acc: 65.21, valid_fscore: 66.77, test_loss: 9.390700340270996, test_acc: 59.03, test_fscore: 59.76, time: 1.97 sec
epoch: 8, train_loss: 9.490799903869629, train_acc: 65.84, train_fscore: 65.74, valid_loss: 7.703999996185303, valid_acc: 65.51, valid_fscore: 66.34, test_loss: 9.00160026550293, test_acc: 59.77, test_fscore: 60.45, time: 1.99 sec
epoch: 9, train_loss: 9.172800064086914, train_acc: 65.27, train_fscore: 64.8, valid_loss: 7.490300178527832, valid_acc: 63.25, valid_fscore: 65.58, test_loss: 8.793499946594238, test_acc: 59.27, test_fscore: 60.15, time: 2.07 sec
epoch: 10, train_loss: 8.964599609375, train_acc: 66.4, train_fscore: 66.0, valid_loss: 7.405099868774414, valid_acc: 67.77, valid_fscore: 68.4, test_loss: 8.709199905395508, test_acc: 62.29, test_fscore: 63.04, time: 2.02 sec
              precision    recall  f1-score   support

           0     0.3375    0.5625    0.4219     144.0
           1     0.7989    0.6163    0.6959     245.0
           2     0.6180    0.5182    0.5637     384.0
           3     0.5799    0.7471    0.6530     170.0
           4     0.8298    0.6522    0.7303     299.0
           5     0.6172    0.6772    0.6458     381.0

    accuracy                         0.6229    1623.0
   macro avg     0.6302    0.6289    0.6184    1623.0
weighted avg     0.6553    0.6229    0.6304    1623.0

[[ 81.   5.  14.   4.  37.   3.]
 [ 15. 151.  41.   4.   0.  34.]
 [ 55.  23. 199.  23.   1.  83.]
 [  0.   0.   6. 127.   0.  37.]
 [ 81.   0.  18.   2. 195.   3.]
 [  8.  10.  44.  59.   2. 258.]]
epoch: 11, train_loss: 8.8641996383667, train_acc: 68.44, train_fscore: 68.03, valid_loss: 7.285200119018555, valid_acc: 68.67, valid_fscore: 69.53, test_loss: 8.589400291442871, test_acc: 63.28, test_fscore: 64.27, time: 1.96 sec
epoch: 12, train_loss: 8.759099960327148, train_acc: 68.4, train_fscore: 68.25, valid_loss: 7.220300197601318, valid_acc: 65.81, valid_fscore: 68.22, test_loss: 8.525099754333496, test_acc: 60.75, test_fscore: 61.95, time: 1.93 sec
epoch: 13, train_loss: 8.670999526977539, train_acc: 68.54, train_fscore: 68.45, valid_loss: 7.098199844360352, valid_acc: 67.47, valid_fscore: 68.41, test_loss: 8.393600463867188, test_acc: 63.96, test_fscore: 64.86, time: 1.91 sec
epoch: 14, train_loss: 8.575300216674805, train_acc: 69.9, train_fscore: 69.59, valid_loss: 7.003699779510498, valid_acc: 66.72, valid_fscore: 68.56, test_loss: 8.253999710083008, test_acc: 62.42, test_fscore: 63.44, time: 2.16 sec
epoch: 15, train_loss: 8.513199806213379, train_acc: 69.72, train_fscore: 69.46, valid_loss: 6.853600025177002, valid_acc: 69.73, valid_fscore: 71.26, test_loss: 8.139900207519531, test_acc: 64.26, test_fscore: 65.03, time: 2.06 sec
epoch: 16, train_loss: 8.437199592590332, train_acc: 69.41, train_fscore: 68.81, valid_loss: 6.779699802398682, valid_acc: 70.33, valid_fscore: 71.48, test_loss: 8.104999542236328, test_acc: 64.94, test_fscore: 65.45, time: 1.98 sec
epoch: 17, train_loss: 8.344499588012695, train_acc: 71.03, train_fscore: 70.5, valid_loss: 6.8144001960754395, valid_acc: 66.87, valid_fscore: 69.13, test_loss: 8.144700050354004, test_acc: 62.42, test_fscore: 63.39, time: 1.97 sec
epoch: 18, train_loss: 8.30519962310791, train_acc: 70.91, train_fscore: 70.7, valid_loss: 6.813700199127197, valid_acc: 69.88, valid_fscore: 71.26, test_loss: 8.17650032043457, test_acc: 64.14, test_fscore: 64.94, time: 1.95 sec
epoch: 19, train_loss: 8.220800399780273, train_acc: 71.82, train_fscore: 71.5, valid_loss: 6.714200019836426, valid_acc: 70.03, valid_fscore: 70.91, test_loss: 8.117400169372559, test_acc: 65.25, test_fscore: 65.84, time: 1.95 sec
epoch: 20, train_loss: 8.148799896240234, train_acc: 72.74, train_fscore: 72.41, valid_loss: 6.666999816894531, valid_acc: 69.43, valid_fscore: 70.96, test_loss: 8.047200202941895, test_acc: 64.82, test_fscore: 65.58, time: 2.04 sec
              precision    recall  f1-score   support

           0     0.3810    0.6667    0.4848     144.0
           1     0.7818    0.7020    0.7398     245.0
           2     0.6628    0.5885    0.6234     384.0
           3     0.5972    0.7412    0.6614     170.0
           4     0.8597    0.6355    0.7308     299.0
           5     0.6402    0.6352    0.6377     381.0

    accuracy                         0.6482    1623.0
   macro avg     0.6538    0.6615    0.6463    1623.0
weighted avg     0.6799    0.6482    0.6558    1623.0

[[ 96.   7.  12.   3.  23.   3.]
 [  5. 172.  34.   1.   0.  33.]
 [ 53.  24. 226.  20.   3.  58.]
 [  0.   0.   4. 126.   0.  40.]
 [ 94.   0.  13.   0. 190.   2.]
 [  4.  17.  52.  61.   5. 242.]]
epoch: 21, train_loss: 8.119600296020508, train_acc: 72.83, train_fscore: 72.58, valid_loss: 6.6554999351501465, valid_acc: 70.03, valid_fscore: 71.35, test_loss: 8.010700225830078, test_acc: 65.19, test_fscore: 65.91, time: 1.99 sec
epoch: 22, train_loss: 8.071200370788574, train_acc: 73.94, train_fscore: 73.72, valid_loss: 6.619200229644775, valid_acc: 71.54, valid_fscore: 72.11, test_loss: 7.9664998054504395, test_acc: 66.79, test_fscore: 67.18, time: 2.17 sec
epoch: 23, train_loss: 7.99399995803833, train_acc: 73.94, train_fscore: 73.63, valid_loss: 6.652100086212158, valid_acc: 68.98, valid_fscore: 70.58, test_loss: 7.979100227355957, test_acc: 65.74, test_fscore: 66.52, time: 1.98 sec
epoch: 24, train_loss: 7.946400165557861, train_acc: 73.82, train_fscore: 73.56, valid_loss: 6.644700050354004, valid_acc: 68.67, valid_fscore: 70.25, test_loss: 7.980599880218506, test_acc: 65.19, test_fscore: 66.0, time: 1.99 sec
epoch: 25, train_loss: 7.907899856567383, train_acc: 75.11, train_fscore: 74.95, valid_loss: 6.601099967956543, valid_acc: 72.29, valid_fscore: 73.12, test_loss: 7.962399959564209, test_acc: 66.54, test_fscore: 67.13, time: 1.98 sec
epoch: 26, train_loss: 7.8445000648498535, train_acc: 74.93, train_fscore: 74.68, valid_loss: 6.578000068664551, valid_acc: 71.23, valid_fscore: 72.13, test_loss: 7.878499984741211, test_acc: 67.22, test_fscore: 67.81, time: 1.98 sec
epoch: 27, train_loss: 7.8206000328063965, train_acc: 75.92, train_fscore: 75.69, valid_loss: 6.5366997718811035, valid_acc: 70.18, valid_fscore: 71.17, test_loss: 7.782199859619141, test_acc: 67.34, test_fscore: 67.96, time: 1.92 sec
epoch: 28, train_loss: 7.779399871826172, train_acc: 75.88, train_fscore: 75.67, valid_loss: 6.465700149536133, valid_acc: 72.44, valid_fscore: 73.42, test_loss: 7.803400039672852, test_acc: 66.67, test_fscore: 67.22, time: 1.98 sec
epoch: 29, train_loss: 7.717100143432617, train_acc: 76.12, train_fscore: 75.9, valid_loss: 6.452400207519531, valid_acc: 73.19, valid_fscore: 73.97, test_loss: 7.834199905395508, test_acc: 66.54, test_fscore: 67.1, time: 1.99 sec
epoch: 30, train_loss: 7.679500102996826, train_acc: 76.35, train_fscore: 76.16, valid_loss: 6.508399963378906, valid_acc: 70.33, valid_fscore: 71.69, test_loss: 7.810999870300293, test_acc: 66.73, test_fscore: 67.47, time: 1.96 sec
              precision    recall  f1-score   support

           0     0.4016    0.6944    0.5089     144.0
           1     0.8104    0.6980    0.7500     245.0
           2     0.6759    0.6354    0.6550     384.0
           3     0.6176    0.7412    0.6738     170.0
           4     0.8738    0.6254    0.7290     299.0
           5     0.6641    0.6693    0.6667     381.0

    accuracy                         0.6673    1623.0
   macro avg     0.6739    0.6773    0.6639    1623.0
weighted avg     0.6995    0.6673    0.6747    1623.0

[[100.   6.  15.   3.  18.   2.]
 [  4. 171.  35.   1.   0.  34.]
 [ 45.  21. 244.  19.   4.  51.]
 [  0.   0.   3. 126.   0.  41.]
 [ 98.   0.  13.   0. 187.   1.]
 [  2.  13.  51.  55.   5. 255.]]
epoch: 31, train_loss: 7.668399810791016, train_acc: 75.94, train_fscore: 75.76, valid_loss: 6.470099925994873, valid_acc: 70.18, valid_fscore: 71.6, test_loss: 7.749300003051758, test_acc: 66.11, test_fscore: 66.79, time: 1.96 sec
epoch: 32, train_loss: 7.604400157928467, train_acc: 77.19, train_fscore: 77.01, valid_loss: 6.440100193023682, valid_acc: 73.04, valid_fscore: 74.08, test_loss: 7.718800067901611, test_acc: 67.47, test_fscore: 68.09, time: 1.97 sec
epoch: 33, train_loss: 7.57480001449585, train_acc: 77.21, train_fscore: 77.04, valid_loss: 6.450500011444092, valid_acc: 72.44, valid_fscore: 73.57, test_loss: 7.700900077819824, test_acc: 66.42, test_fscore: 67.07, time: 1.94 sec
epoch: 34, train_loss: 7.565999984741211, train_acc: 77.26, train_fscore: 77.07, valid_loss: 6.420599937438965, valid_acc: 72.14, valid_fscore: 72.9, test_loss: 7.6859002113342285, test_acc: 67.1, test_fscore: 67.66, time: 2.04 sec
epoch: 35, train_loss: 7.505199909210205, train_acc: 78.2, train_fscore: 78.0, valid_loss: 6.417900085449219, valid_acc: 71.23, valid_fscore: 72.27, test_loss: 7.704999923706055, test_acc: 66.97, test_fscore: 67.64, time: 2.0 sec
epoch: 36, train_loss: 7.478099822998047, train_acc: 78.18, train_fscore: 78.01, valid_loss: 6.416900157928467, valid_acc: 71.39, valid_fscore: 72.53, test_loss: 7.715799808502197, test_acc: 66.73, test_fscore: 67.36, time: 2.0 sec
epoch: 37, train_loss: 7.473499774932861, train_acc: 78.37, train_fscore: 78.21, valid_loss: 6.427199840545654, valid_acc: 72.14, valid_fscore: 73.3, test_loss: 7.659200191497803, test_acc: 67.53, test_fscore: 68.17, time: 1.93 sec
epoch: 38, train_loss: 7.410399913787842, train_acc: 78.64, train_fscore: 78.49, valid_loss: 6.414299964904785, valid_acc: 71.84, valid_fscore: 72.52, test_loss: 7.5817999839782715, test_acc: 67.84, test_fscore: 68.37, time: 1.99 sec
epoch: 39, train_loss: 7.396500110626221, train_acc: 79.28, train_fscore: 79.11, valid_loss: 6.405799865722656, valid_acc: 72.74, valid_fscore: 73.89, test_loss: 7.605800151824951, test_acc: 67.1, test_fscore: 67.75, time: 1.98 sec
epoch: 40, train_loss: 7.361199855804443, train_acc: 79.63, train_fscore: 79.54, valid_loss: 6.401500225067139, valid_acc: 72.74, valid_fscore: 73.86, test_loss: 7.631700038909912, test_acc: 66.97, test_fscore: 67.63, time: 2.01 sec
              precision    recall  f1-score   support

           0     0.4150    0.7292    0.5290     144.0
           1     0.8018    0.7429    0.7712     245.0
           2     0.6941    0.6380    0.6649     384.0
           3     0.6077    0.7471    0.6702     170.0
           4     0.8714    0.6120    0.7191     299.0
           5     0.6604    0.6430    0.6516     381.0

    accuracy                         0.6697    1623.0
   macro avg     0.6750    0.6854    0.6676    1623.0
weighted avg     0.7013    0.6697    0.6763    1623.0

[[105.   5.  15.   0.  17.   2.]
 [  3. 182.  26.   2.   0.  32.]
 [ 44.  25. 245.  15.   4.  51.]
 [  0.   0.   3. 127.   0.  40.]
 [100.   1.  14.   0. 183.   1.]
 [  1.  14.  50.  65.   6. 245.]]
epoch: 41, train_loss: 7.3454999923706055, train_acc: 79.62, train_fscore: 79.47, valid_loss: 6.395199775695801, valid_acc: 72.89, valid_fscore: 73.71, test_loss: 7.617199897766113, test_acc: 66.97, test_fscore: 67.6, time: 2.03 sec
epoch: 42, train_loss: 7.332900047302246, train_acc: 80.2, train_fscore: 80.03, valid_loss: 6.399199962615967, valid_acc: 72.59, valid_fscore: 73.78, test_loss: 7.621099948883057, test_acc: 66.97, test_fscore: 67.64, time: 1.97 sec
epoch: 43, train_loss: 7.310200214385986, train_acc: 80.37, train_fscore: 80.3, valid_loss: 6.411300182342529, valid_acc: 71.99, valid_fscore: 73.16, test_loss: 7.606500148773193, test_acc: 67.04, test_fscore: 67.68, time: 2.01 sec
epoch: 44, train_loss: 7.288899898529053, train_acc: 80.74, train_fscore: 80.61, valid_loss: 6.408199787139893, valid_acc: 72.59, valid_fscore: 73.71, test_loss: 7.6321001052856445, test_acc: 67.53, test_fscore: 68.21, time: 2.0 sec
epoch: 45, train_loss: 7.279600143432617, train_acc: 80.98, train_fscore: 80.91, valid_loss: 6.419000148773193, valid_acc: 72.44, valid_fscore: 73.6, test_loss: 7.612599849700928, test_acc: 67.04, test_fscore: 67.73, time: 1.98 sec
epoch: 46, train_loss: 7.221399784088135, train_acc: 80.88, train_fscore: 80.78, valid_loss: 6.418399810791016, valid_acc: 71.54, valid_fscore: 72.61, test_loss: 7.581200122833252, test_acc: 67.22, test_fscore: 67.79, time: 2.04 sec
epoch: 47, train_loss: 7.238699913024902, train_acc: 80.68, train_fscore: 80.53, valid_loss: 6.418300151824951, valid_acc: 72.29, valid_fscore: 73.29, test_loss: 7.578000068664551, test_acc: 68.15, test_fscore: 68.81, time: 1.97 sec
epoch: 48, train_loss: 7.197500228881836, train_acc: 82.24, train_fscore: 82.17, valid_loss: 6.411799907684326, valid_acc: 73.95, valid_fscore: 74.81, test_loss: 7.607699871063232, test_acc: 67.84, test_fscore: 68.5, time: 2.01 sec
epoch: 49, train_loss: 7.189499855041504, train_acc: 81.15, train_fscore: 81.04, valid_loss: 6.3730998039245605, valid_acc: 74.25, valid_fscore: 74.83, test_loss: 7.5945000648498535, test_acc: 67.34, test_fscore: 67.91, time: 1.95 sec
epoch: 50, train_loss: 7.14769983291626, train_acc: 82.01, train_fscore: 81.89, valid_loss: 6.411300182342529, valid_acc: 72.14, valid_fscore: 73.37, test_loss: 7.603899955749512, test_acc: 67.34, test_fscore: 67.98, time: 2.05 sec
              precision    recall  f1-score   support

           0     0.4211    0.8333    0.5594     144.0
           1     0.8130    0.7633    0.7874     245.0
           2     0.7301    0.6198    0.6704     384.0
           3     0.6269    0.7118    0.6667     170.0
           4     0.9037    0.5652    0.6955     299.0
           5     0.6418    0.6772    0.6590     381.0

    accuracy                         0.6734    1623.0
   macro avg     0.6894    0.6951    0.6731    1623.0
weighted avg     0.7156    0.6734    0.6798    1623.0

[[120.   4.   9.   0.   8.   3.]
 [  3. 187.  18.   2.   0.  35.]
 [ 45.  24. 238.  13.   4.  60.]
 [  0.   0.   5. 121.   0.  44.]
 [115.   1.  12.   0. 169.   2.]
 [  2.  14.  44.  57.   6. 258.]]
epoch: 51, train_loss: 7.130199909210205, train_acc: 82.12, train_fscore: 82.02, valid_loss: 6.417600154876709, valid_acc: 73.64, valid_fscore: 74.59, test_loss: 7.583700180053711, test_acc: 68.33, test_fscore: 68.94, time: 1.95 sec
epoch: 52, train_loss: 7.110300064086914, train_acc: 82.88, train_fscore: 82.75, valid_loss: 6.402299880981445, valid_acc: 74.7, valid_fscore: 75.35, test_loss: 7.570899963378906, test_acc: 68.52, test_fscore: 69.1, time: 1.94 sec
epoch: 53, train_loss: 7.092100143432617, train_acc: 82.78, train_fscore: 82.67, valid_loss: 6.409999847412109, valid_acc: 73.8, valid_fscore: 74.74, test_loss: 7.62060022354126, test_acc: 67.41, test_fscore: 68.02, time: 2.0 sec
epoch: 54, train_loss: 7.062300205230713, train_acc: 82.82, train_fscore: 82.7, valid_loss: 6.405399799346924, valid_acc: 73.34, valid_fscore: 74.14, test_loss: 7.57420015335083, test_acc: 67.96, test_fscore: 68.58, time: 1.94 sec
epoch: 55, train_loss: 7.063000202178955, train_acc: 82.74, train_fscore: 82.58, valid_loss: 6.432000160217285, valid_acc: 74.85, valid_fscore: 75.34, test_loss: 7.520400047302246, test_acc: 69.38, test_fscore: 69.91, time: 1.92 sec
epoch: 56, train_loss: 7.05810022354126, train_acc: 83.29, train_fscore: 83.19, valid_loss: 6.440499782562256, valid_acc: 74.55, valid_fscore: 75.44, test_loss: 7.629300117492676, test_acc: 66.91, test_fscore: 67.45, time: 1.94 sec
epoch: 57, train_loss: 7.020699977874756, train_acc: 83.54, train_fscore: 83.44, valid_loss: 6.40880012512207, valid_acc: 74.4, valid_fscore: 75.11, test_loss: 7.607399940490723, test_acc: 67.71, test_fscore: 68.25, time: 1.99 sec
epoch: 58, train_loss: 6.984300136566162, train_acc: 83.75, train_fscore: 83.67, valid_loss: 6.404399871826172, valid_acc: 74.25, valid_fscore: 74.85, test_loss: 7.55620002746582, test_acc: 68.39, test_fscore: 68.96, time: 1.96 sec
epoch: 59, train_loss: 6.980000019073486, train_acc: 83.89, train_fscore: 83.79, valid_loss: 6.435500144958496, valid_acc: 73.95, valid_fscore: 74.64, test_loss: 7.559999942779541, test_acc: 68.45, test_fscore: 69.01, time: 1.96 sec
epoch: 60, train_loss: 6.966800212860107, train_acc: 83.95, train_fscore: 83.82, valid_loss: 6.467199802398682, valid_acc: 74.55, valid_fscore: 75.38, test_loss: 7.630099773406982, test_acc: 66.97, test_fscore: 67.51, time: 1.96 sec
              precision    recall  f1-score   support

           0     0.4254    0.7917    0.5534     144.0
           1     0.8304    0.7592    0.7932     245.0
           2     0.6960    0.6380    0.6658     384.0
           3     0.6296    0.7000    0.6630     170.0
           4     0.8895    0.5385    0.6708     299.0
           5     0.6406    0.6877    0.6633     381.0

    accuracy                         0.6697    1623.0
   macro avg     0.6852    0.6858    0.6682    1623.0
weighted avg     0.7080    0.6697    0.6751    1623.0

[[114.   5.  13.   0.  11.   1.]
 [  2. 186.  21.   1.   0.  35.]
 [ 40.  20. 245.  13.   4.  62.]
 [  0.   0.   3. 119.   0.  48.]
 [110.   1.  26.   0. 161.   1.]
 [  2.  12.  44.  56.   5. 262.]]
epoch: 61, train_loss: 6.942399978637695, train_acc: 84.67, train_fscore: 84.6, valid_loss: 6.441199779510498, valid_acc: 74.7, valid_fscore: 75.32, test_loss: 7.568399906158447, test_acc: 68.52, test_fscore: 69.09, time: 1.93 sec
epoch: 62, train_loss: 6.925300121307373, train_acc: 84.16, train_fscore: 84.03, valid_loss: 6.433700084686279, valid_acc: 73.64, valid_fscore: 74.32, test_loss: 7.558599948883057, test_acc: 68.15, test_fscore: 68.68, time: 1.94 sec
epoch: 63, train_loss: 6.906199932098389, train_acc: 84.75, train_fscore: 84.64, valid_loss: 6.431700229644775, valid_acc: 74.55, valid_fscore: 75.22, test_loss: 7.583000183105469, test_acc: 68.15, test_fscore: 68.71, time: 1.99 sec
epoch: 64, train_loss: 6.894400119781494, train_acc: 84.98, train_fscore: 84.87, valid_loss: 6.473800182342529, valid_acc: 74.1, valid_fscore: 74.82, test_loss: 7.587200164794922, test_acc: 68.33, test_fscore: 68.87, time: 1.95 sec
epoch: 65, train_loss: 6.865699768066406, train_acc: 85.17, train_fscore: 85.07, valid_loss: 6.484099864959717, valid_acc: 74.4, valid_fscore: 74.86, test_loss: 7.5655999183654785, test_acc: 68.7, test_fscore: 69.23, time: 2.04 sec
epoch: 66, train_loss: 6.885700225830078, train_acc: 85.33, train_fscore: 85.23, valid_loss: 6.460000038146973, valid_acc: 73.8, valid_fscore: 74.66, test_loss: 7.618199825286865, test_acc: 68.21, test_fscore: 68.8, time: 2.02 sec
epoch: 67, train_loss: 6.855999946594238, train_acc: 85.04, train_fscore: 84.94, valid_loss: 6.425099849700928, valid_acc: 74.25, valid_fscore: 74.9, test_loss: 7.613900184631348, test_acc: 68.21, test_fscore: 68.7, time: 2.03 sec
epoch: 68, train_loss: 6.8572001457214355, train_acc: 85.76, train_fscore: 85.66, valid_loss: 6.474899768829346, valid_acc: 74.1, valid_fscore: 74.8, test_loss: 7.621699810028076, test_acc: 68.27, test_fscore: 68.8, time: 2.03 sec
epoch: 69, train_loss: 6.82919979095459, train_acc: 85.95, train_fscore: 85.88, valid_loss: 6.4832000732421875, valid_acc: 74.4, valid_fscore: 75.07, test_loss: 7.609799861907959, test_acc: 68.45, test_fscore: 69.06, time: 2.0 sec
epoch: 70, train_loss: 6.809100151062012, train_acc: 85.87, train_fscore: 85.78, valid_loss: 6.417799949645996, valid_acc: 74.55, valid_fscore: 75.04, test_loss: 7.5954999923706055, test_acc: 68.76, test_fscore: 69.34, time: 2.05 sec
              precision    recall  f1-score   support

           0     0.4402    0.7917    0.5658     144.0
           1     0.8217    0.7714    0.7958     245.0
           2     0.7158    0.6823    0.6987     384.0
           3     0.6335    0.7118    0.6704     170.0
           4     0.8900    0.5953    0.7134     299.0
           5     0.6684    0.6614    0.6649     381.0

    accuracy                         0.6876    1623.0
   macro avg     0.6949    0.7023    0.6848    1623.0
weighted avg     0.7197    0.6876    0.6934    1623.0

[[114.   4.  12.   0.  13.   1.]
 [  3. 189.  19.   1.   0.  33.]
 [ 42.  22. 262.  11.   3.  44.]
 [  0.   0.   4. 121.   0.  45.]
 [ 98.   1.  20.   0. 178.   2.]
 [  2.  14.  49.  58.   6. 252.]]
epoch: 71, train_loss: 6.761099815368652, train_acc: 86.24, train_fscore: 86.13, valid_loss: 6.435500144958496, valid_acc: 74.25, valid_fscore: 74.82, test_loss: 7.621200084686279, test_acc: 68.33, test_fscore: 68.9, time: 1.95 sec
epoch: 72, train_loss: 6.777699947357178, train_acc: 86.26, train_fscore: 86.19, valid_loss: 6.4644999504089355, valid_acc: 74.55, valid_fscore: 75.16, test_loss: 7.59089994430542, test_acc: 68.82, test_fscore: 69.36, time: 1.99 sec
epoch: 73, train_loss: 6.764500141143799, train_acc: 86.81, train_fscore: 86.71, valid_loss: 6.481400012969971, valid_acc: 74.55, valid_fscore: 74.99, test_loss: 7.558800220489502, test_acc: 69.93, test_fscore: 70.47, time: 2.0 sec
epoch: 74, train_loss: 6.758999824523926, train_acc: 86.59, train_fscore: 86.48, valid_loss: 6.508900165557861, valid_acc: 73.8, valid_fscore: 74.6, test_loss: 7.634099960327148, test_acc: 68.7, test_fscore: 69.29, time: 2.03 sec
epoch: 75, train_loss: 6.719699859619141, train_acc: 86.44, train_fscore: 86.35, valid_loss: 6.538700103759766, valid_acc: 73.64, valid_fscore: 74.23, test_loss: 7.627399921417236, test_acc: 68.33, test_fscore: 68.87, time: 2.01 sec
epoch: 76, train_loss: 6.736000061035156, train_acc: 86.92, train_fscore: 86.87, valid_loss: 6.564300060272217, valid_acc: 73.19, valid_fscore: 73.93, test_loss: 7.585000038146973, test_acc: 69.13, test_fscore: 69.69, time: 2.05 sec
epoch: 77, train_loss: 6.700300216674805, train_acc: 87.21, train_fscore: 87.14, valid_loss: 6.516300201416016, valid_acc: 74.85, valid_fscore: 75.15, test_loss: 7.553400039672852, test_acc: 69.99, test_fscore: 70.46, time: 2.08 sec
epoch: 78, train_loss: 6.694799900054932, train_acc: 87.35, train_fscore: 87.21, valid_loss: 6.515699863433838, valid_acc: 75.0, valid_fscore: 75.57, test_loss: 7.642600059509277, test_acc: 69.5, test_fscore: 70.03, time: 2.0 sec
epoch: 79, train_loss: 6.684299945831299, train_acc: 87.91, train_fscore: 87.86, valid_loss: 6.5289998054504395, valid_acc: 75.3, valid_fscore: 75.74, test_loss: 7.646500110626221, test_acc: 69.07, test_fscore: 69.58, time: 1.98 sec
epoch: 80, train_loss: 6.686299800872803, train_acc: 87.21, train_fscore: 87.15, valid_loss: 6.506800174713135, valid_acc: 75.9, valid_fscore: 76.09, test_loss: 7.579599857330322, test_acc: 70.18, test_fscore: 70.65, time: 1.99 sec
              precision    recall  f1-score   support

           0     0.4779    0.7500    0.5838     144.0
           1     0.8370    0.7755    0.8051     245.0
           2     0.7135    0.6875    0.7003     384.0
           3     0.6305    0.7529    0.6863     170.0
           4     0.8734    0.6689    0.7576     299.0
           5     0.6766    0.6535    0.6649     381.0

    accuracy                         0.7018    1623.0
   macro avg     0.7015    0.7147    0.6997    1623.0
weighted avg     0.7233    0.7018    0.7065    1623.0

[[108.   4.  12.   0.  19.   1.]
 [  2. 190.  20.   1.   0.  32.]
 [ 39.  20. 264.  12.   4.  45.]
 [  0.   0.   3. 128.   0.  39.]
 [ 77.   1.  19.   0. 200.   2.]
 [  0.  12.  52.  62.   6. 249.]]
epoch: 81, train_loss: 6.680500030517578, train_acc: 87.33, train_fscore: 87.22, valid_loss: 6.539100170135498, valid_acc: 74.7, valid_fscore: 75.35, test_loss: 7.670499801635742, test_acc: 68.82, test_fscore: 69.4, time: 1.98 sec
epoch: 82, train_loss: 6.668799877166748, train_acc: 87.21, train_fscore: 87.17, valid_loss: 6.532700061798096, valid_acc: 74.7, valid_fscore: 75.14, test_loss: 7.674200057983398, test_acc: 68.64, test_fscore: 69.1, time: 1.92 sec
epoch: 83, train_loss: 6.639599800109863, train_acc: 88.22, train_fscore: 88.15, valid_loss: 6.531199932098389, valid_acc: 76.36, valid_fscore: 76.43, test_loss: 7.57480001449585, test_acc: 69.93, test_fscore: 70.34, time: 2.02 sec
epoch: 84, train_loss: 6.63100004196167, train_acc: 88.28, train_fscore: 88.2, valid_loss: 6.519400119781494, valid_acc: 76.05, valid_fscore: 76.49, test_loss: 7.650100231170654, test_acc: 69.13, test_fscore: 69.66, time: 1.97 sec
epoch: 85, train_loss: 6.627699851989746, train_acc: 87.99, train_fscore: 87.91, valid_loss: 6.501399993896484, valid_acc: 73.64, valid_fscore: 74.29, test_loss: 7.664299964904785, test_acc: 68.52, test_fscore: 69.07, time: 2.09 sec
epoch: 86, train_loss: 6.603799819946289, train_acc: 87.89, train_fscore: 87.81, valid_loss: 6.507400035858154, valid_acc: 75.45, valid_fscore: 75.66, test_loss: 7.602099895477295, test_acc: 70.24, test_fscore: 70.69, time: 1.99 sec
epoch: 87, train_loss: 6.584799766540527, train_acc: 88.59, train_fscore: 88.51, valid_loss: 6.5833001136779785, valid_acc: 74.85, valid_fscore: 75.36, test_loss: 7.660600185394287, test_acc: 69.19, test_fscore: 69.71, time: 2.01 sec
epoch: 88, train_loss: 6.563000202178955, train_acc: 88.69, train_fscore: 88.59, valid_loss: 6.621500015258789, valid_acc: 74.55, valid_fscore: 75.04, test_loss: 7.686800003051758, test_acc: 68.88, test_fscore: 69.44, time: 2.02 sec
epoch: 89, train_loss: 6.553299903869629, train_acc: 88.75, train_fscore: 88.7, valid_loss: 6.6016998291015625, valid_acc: 75.45, valid_fscore: 75.66, test_loss: 7.663599967956543, test_acc: 69.5, test_fscore: 69.97, time: 2.03 sec
epoch: 90, train_loss: 6.53410005569458, train_acc: 89.41, train_fscore: 89.33, valid_loss: 6.613999843597412, valid_acc: 74.85, valid_fscore: 75.28, test_loss: 7.6321001052856445, test_acc: 70.36, test_fscore: 70.81, time: 2.05 sec
              precision    recall  f1-score   support

           0     0.4703    0.7708    0.5842     144.0
           1     0.8304    0.7796    0.8042     245.0
           2     0.7095    0.7188    0.7141     384.0
           3     0.6368    0.7529    0.6900     170.0
           4     0.8756    0.6355    0.7364     299.0
           5     0.7029    0.6457    0.6731     381.0

    accuracy                         0.7036    1623.0
   macro avg     0.7043    0.7172    0.7003    1623.0
weighted avg     0.7280    0.7036    0.7081    1623.0

[[111.   4.  12.   0.  16.   1.]
 [  3. 191.  20.   3.   0.  28.]
 [ 37.  21. 276.   9.   5.  36.]
 [  0.   0.   5. 128.   0.  37.]
 [ 84.   1.  22.   0. 190.   2.]
 [  1.  13.  54.  61.   6. 246.]]
epoch: 91, train_loss: 6.5690999031066895, train_acc: 88.79, train_fscore: 88.68, valid_loss: 6.667500019073486, valid_acc: 75.15, valid_fscore: 75.59, test_loss: 7.660200119018555, test_acc: 70.24, test_fscore: 70.69, time: 2.0 sec
epoch: 92, train_loss: 6.533199787139893, train_acc: 89.1, train_fscore: 89.03, valid_loss: 6.649400234222412, valid_acc: 74.7, valid_fscore: 74.95, test_loss: 7.739799976348877, test_acc: 69.32, test_fscore: 69.78, time: 2.0 sec
epoch: 93, train_loss: 6.514699935913086, train_acc: 89.7, train_fscore: 89.66, valid_loss: 6.614999771118164, valid_acc: 75.0, valid_fscore: 75.49, test_loss: 7.808899879455566, test_acc: 68.08, test_fscore: 68.61, time: 2.0 sec
epoch: 94, train_loss: 6.503699779510498, train_acc: 89.35, train_fscore: 89.29, valid_loss: 6.605400085449219, valid_acc: 75.3, valid_fscore: 75.43, test_loss: 7.6875, test_acc: 69.5, test_fscore: 69.98, time: 2.01 sec
epoch: 95, train_loss: 6.487299919128418, train_acc: 89.62, train_fscore: 89.53, valid_loss: 6.62060022354126, valid_acc: 75.45, valid_fscore: 75.59, test_loss: 7.714399814605713, test_acc: 69.01, test_fscore: 69.47, time: 2.01 sec
epoch: 96, train_loss: 6.514400005340576, train_acc: 90.19, train_fscore: 90.12, valid_loss: 6.619100093841553, valid_acc: 74.55, valid_fscore: 74.87, test_loss: 7.772799968719482, test_acc: 68.82, test_fscore: 69.29, time: 2.0 sec
epoch: 97, train_loss: 6.470300197601318, train_acc: 89.43, train_fscore: 89.37, valid_loss: 6.61959981918335, valid_acc: 74.7, valid_fscore: 75.14, test_loss: 7.733500003814697, test_acc: 69.5, test_fscore: 70.05, time: 2.03 sec
epoch: 98, train_loss: 6.473700046539307, train_acc: 89.62, train_fscore: 89.54, valid_loss: 6.684599876403809, valid_acc: 75.0, valid_fscore: 75.22, test_loss: 7.702000141143799, test_acc: 69.87, test_fscore: 70.41, time: 2.01 sec
epoch: 99, train_loss: 6.447999954223633, train_acc: 89.76, train_fscore: 89.69, valid_loss: 6.63730001449585, valid_acc: 75.3, valid_fscore: 75.4, test_loss: 7.750999927520752, test_acc: 69.07, test_fscore: 69.5, time: 1.98 sec
epoch: 100, train_loss: 6.440299987792969, train_acc: 90.34, train_fscore: 90.27, valid_loss: 6.629000186920166, valid_acc: 74.1, valid_fscore: 74.51, test_loss: 7.7677001953125, test_acc: 69.19, test_fscore: 69.66, time: 2.02 sec
              precision    recall  f1-score   support

           0     0.4696    0.8056    0.5934     144.0
           1     0.8393    0.7673    0.8017     245.0
           2     0.7123    0.6641    0.6873     384.0
           3     0.6429    0.7412    0.6885     170.0
           4     0.8867    0.6020    0.7171     299.0
           5     0.6532    0.6772    0.6649     381.0

    accuracy                         0.6919    1623.0
   macro avg     0.7007    0.7096    0.6922    1623.0
weighted avg     0.7209    0.6919    0.6966    1623.0

[[116.   4.  10.   0.  13.   1.]
 [  2. 188.  20.   2.   0.  33.]
 [ 38.  19. 255.  10.   4.  58.]
 [  0.   0.   2. 126.   0.  42.]
 [ 91.   1.  24.   0. 180.   3.]
 [  0.  12.  47.  58.   6. 258.]]
epoch: 101, train_loss: 6.458199977874756, train_acc: 89.47, train_fscore: 89.38, valid_loss: 6.698400020599365, valid_acc: 74.7, valid_fscore: 74.89, test_loss: 7.752699851989746, test_acc: 69.99, test_fscore: 70.49, time: 2.03 sec
epoch: 102, train_loss: 6.433800220489502, train_acc: 89.88, train_fscore: 89.81, valid_loss: 6.686999797821045, valid_acc: 75.6, valid_fscore: 75.74, test_loss: 7.754300117492676, test_acc: 69.5, test_fscore: 69.93, time: 2.04 sec
epoch: 103, train_loss: 6.438700199127197, train_acc: 90.73, train_fscore: 90.67, valid_loss: 6.654099941253662, valid_acc: 75.75, valid_fscore: 76.09, test_loss: 7.7845001220703125, test_acc: 68.95, test_fscore: 69.34, time: 2.06 sec
epoch: 104, train_loss: 6.401199817657471, train_acc: 90.67, train_fscore: 90.61, valid_loss: 6.72730016708374, valid_acc: 75.6, valid_fscore: 75.71, test_loss: 7.701600074768066, test_acc: 69.81, test_fscore: 70.25, time: 1.95 sec
epoch: 105, train_loss: 6.392499923706055, train_acc: 90.69, train_fscore: 90.62, valid_loss: 6.75600004196167, valid_acc: 76.05, valid_fscore: 75.88, test_loss: 7.713099956512451, test_acc: 70.55, test_fscore: 70.9, time: 1.97 sec
epoch: 106, train_loss: 6.387499809265137, train_acc: 91.12, train_fscore: 91.05, valid_loss: 6.717899799346924, valid_acc: 74.85, valid_fscore: 75.27, test_loss: 7.878600120544434, test_acc: 68.52, test_fscore: 68.93, time: 2.08 sec
epoch: 107, train_loss: 6.393700122833252, train_acc: 90.24, train_fscore: 90.19, valid_loss: 6.721399784088135, valid_acc: 74.7, valid_fscore: 74.86, test_loss: 7.763299942016602, test_acc: 69.01, test_fscore: 69.44, time: 1.96 sec
epoch: 108, train_loss: 6.371200084686279, train_acc: 90.96, train_fscore: 90.91, valid_loss: 6.719200134277344, valid_acc: 75.6, valid_fscore: 75.67, test_loss: 7.7494001388549805, test_acc: 69.62, test_fscore: 70.04, time: 2.0 sec
epoch: 109, train_loss: 6.355100154876709, train_acc: 91.22, train_fscore: 91.16, valid_loss: 6.71019983291626, valid_acc: 75.6, valid_fscore: 75.8, test_loss: 7.848800182342529, test_acc: 69.5, test_fscore: 69.88, time: 2.1 sec
epoch: 110, train_loss: 6.350399971008301, train_acc: 91.2, train_fscore: 91.14, valid_loss: 6.7657999992370605, valid_acc: 74.1, valid_fscore: 74.29, test_loss: 7.838699817657471, test_acc: 69.56, test_fscore: 70.02, time: 1.99 sec
              precision    recall  f1-score   support

           0     0.4889    0.7639    0.5962     144.0
           1     0.8592    0.7469    0.7991     245.0
           2     0.6939    0.6849    0.6894     384.0
           3     0.6368    0.7529    0.6900     170.0
           4     0.8785    0.6288    0.7329     299.0
           5     0.6573    0.6745    0.6658     381.0

    accuracy                         0.6956    1623.0
   macro avg     0.7024    0.7087    0.6956    1623.0
weighted avg     0.7201    0.6956    0.7002    1623.0

[[110.   4.  13.   0.  16.   1.]
 [  2. 183.  25.   2.   0.  33.]
 [ 32.  14. 263.  12.   5.  58.]
 [  0.   0.   3. 128.   0.  39.]
 [ 81.   1.  26.   0. 188.   3.]
 [  0.  11.  49.  59.   5. 257.]]
epoch: 111, train_loss: 6.360400199890137, train_acc: 91.06, train_fscore: 91.01, valid_loss: 6.741700172424316, valid_acc: 74.25, valid_fscore: 74.44, test_loss: 7.872000217437744, test_acc: 68.7, test_fscore: 69.18, time: 1.98 sec
epoch: 112, train_loss: 6.334400177001953, train_acc: 91.68, train_fscore: 91.63, valid_loss: 6.736400127410889, valid_acc: 74.85, valid_fscore: 74.89, test_loss: 7.819799900054932, test_acc: 70.06, test_fscore: 70.42, time: 1.99 sec
epoch: 113, train_loss: 6.340799808502197, train_acc: 91.08, train_fscore: 90.97, valid_loss: 6.829800128936768, valid_acc: 74.7, valid_fscore: 74.76, test_loss: 7.751299858093262, test_acc: 70.55, test_fscore: 70.97, time: 1.92 sec
epoch: 114, train_loss: 6.329800128936768, train_acc: 91.95, train_fscore: 91.92, valid_loss: 6.811600208282471, valid_acc: 74.4, valid_fscore: 74.47, test_loss: 7.826200008392334, test_acc: 69.99, test_fscore: 70.41, time: 1.98 sec
epoch: 115, train_loss: 6.306000232696533, train_acc: 91.66, train_fscore: 91.59, valid_loss: 6.783299922943115, valid_acc: 74.7, valid_fscore: 74.68, test_loss: 7.784800052642822, test_acc: 70.06, test_fscore: 70.45, time: 2.09 sec
epoch: 116, train_loss: 6.281499862670898, train_acc: 91.78, train_fscore: 91.71, valid_loss: 6.78410005569458, valid_acc: 74.85, valid_fscore: 74.94, test_loss: 7.828100204467773, test_acc: 69.99, test_fscore: 70.38, time: 1.95 sec
epoch: 117, train_loss: 6.28249979019165, train_acc: 92.19, train_fscore: 92.15, valid_loss: 6.757199764251709, valid_acc: 75.0, valid_fscore: 75.12, test_loss: 7.88670015335083, test_acc: 69.38, test_fscore: 69.77, time: 1.97 sec
epoch: 118, train_loss: 6.2754998207092285, train_acc: 91.84, train_fscore: 91.78, valid_loss: 6.818900108337402, valid_acc: 74.4, valid_fscore: 74.49, test_loss: 7.872099876403809, test_acc: 69.5, test_fscore: 69.99, time: 1.99 sec
epoch: 119, train_loss: 6.2758002281188965, train_acc: 92.03, train_fscore: 91.99, valid_loss: 6.8354997634887695, valid_acc: 74.85, valid_fscore: 74.83, test_loss: 7.896999835968018, test_acc: 69.13, test_fscore: 69.5, time: 1.93 sec
epoch: 120, train_loss: 6.264900207519531, train_acc: 91.88, train_fscore: 91.82, valid_loss: 6.831200122833252, valid_acc: 74.7, valid_fscore: 74.75, test_loss: 7.876500129699707, test_acc: 69.75, test_fscore: 70.18, time: 2.02 sec
              precision    recall  f1-score   support

           0     0.4714    0.7431    0.5768     144.0
           1     0.8514    0.7714    0.8094     245.0
           2     0.6917    0.7188    0.7050     384.0
           3     0.6543    0.7235    0.6872     170.0
           4     0.8702    0.6054    0.7140     299.0
           5     0.6755    0.6719    0.6737     381.0

    accuracy                         0.6975    1623.0
   macro avg     0.7024    0.7057    0.6943    1623.0
weighted avg     0.7214    0.6975    0.7018    1623.0

[[107.   4.  14.   0.  18.   1.]
 [  2. 189.  23.   2.   0.  29.]
 [ 33.  16. 276.   7.   4.  48.]
 [  0.   0.   4. 123.   0.  43.]
 [ 85.   2.  29.   0. 181.   2.]
 [  0.  11.  53.  56.   5. 256.]]
epoch: 121, train_loss: 6.260700225830078, train_acc: 92.36, train_fscore: 92.31, valid_loss: 6.901100158691406, valid_acc: 73.34, valid_fscore: 73.49, test_loss: 7.822700023651123, test_acc: 69.38, test_fscore: 69.88, time: 1.98 sec
epoch: 122, train_loss: 6.261000156402588, train_acc: 92.25, train_fscore: 92.19, valid_loss: 6.883200168609619, valid_acc: 74.55, valid_fscore: 74.54, test_loss: 7.909299850463867, test_acc: 69.75, test_fscore: 70.17, time: 1.9 sec
epoch: 123, train_loss: 6.257299900054932, train_acc: 92.48, train_fscore: 92.43, valid_loss: 6.883699893951416, valid_acc: 74.1, valid_fscore: 74.1, test_loss: 7.958600044250488, test_acc: 70.06, test_fscore: 70.42, time: 1.99 sec
epoch: 124, train_loss: 6.226900100708008, train_acc: 92.52, train_fscore: 92.48, valid_loss: 6.921800136566162, valid_acc: 74.1, valid_fscore: 74.28, test_loss: 7.9527997970581055, test_acc: 69.75, test_fscore: 70.18, time: 1.95 sec
epoch: 125, train_loss: 6.196800231933594, train_acc: 92.13, train_fscore: 92.09, valid_loss: 6.9415998458862305, valid_acc: 75.0, valid_fscore: 75.12, test_loss: 7.875500202178955, test_acc: 70.24, test_fscore: 70.6, time: 2.0 sec
epoch: 126, train_loss: 6.221799850463867, train_acc: 92.54, train_fscore: 92.48, valid_loss: 6.924499988555908, valid_acc: 74.85, valid_fscore: 74.94, test_loss: 7.915900230407715, test_acc: 69.99, test_fscore: 70.38, time: 1.95 sec
epoch: 127, train_loss: 6.221199989318848, train_acc: 92.71, train_fscore: 92.67, valid_loss: 6.926000118255615, valid_acc: 74.4, valid_fscore: 74.36, test_loss: 7.965700149536133, test_acc: 69.25, test_fscore: 69.69, time: 1.94 sec
epoch: 128, train_loss: 6.224899768829346, train_acc: 92.54, train_fscore: 92.5, valid_loss: 6.914299964904785, valid_acc: 74.4, valid_fscore: 74.51, test_loss: 7.9440999031066895, test_acc: 69.13, test_fscore: 69.58, time: 1.97 sec
epoch: 129, train_loss: 6.1975998878479, train_acc: 92.97, train_fscore: 92.91, valid_loss: 6.9232001304626465, valid_acc: 75.6, valid_fscore: 75.54, test_loss: 7.899899959564209, test_acc: 70.67, test_fscore: 71.0, time: 1.91 sec
epoch: 130, train_loss: 6.190199851989746, train_acc: 93.22, train_fscore: 93.18, valid_loss: 6.907599925994873, valid_acc: 75.6, valid_fscore: 75.5, test_loss: 7.894100189208984, test_acc: 70.98, test_fscore: 71.33, time: 1.99 sec
              precision    recall  f1-score   support

           0     0.5149    0.7222    0.6012     144.0
           1     0.8500    0.7633    0.8043     245.0
           2     0.6983    0.7292    0.7134     384.0
           3     0.6614    0.7353    0.6964     170.0
           4     0.8578    0.6656    0.7495     299.0
           5     0.6781    0.6745    0.6763     381.0

    accuracy                         0.7098    1623.0
   macro avg     0.7101    0.7150    0.7068    1623.0
weighted avg     0.7257    0.7098    0.7133    1623.0

[[104.   4.  13.   0.  22.   1.]
 [  2. 187.  24.   1.   0.  31.]
 [ 28.  16. 280.   7.   6.  47.]
 [  0.   0.   4. 125.   0.  41.]
 [ 68.   2.  28.   0. 199.   2.]
 [  0.  11.  52.  56.   5. 257.]]
epoch: 131, train_loss: 6.1905999183654785, train_acc: 92.83, train_fscore: 92.78, valid_loss: 6.952199935913086, valid_acc: 73.8, valid_fscore: 74.17, test_loss: 7.971099853515625, test_acc: 69.81, test_fscore: 70.25, time: 1.97 sec
epoch: 132, train_loss: 6.168499946594238, train_acc: 92.97, train_fscore: 92.93, valid_loss: 6.974999904632568, valid_acc: 73.8, valid_fscore: 73.95, test_loss: 7.990600109100342, test_acc: 70.06, test_fscore: 70.46, time: 2.09 sec
epoch: 133, train_loss: 6.169899940490723, train_acc: 93.06, train_fscore: 93.02, valid_loss: 6.967400074005127, valid_acc: 74.7, valid_fscore: 74.75, test_loss: 8.006600379943848, test_acc: 70.3, test_fscore: 70.71, time: 1.97 sec
epoch: 134, train_loss: 6.172699928283691, train_acc: 93.74, train_fscore: 93.71, valid_loss: 6.92080020904541, valid_acc: 74.25, valid_fscore: 74.51, test_loss: 8.067700386047363, test_acc: 69.13, test_fscore: 69.56, time: 1.97 sec
epoch: 135, train_loss: 6.157599925994873, train_acc: 92.71, train_fscore: 92.67, valid_loss: 6.944900035858154, valid_acc: 74.25, valid_fscore: 74.33, test_loss: 7.993899822235107, test_acc: 69.99, test_fscore: 70.4, time: 2.11 sec
epoch: 136, train_loss: 6.136199951171875, train_acc: 93.94, train_fscore: 93.9, valid_loss: 6.950500011444092, valid_acc: 74.25, valid_fscore: 74.2, test_loss: 7.9980998039245605, test_acc: 70.06, test_fscore: 70.45, time: 1.99 sec
epoch: 137, train_loss: 6.1605000495910645, train_acc: 93.57, train_fscore: 93.54, valid_loss: 6.931000232696533, valid_acc: 74.55, valid_fscore: 74.66, test_loss: 8.031100273132324, test_acc: 68.76, test_fscore: 69.19, time: 2.0 sec
epoch: 138, train_loss: 6.124899864196777, train_acc: 93.45, train_fscore: 93.41, valid_loss: 6.941999912261963, valid_acc: 74.7, valid_fscore: 74.58, test_loss: 8.015800476074219, test_acc: 69.56, test_fscore: 69.99, time: 2.05 sec
epoch: 139, train_loss: 6.123799800872803, train_acc: 93.12, train_fscore: 93.08, valid_loss: 6.972799777984619, valid_acc: 75.0, valid_fscore: 74.9, test_loss: 8.026300430297852, test_acc: 70.36, test_fscore: 70.76, time: 1.96 sec
epoch: 140, train_loss: 6.106200218200684, train_acc: 93.9, train_fscore: 93.87, valid_loss: 6.97160005569458, valid_acc: 74.1, valid_fscore: 74.01, test_loss: 8.025500297546387, test_acc: 69.99, test_fscore: 70.33, time: 2.06 sec
              precision    recall  f1-score   support

           0     0.5024    0.7222    0.5926     144.0
           1     0.8514    0.7714    0.8094     245.0
           2     0.6942    0.7214    0.7075     384.0
           3     0.6311    0.7647    0.6915     170.0
           4     0.8514    0.6321    0.7255     299.0
           5     0.6730    0.6483    0.6604     381.0

    accuracy                         0.6999    1623.0
   macro avg     0.7006    0.7100    0.6978    1623.0
weighted avg     0.7183    0.6999    0.7033    1623.0

[[104.   5.  12.   0.  22.   1.]
 [  2. 189.  22.   3.   0.  29.]
 [ 28.  15. 277.   7.   6.  51.]
 [  0.   0.   4. 130.   0.  36.]
 [ 73.   2.  32.   0. 189.   3.]
 [  0.  11.  52.  66.   5. 247.]]
epoch: 141, train_loss: 6.113399982452393, train_acc: 94.19, train_fscore: 94.15, valid_loss: 6.994500160217285, valid_acc: 74.4, valid_fscore: 74.32, test_loss: 8.039799690246582, test_acc: 70.06, test_fscore: 70.44, time: 1.95 sec
epoch: 142, train_loss: 6.09499979019165, train_acc: 94.11, train_fscore: 94.09, valid_loss: 7.009399890899658, valid_acc: 75.15, valid_fscore: 74.97, test_loss: 8.003499984741211, test_acc: 70.98, test_fscore: 71.3, time: 1.95 sec
epoch: 143, train_loss: 6.103099822998047, train_acc: 94.0, train_fscore: 93.95, valid_loss: 7.033299922943115, valid_acc: 73.8, valid_fscore: 73.75, test_loss: 8.007200241088867, test_acc: 70.12, test_fscore: 70.49, time: 1.96 sec
epoch: 144, train_loss: 6.086100101470947, train_acc: 93.96, train_fscore: 93.93, valid_loss: 7.03879976272583, valid_acc: 73.04, valid_fscore: 73.15, test_loss: 8.086299896240234, test_acc: 69.62, test_fscore: 70.03, time: 2.06 sec
epoch: 145, train_loss: 6.058199882507324, train_acc: 94.42, train_fscore: 94.39, valid_loss: 7.009500026702881, valid_acc: 74.1, valid_fscore: 73.97, test_loss: 8.083100318908691, test_acc: 69.69, test_fscore: 69.99, time: 1.99 sec
epoch: 146, train_loss: 6.076099872589111, train_acc: 94.38, train_fscore: 94.34, valid_loss: 7.021900177001953, valid_acc: 74.4, valid_fscore: 74.22, test_loss: 8.081500053405762, test_acc: 70.3, test_fscore: 70.6, time: 2.11 sec
epoch: 147, train_loss: 6.068999767303467, train_acc: 94.29, train_fscore: 94.25, valid_loss: 7.036200046539307, valid_acc: 73.95, valid_fscore: 73.9, test_loss: 8.143600463867188, test_acc: 70.43, test_fscore: 70.8, time: 1.94 sec
epoch: 148, train_loss: 6.064899921417236, train_acc: 93.98, train_fscore: 93.95, valid_loss: 7.010799884796143, valid_acc: 74.4, valid_fscore: 74.26, test_loss: 8.147000312805176, test_acc: 69.81, test_fscore: 70.14, time: 2.0 sec
epoch: 149, train_loss: 6.067999839782715, train_acc: 94.64, train_fscore: 94.61, valid_loss: 7.071700096130371, valid_acc: 74.7, valid_fscore: 74.47, test_loss: 8.050399780273438, test_acc: 70.61, test_fscore: 70.91, time: 1.93 sec
epoch: 150, train_loss: 6.061699867248535, train_acc: 94.81, train_fscore: 94.78, valid_loss: 7.04610013961792, valid_acc: 74.1, valid_fscore: 74.06, test_loss: 8.02239990234375, test_acc: 71.16, test_fscore: 71.51, time: 1.99 sec
              precision    recall  f1-score   support

           0     0.5192    0.7500    0.6136     144.0
           1     0.8605    0.7551    0.8043     245.0
           2     0.6970    0.7370    0.7165     384.0
           3     0.6500    0.7647    0.7027     170.0
           4     0.8640    0.6589    0.7476     299.0
           5     0.6885    0.6614    0.6747     381.0

    accuracy                         0.7116    1623.0
   macro avg     0.7132    0.7212    0.7099    1623.0
weighted avg     0.7298    0.7116    0.7151    1623.0

[[108.   3.  11.   0.  21.   1.]
 [  2. 185.  27.   3.   0.  28.]
 [ 29.  14. 283.   6.   5.  47.]
 [  0.   0.   4. 130.   0.  36.]
 [ 69.   2.  29.   0. 197.   2.]
 [  0.  11.  52.  61.   5. 252.]]
Best validation F-Score: 71.51
Test performance..
F-Score: 71.51
Accuracy: 71.16
Loss: 8.02239990234375
--- 10 ---
loss_mask: [True, True, True, True]
Namespace(no_cuda=False, lr=0.0001, l2=1e-05, dropout=0.5, batch_size=64, hidden_dim=1024, n_head=8, epochs=150, temp=2, tensorboard=False, class_weight=True, Dataset='IEMOCAP', loss_mask='1111')
Running on GPU
temp 2
total parameters: 97535000
training parameters: 97535000
epoch: 1, train_loss: 12.284600257873535, train_acc: 22.44, train_fscore: 22.12, valid_loss: 10.229299545288086, valid_acc: 33.89, valid_fscore: 27.5, test_loss: 11.215200424194336, test_acc: 27.17, test_fscore: 22.44, time: 3.14 sec
epoch: 2, train_loss: 11.586700439453125, train_acc: 35.87, train_fscore: 34.34, valid_loss: 9.5826997756958, valid_acc: 45.03, valid_fscore: 44.5, test_loss: 10.61709976196289, test_acc: 46.03, test_fscore: 43.66, time: 1.99 sec
epoch: 3, train_loss: 11.076899528503418, train_acc: 48.37, train_fscore: 46.37, valid_loss: 9.272899627685547, valid_acc: 55.87, valid_fscore: 55.67, test_loss: 10.321499824523926, test_acc: 48.43, test_fscore: 46.83, time: 2.02 sec
epoch: 4, train_loss: 10.68019962310791, train_acc: 50.45, train_fscore: 47.77, valid_loss: 9.08240032196045, valid_acc: 49.4, valid_fscore: 51.42, test_loss: 10.181699752807617, test_acc: 44.36, test_fscore: 44.05, time: 2.03 sec
epoch: 5, train_loss: 10.381699562072754, train_acc: 52.88, train_fscore: 51.38, valid_loss: 8.827300071716309, valid_acc: 56.02, valid_fscore: 58.33, test_loss: 10.01099967956543, test_acc: 51.82, test_fscore: 52.15, time: 1.97 sec
epoch: 6, train_loss: 10.11520004272461, train_acc: 60.16, train_fscore: 59.76, valid_loss: 8.530699729919434, valid_acc: 65.66, valid_fscore: 66.04, test_loss: 9.749799728393555, test_acc: 59.83, test_fscore: 60.17, time: 2.01 sec
epoch: 7, train_loss: 9.804499626159668, train_acc: 63.82, train_fscore: 63.59, valid_loss: 8.163700103759766, valid_acc: 64.31, valid_fscore: 66.41, test_loss: 9.38759994506836, test_acc: 56.87, test_fscore: 57.72, time: 1.92 sec
epoch: 8, train_loss: 9.48900032043457, train_acc: 64.13, train_fscore: 64.07, valid_loss: 7.868800163269043, valid_acc: 63.25, valid_fscore: 65.44, test_loss: 9.119799613952637, test_acc: 58.41, test_fscore: 59.19, time: 1.94 sec
epoch: 9, train_loss: 9.169699668884277, train_acc: 65.78, train_fscore: 65.58, valid_loss: 7.653900146484375, valid_acc: 66.57, valid_fscore: 67.0, test_loss: 8.93019962310791, test_acc: 60.57, test_fscore: 61.21, time: 2.06 sec
epoch: 10, train_loss: 8.989100456237793, train_acc: 67.14, train_fscore: 66.75, valid_loss: 7.4567999839782715, valid_acc: 65.96, valid_fscore: 67.66, test_loss: 8.741800308227539, test_acc: 61.43, test_fscore: 62.47, time: 2.11 sec
              precision    recall  f1-score   support

           0     0.3228    0.6389    0.4289     144.0
           1     0.7885    0.6694    0.7241     245.0
           2     0.6103    0.5547    0.5812     384.0
           3     0.5825    0.7059    0.6383     170.0
           4     0.8426    0.5552    0.6694     299.0
           5     0.6402    0.6352    0.6377     381.0

    accuracy                         0.6143    1623.0
   macro avg     0.6312    0.6265    0.6132    1623.0
weighted avg     0.6586    0.6143    0.6247    1623.0

[[ 92.   8.  13.   4.  25.   2.]
 [ 14. 164.  39.   2.   0.  26.]
 [ 61.  25. 213.  23.   1.  61.]
 [  0.   0.   6. 120.   0.  44.]
 [108.   0.  19.   3. 166.   3.]
 [ 10.  11.  59.  54.   5. 242.]]
epoch: 11, train_loss: 8.886699676513672, train_acc: 68.09, train_fscore: 67.98, valid_loss: 7.365099906921387, valid_acc: 66.87, valid_fscore: 69.07, test_loss: 8.619999885559082, test_acc: 60.44, test_fscore: 61.67, time: 1.95 sec
epoch: 12, train_loss: 8.796299934387207, train_acc: 68.01, train_fscore: 68.0, valid_loss: 7.262700080871582, valid_acc: 68.37, valid_fscore: 69.08, test_loss: 8.524499893188477, test_acc: 63.59, test_fscore: 64.46, time: 2.06 sec
epoch: 13, train_loss: 8.693499565124512, train_acc: 69.1, train_fscore: 68.69, valid_loss: 7.046000003814697, valid_acc: 68.67, valid_fscore: 69.36, test_loss: 8.370400428771973, test_acc: 63.96, test_fscore: 64.74, time: 1.92 sec
epoch: 14, train_loss: 8.614999771118164, train_acc: 69.55, train_fscore: 69.23, valid_loss: 7.02400016784668, valid_acc: 65.06, valid_fscore: 67.71, test_loss: 8.305500030517578, test_acc: 59.7, test_fscore: 60.54, time: 2.61 sec
epoch: 15, train_loss: 8.501999855041504, train_acc: 68.71, train_fscore: 68.52, valid_loss: 7.000500202178955, valid_acc: 68.52, valid_fscore: 70.33, test_loss: 8.274499893188477, test_acc: 62.66, test_fscore: 63.52, time: 2.39 sec
epoch: 16, train_loss: 8.439299583435059, train_acc: 70.23, train_fscore: 69.78, valid_loss: 6.946700096130371, valid_acc: 68.67, valid_fscore: 69.95, test_loss: 8.226300239562988, test_acc: 64.14, test_fscore: 64.87, time: 1.95 sec
epoch: 17, train_loss: 8.372400283813477, train_acc: 70.64, train_fscore: 70.2, valid_loss: 6.895299911499023, valid_acc: 66.57, valid_fscore: 68.61, test_loss: 8.182499885559082, test_acc: 62.54, test_fscore: 63.5, time: 1.97 sec
epoch: 18, train_loss: 8.314000129699707, train_acc: 71.32, train_fscore: 71.16, valid_loss: 6.835599899291992, valid_acc: 67.32, valid_fscore: 68.95, test_loss: 8.138400077819824, test_acc: 64.76, test_fscore: 65.6, time: 1.94 sec
epoch: 19, train_loss: 8.249600410461426, train_acc: 71.84, train_fscore: 71.58, valid_loss: 6.763000011444092, valid_acc: 69.13, valid_fscore: 69.89, test_loss: 8.073200225830078, test_acc: 66.24, test_fscore: 66.84, time: 2.05 sec
epoch: 20, train_loss: 8.198699951171875, train_acc: 72.04, train_fscore: 71.62, valid_loss: 6.73390007019043, valid_acc: 69.13, valid_fscore: 70.91, test_loss: 8.099200248718262, test_acc: 63.59, test_fscore: 64.47, time: 1.94 sec
              precision    recall  f1-score   support

           0     0.3511    0.6875    0.4648     144.0
           1     0.7586    0.7184    0.7379     245.0
           2     0.6807    0.5885    0.6313     384.0
           3     0.6085    0.6765    0.6407     170.0
           4     0.8684    0.5518    0.6748     299.0
           5     0.6307    0.6588    0.6444     381.0

    accuracy                         0.6359    1623.0
   macro avg     0.6497    0.6469    0.6323    1623.0
weighted avg     0.6785    0.6359    0.6447    1623.0

[[ 99.   9.  11.   3.  19.   3.]
 [  5. 176.  30.   1.   0.  33.]
 [ 53.  26. 226.  19.   2.  58.]
 [  0.   0.   4. 115.   0.  51.]
 [120.   0.  12.   0. 165.   2.]
 [  5.  21.  49.  51.   4. 251.]]
epoch: 21, train_loss: 8.148500442504883, train_acc: 72.79, train_fscore: 72.6, valid_loss: 6.709199905395508, valid_acc: 69.13, valid_fscore: 70.42, test_loss: 8.076199531555176, test_acc: 64.63, test_fscore: 65.48, time: 1.99 sec
epoch: 22, train_loss: 8.08180046081543, train_acc: 73.77, train_fscore: 73.51, valid_loss: 6.718900203704834, valid_acc: 70.18, valid_fscore: 70.56, test_loss: 8.032299995422363, test_acc: 67.28, test_fscore: 67.73, time: 2.31 sec
epoch: 23, train_loss: 8.046199798583984, train_acc: 74.08, train_fscore: 73.77, valid_loss: 6.676400184631348, valid_acc: 69.58, valid_fscore: 70.73, test_loss: 7.992599964141846, test_acc: 66.3, test_fscore: 67.02, time: 2.07 sec
epoch: 24, train_loss: 7.975299835205078, train_acc: 73.8, train_fscore: 73.61, valid_loss: 6.662099838256836, valid_acc: 68.83, valid_fscore: 70.89, test_loss: 7.9629998207092285, test_acc: 65.37, test_fscore: 66.24, time: 2.0 sec
epoch: 25, train_loss: 7.945499897003174, train_acc: 74.37, train_fscore: 74.18, valid_loss: 6.635499954223633, valid_acc: 70.63, valid_fscore: 71.12, test_loss: 7.927299976348877, test_acc: 66.91, test_fscore: 67.45, time: 2.01 sec
epoch: 26, train_loss: 7.934199810028076, train_acc: 74.93, train_fscore: 74.62, valid_loss: 6.638199806213379, valid_acc: 70.48, valid_fscore: 71.34, test_loss: 7.944699764251709, test_acc: 66.67, test_fscore: 67.29, time: 1.95 sec
epoch: 27, train_loss: 7.850599765777588, train_acc: 75.22, train_fscore: 75.0, valid_loss: 6.590199947357178, valid_acc: 71.69, valid_fscore: 72.77, test_loss: 7.929699897766113, test_acc: 66.3, test_fscore: 67.02, time: 2.11 sec
epoch: 28, train_loss: 7.819300174713135, train_acc: 75.65, train_fscore: 75.51, valid_loss: 6.561200141906738, valid_acc: 71.54, valid_fscore: 72.53, test_loss: 7.833499908447266, test_acc: 67.47, test_fscore: 68.09, time: 2.11 sec
epoch: 29, train_loss: 7.752399921417236, train_acc: 76.18, train_fscore: 75.89, valid_loss: 6.5578999519348145, valid_acc: 70.33, valid_fscore: 70.74, test_loss: 7.755799770355225, test_acc: 68.27, test_fscore: 68.61, time: 1.99 sec
epoch: 30, train_loss: 7.734300136566162, train_acc: 76.1, train_fscore: 75.8, valid_loss: 6.557499885559082, valid_acc: 69.58, valid_fscore: 70.97, test_loss: 7.749199867248535, test_acc: 66.91, test_fscore: 67.6, time: 2.01 sec
              precision    recall  f1-score   support

           0     0.4163    0.7083    0.5244     144.0
           1     0.7926    0.7020    0.7446     245.0
           2     0.6738    0.6562    0.6649     384.0
           3     0.5981    0.7529    0.6667     170.0
           4     0.8802    0.6388    0.7403     299.0
           5     0.6770    0.6325    0.6540     381.0

    accuracy                         0.6691    1623.0
   macro avg     0.6730    0.6818    0.6658    1623.0
weighted avg     0.6997    0.6691    0.6760    1623.0

[[102.   7.  14.   3.  17.   1.]
 [  6. 172.  35.   1.   0.  31.]
 [ 42.  22. 252.  21.   4.  43.]
 [  0.   0.   3. 128.   0.  39.]
 [ 94.   0.  13.   0. 191.   1.]
 [  1.  16.  57.  61.   5. 241.]]
epoch: 31, train_loss: 7.714399814605713, train_acc: 76.14, train_fscore: 75.94, valid_loss: 6.558899879455566, valid_acc: 71.39, valid_fscore: 72.97, test_loss: 7.846700191497803, test_acc: 65.87, test_fscore: 66.59, time: 1.95 sec
epoch: 32, train_loss: 7.6707000732421875, train_acc: 77.01, train_fscore: 76.91, valid_loss: 6.55709981918335, valid_acc: 71.39, valid_fscore: 72.51, test_loss: 7.841100215911865, test_acc: 66.24, test_fscore: 66.91, time: 2.26 sec
epoch: 33, train_loss: 7.6305999755859375, train_acc: 76.62, train_fscore: 76.36, valid_loss: 6.559599876403809, valid_acc: 70.48, valid_fscore: 71.42, test_loss: 7.761000156402588, test_acc: 67.1, test_fscore: 67.73, time: 3.6 sec
epoch: 34, train_loss: 7.605199813842773, train_acc: 77.09, train_fscore: 76.98, valid_loss: 6.536499977111816, valid_acc: 70.63, valid_fscore: 71.83, test_loss: 7.7058000564575195, test_acc: 67.04, test_fscore: 67.72, time: 4.03 sec
epoch: 35, train_loss: 7.562300205230713, train_acc: 78.22, train_fscore: 78.1, valid_loss: 6.503399848937988, valid_acc: 71.08, valid_fscore: 72.38, test_loss: 7.711299896240234, test_acc: 66.85, test_fscore: 67.54, time: 2.02 sec
epoch: 36, train_loss: 7.532400131225586, train_acc: 77.87, train_fscore: 77.69, valid_loss: 6.541900157928467, valid_acc: 71.23, valid_fscore: 72.29, test_loss: 7.729599952697754, test_acc: 66.97, test_fscore: 67.64, time: 2.6 sec
epoch: 37, train_loss: 7.531700134277344, train_acc: 78.66, train_fscore: 78.53, valid_loss: 6.534800052642822, valid_acc: 71.08, valid_fscore: 72.02, test_loss: 7.732600212097168, test_acc: 66.73, test_fscore: 67.41, time: 4.69 sec
epoch: 38, train_loss: 7.48859977722168, train_acc: 78.82, train_fscore: 78.69, valid_loss: 6.513999938964844, valid_acc: 71.08, valid_fscore: 72.09, test_loss: 7.672800064086914, test_acc: 67.04, test_fscore: 67.72, time: 4.8 sec
epoch: 39, train_loss: 7.47160005569458, train_acc: 78.47, train_fscore: 78.33, valid_loss: 6.505799770355225, valid_acc: 71.08, valid_fscore: 72.37, test_loss: 7.640200138092041, test_acc: 66.17, test_fscore: 66.9, time: 4.23 sec
epoch: 40, train_loss: 7.4390997886657715, train_acc: 78.04, train_fscore: 77.87, valid_loss: 6.507500171661377, valid_acc: 71.69, valid_fscore: 72.62, test_loss: 7.625100135803223, test_acc: 67.28, test_fscore: 67.92, time: 4.54 sec
              precision    recall  f1-score   support

           0     0.4286    0.7083    0.5340     144.0
           1     0.8000    0.7347    0.7660     245.0
           2     0.6792    0.6562    0.6675     384.0
           3     0.6061    0.7059    0.6522     170.0
           4     0.8750    0.6555    0.7495     299.0
           5     0.6594    0.6352    0.6471     381.0

    accuracy                         0.6728    1623.0
   macro avg     0.6747    0.6826    0.6694    1623.0
weighted avg     0.6990    0.6728    0.6792    1623.0

[[102.   7.  15.   2.  17.   1.]
 [  3. 180.  31.   1.   0.  30.]
 [ 43.  23. 252.  15.   5.  46.]
 [  0.   0.   3. 120.   0.  47.]
 [ 90.   0.  12.   0. 196.   1.]
 [  0.  15.  58.  60.   6. 242.]]
epoch: 41, train_loss: 7.389599800109863, train_acc: 80.28, train_fscore: 80.15, valid_loss: 6.489799976348877, valid_acc: 71.54, valid_fscore: 72.45, test_loss: 7.657800197601318, test_acc: 66.85, test_fscore: 67.53, time: 4.55 sec
epoch: 42, train_loss: 7.391200065612793, train_acc: 78.99, train_fscore: 78.82, valid_loss: 6.48360013961792, valid_acc: 72.29, valid_fscore: 73.42, test_loss: 7.688399791717529, test_acc: 66.42, test_fscore: 67.13, time: 4.7 sec
epoch: 43, train_loss: 7.359899997711182, train_acc: 80.14, train_fscore: 80.04, valid_loss: 6.499199867248535, valid_acc: 72.14, valid_fscore: 73.3, test_loss: 7.648799896240234, test_acc: 66.85, test_fscore: 67.5, time: 4.21 sec
epoch: 44, train_loss: 7.351200103759766, train_acc: 80.33, train_fscore: 80.19, valid_loss: 6.489699840545654, valid_acc: 72.89, valid_fscore: 73.71, test_loss: 7.598400115966797, test_acc: 67.9, test_fscore: 68.5, time: 4.51 sec
epoch: 45, train_loss: 7.3225998878479, train_acc: 80.61, train_fscore: 80.47, valid_loss: 6.473800182342529, valid_acc: 72.44, valid_fscore: 73.38, test_loss: 7.622900009155273, test_acc: 67.59, test_fscore: 68.22, time: 4.59 sec
epoch: 46, train_loss: 7.28380012512207, train_acc: 80.22, train_fscore: 80.11, valid_loss: 6.519499778747559, valid_acc: 71.84, valid_fscore: 73.14, test_loss: 7.625199794769287, test_acc: 67.1, test_fscore: 67.72, time: 4.58 sec
epoch: 47, train_loss: 7.293099880218506, train_acc: 80.0, train_fscore: 79.83, valid_loss: 6.4994001388549805, valid_acc: 72.89, valid_fscore: 73.7, test_loss: 7.60890007019043, test_acc: 67.9, test_fscore: 68.48, time: 4.24 sec
epoch: 48, train_loss: 7.253399848937988, train_acc: 80.76, train_fscore: 80.6, valid_loss: 6.510499954223633, valid_acc: 72.89, valid_fscore: 73.85, test_loss: 7.6433000564575195, test_acc: 67.65, test_fscore: 68.31, time: 4.58 sec
epoch: 49, train_loss: 7.242199897766113, train_acc: 80.49, train_fscore: 80.35, valid_loss: 6.491199970245361, valid_acc: 72.44, valid_fscore: 73.36, test_loss: 7.625, test_acc: 67.78, test_fscore: 68.41, time: 4.32 sec
epoch: 50, train_loss: 7.186500072479248, train_acc: 81.79, train_fscore: 81.7, valid_loss: 6.509699821472168, valid_acc: 73.04, valid_fscore: 73.99, test_loss: 7.618599891662598, test_acc: 67.9, test_fscore: 68.5, time: 4.47 sec
              precision    recall  f1-score   support

           0     0.4264    0.7847    0.5526     144.0
           1     0.8087    0.7592    0.7832     245.0
           2     0.6917    0.6719    0.6816     384.0
           3     0.6432    0.7000    0.6704     170.0
           4     0.8964    0.5786    0.7033     299.0
           5     0.6711    0.6640    0.6675     381.0

    accuracy                         0.6790    1623.0
   macro avg     0.6896    0.6931    0.6764    1623.0
weighted avg     0.7136    0.6790    0.6850    1623.0

[[113.   5.  14.   0.  10.   2.]
 [  2. 186.  26.   1.   0.  30.]
 [ 42.  22. 258.  14.   4.  44.]
 [  0.   0.   4. 119.   0.  47.]
 [108.   1.  16.   0. 173.   1.]
 [  0.  16.  55.  51.   6. 253.]]
epoch: 51, train_loss: 7.18120002746582, train_acc: 82.18, train_fscore: 82.08, valid_loss: 6.509500026702881, valid_acc: 72.59, valid_fscore: 73.5, test_loss: 7.566800117492676, test_acc: 67.9, test_fscore: 68.51, time: 4.57 sec
epoch: 52, train_loss: 7.185999870300293, train_acc: 81.5, train_fscore: 81.34, valid_loss: 6.5233001708984375, valid_acc: 72.14, valid_fscore: 73.13, test_loss: 7.5671000480651855, test_acc: 67.65, test_fscore: 68.26, time: 3.69 sec
epoch: 53, train_loss: 7.157100200653076, train_acc: 81.71, train_fscore: 81.55, valid_loss: 6.474800109863281, valid_acc: 72.89, valid_fscore: 73.72, test_loss: 7.59499979019165, test_acc: 67.71, test_fscore: 68.31, time: 3.09 sec
epoch: 54, train_loss: 7.160200119018555, train_acc: 82.28, train_fscore: 82.18, valid_loss: 6.501500129699707, valid_acc: 72.74, valid_fscore: 73.56, test_loss: 7.6020002365112305, test_acc: 67.65, test_fscore: 68.24, time: 4.31 sec
epoch: 55, train_loss: 7.126800060272217, train_acc: 82.76, train_fscore: 82.67, valid_loss: 6.508699893951416, valid_acc: 72.74, valid_fscore: 73.54, test_loss: 7.536399841308594, test_acc: 68.21, test_fscore: 68.77, time: 4.41 sec
epoch: 56, train_loss: 7.101500034332275, train_acc: 82.37, train_fscore: 82.21, valid_loss: 6.5071001052856445, valid_acc: 73.34, valid_fscore: 74.32, test_loss: 7.585999965667725, test_acc: 68.45, test_fscore: 69.01, time: 4.56 sec
epoch: 57, train_loss: 7.055600166320801, train_acc: 83.15, train_fscore: 83.07, valid_loss: 6.491600036621094, valid_acc: 73.19, valid_fscore: 74.06, test_loss: 7.6107001304626465, test_acc: 67.47, test_fscore: 68.04, time: 4.44 sec
epoch: 58, train_loss: 7.049300193786621, train_acc: 83.5, train_fscore: 83.41, valid_loss: 6.521399974822998, valid_acc: 72.59, valid_fscore: 73.25, test_loss: 7.543799877166748, test_acc: 68.58, test_fscore: 69.15, time: 4.5 sec
epoch: 59, train_loss: 7.036600112915039, train_acc: 83.48, train_fscore: 83.36, valid_loss: 6.507299900054932, valid_acc: 72.74, valid_fscore: 73.72, test_loss: 7.553400039672852, test_acc: 68.15, test_fscore: 68.75, time: 4.66 sec
epoch: 60, train_loss: 7.029399871826172, train_acc: 83.75, train_fscore: 83.65, valid_loss: 6.448400020599365, valid_acc: 74.55, valid_fscore: 75.27, test_loss: 7.57919979095459, test_acc: 67.78, test_fscore: 68.31, time: 4.65 sec
              precision    recall  f1-score   support

           0     0.4356    0.7986    0.5637     144.0
           1     0.8162    0.7796    0.7975     245.0
           2     0.6901    0.6901    0.6901     384.0
           3     0.6131    0.7176    0.6612     170.0
           4     0.8980    0.5886    0.7111     299.0
           5     0.6676    0.6063    0.6355     381.0

    accuracy                         0.6778    1623.0
   macro avg     0.6868    0.6968    0.6765    1623.0
weighted avg     0.7115    0.6778    0.6831    1623.0

[[115.   5.  13.   0.  10.   1.]
 [  2. 191.  23.   1.   0.  28.]
 [ 42.  21. 265.  11.   4.  41.]
 [  0.   0.   4. 122.   0.  44.]
 [105.   1.  16.   0. 176.   1.]
 [  0.  16.  63.  65.   6. 231.]]
epoch: 61, train_loss: 7.003399848937988, train_acc: 83.33, train_fscore: 83.19, valid_loss: 6.4969000816345215, valid_acc: 72.59, valid_fscore: 73.25, test_loss: 7.602700233459473, test_acc: 68.21, test_fscore: 68.84, time: 4.01 sec
epoch: 62, train_loss: 6.983699798583984, train_acc: 83.97, train_fscore: 83.88, valid_loss: 6.58620023727417, valid_acc: 71.69, valid_fscore: 72.62, test_loss: 7.577899932861328, test_acc: 68.45, test_fscore: 69.04, time: 3.93 sec
epoch: 63, train_loss: 6.9664998054504395, train_acc: 83.85, train_fscore: 83.76, valid_loss: 6.524199962615967, valid_acc: 73.95, valid_fscore: 74.73, test_loss: 7.5472002029418945, test_acc: 68.64, test_fscore: 69.14, time: 4.16 sec
epoch: 64, train_loss: 6.95959997177124, train_acc: 84.71, train_fscore: 84.58, valid_loss: 6.4868998527526855, valid_acc: 74.25, valid_fscore: 74.82, test_loss: 7.610899925231934, test_acc: 68.76, test_fscore: 69.28, time: 4.65 sec
epoch: 65, train_loss: 6.962900161743164, train_acc: 84.55, train_fscore: 84.46, valid_loss: 6.546500205993652, valid_acc: 73.49, valid_fscore: 74.12, test_loss: 7.618599891662598, test_acc: 68.45, test_fscore: 68.98, time: 4.11 sec
epoch: 66, train_loss: 6.926700115203857, train_acc: 84.49, train_fscore: 84.41, valid_loss: 6.5696001052856445, valid_acc: 72.29, valid_fscore: 73.08, test_loss: 7.572000026702881, test_acc: 69.44, test_fscore: 70.0, time: 4.55 sec
epoch: 67, train_loss: 6.911099910736084, train_acc: 85.15, train_fscore: 85.06, valid_loss: 6.541500091552734, valid_acc: 73.95, valid_fscore: 74.7, test_loss: 7.575099945068359, test_acc: 69.13, test_fscore: 69.69, time: 4.6 sec
epoch: 68, train_loss: 6.894100189208984, train_acc: 85.23, train_fscore: 85.14, valid_loss: 6.535699844360352, valid_acc: 73.49, valid_fscore: 74.23, test_loss: 7.558199882507324, test_acc: 68.52, test_fscore: 69.08, time: 4.58 sec
epoch: 69, train_loss: 6.909299850463867, train_acc: 85.13, train_fscore: 85.05, valid_loss: 6.531099796295166, valid_acc: 73.04, valid_fscore: 73.91, test_loss: 7.576000213623047, test_acc: 68.95, test_fscore: 69.51, time: 4.6 sec
epoch: 70, train_loss: 6.8628997802734375, train_acc: 85.27, train_fscore: 85.17, valid_loss: 6.549099922180176, valid_acc: 73.34, valid_fscore: 74.3, test_loss: 7.65939998626709, test_acc: 68.08, test_fscore: 68.56, time: 4.1 sec
              precision    recall  f1-score   support

           0     0.4307    0.8194    0.5646     144.0
           1     0.8202    0.7633    0.7907     245.0
           2     0.6997    0.6979    0.6988     384.0
           3     0.6335    0.7118    0.6704     170.0
           4     0.9029    0.5284    0.6667     299.0
           5     0.6801    0.6640    0.6720     381.0

    accuracy                         0.6808    1623.0
   macro avg     0.6945    0.6975    0.6772    1623.0
weighted avg     0.7199    0.6808    0.6856    1623.0

[[118.   5.  12.   0.   8.   1.]
 [  2. 187.  24.   3.   0.  29.]
 [ 39.  20. 268.  10.   4.  43.]
 [  0.   0.   4. 121.   0.  45.]
 [115.   1.  24.   0. 158.   1.]
 [  0.  15.  51.  57.   5. 253.]]
epoch: 71, train_loss: 6.849999904632568, train_acc: 86.11, train_fscore: 86.02, valid_loss: 6.559599876403809, valid_acc: 73.64, valid_fscore: 74.37, test_loss: 7.585899829864502, test_acc: 68.7, test_fscore: 69.22, time: 4.5 sec
epoch: 72, train_loss: 6.827899932861328, train_acc: 85.78, train_fscore: 85.69, valid_loss: 6.574999809265137, valid_acc: 73.04, valid_fscore: 73.74, test_loss: 7.562600135803223, test_acc: 69.01, test_fscore: 69.58, time: 4.4 sec
epoch: 73, train_loss: 6.81220006942749, train_acc: 85.5, train_fscore: 85.43, valid_loss: 6.546299934387207, valid_acc: 73.95, valid_fscore: 74.59, test_loss: 7.555300235748291, test_acc: 69.07, test_fscore: 69.61, time: 4.38 sec
epoch: 74, train_loss: 6.807799816131592, train_acc: 85.62, train_fscore: 85.51, valid_loss: 6.537799835205078, valid_acc: 74.4, valid_fscore: 74.87, test_loss: 7.5493998527526855, test_acc: 69.75, test_fscore: 70.23, time: 4.51 sec
epoch: 75, train_loss: 6.777100086212158, train_acc: 86.36, train_fscore: 86.24, valid_loss: 6.535799980163574, valid_acc: 74.1, valid_fscore: 74.6, test_loss: 7.595799922943115, test_acc: 69.38, test_fscore: 69.9, time: 4.49 sec
epoch: 76, train_loss: 6.7870001792907715, train_acc: 86.46, train_fscore: 86.35, valid_loss: 6.560200214385986, valid_acc: 73.34, valid_fscore: 74.09, test_loss: 7.642899990081787, test_acc: 68.52, test_fscore: 69.07, time: 4.52 sec
epoch: 77, train_loss: 6.754700183868408, train_acc: 86.67, train_fscore: 86.59, valid_loss: 6.611599922180176, valid_acc: 73.19, valid_fscore: 73.64, test_loss: 7.5721001625061035, test_acc: 69.32, test_fscore: 69.85, time: 4.54 sec
epoch: 78, train_loss: 6.783899784088135, train_acc: 87.25, train_fscore: 87.19, valid_loss: 6.595900058746338, valid_acc: 73.04, valid_fscore: 73.73, test_loss: 7.595600128173828, test_acc: 69.07, test_fscore: 69.61, time: 4.54 sec
epoch: 79, train_loss: 6.747700214385986, train_acc: 86.63, train_fscore: 86.54, valid_loss: 6.612299919128418, valid_acc: 72.89, valid_fscore: 73.72, test_loss: 7.616499900817871, test_acc: 69.01, test_fscore: 69.53, time: 4.52 sec
epoch: 80, train_loss: 6.726399898529053, train_acc: 87.04, train_fscore: 86.95, valid_loss: 6.568600177764893, valid_acc: 73.64, valid_fscore: 73.96, test_loss: 7.56879997253418, test_acc: 69.44, test_fscore: 69.94, time: 4.5 sec
              precision    recall  f1-score   support

           0     0.4638    0.7569    0.5752     144.0
           1     0.8202    0.7633    0.7907     245.0
           2     0.7021    0.6875    0.6947     384.0
           3     0.6557    0.7059    0.6799     170.0
           4     0.8863    0.6254    0.7333     299.0
           5     0.6667    0.6824    0.6744     381.0

    accuracy                         0.6944    1623.0
   macro avg     0.6991    0.7036    0.6914    1623.0
weighted avg     0.7195    0.6944    0.6994    1623.0

[[109.   5.  14.   0.  15.   1.]
 [  2. 187.  24.   2.   0.  30.]
 [ 36.  21. 264.   8.   4.  51.]
 [  0.   0.   4. 120.   0.  46.]
 [ 88.   1.  21.   0. 187.   2.]
 [  0.  14.  49.  53.   5. 260.]]
epoch: 81, train_loss: 6.709700107574463, train_acc: 87.14, train_fscore: 87.07, valid_loss: 6.577000141143799, valid_acc: 72.29, valid_fscore: 73.09, test_loss: 7.643199920654297, test_acc: 68.58, test_fscore: 69.13, time: 4.64 sec
epoch: 82, train_loss: 6.706399917602539, train_acc: 87.06, train_fscore: 86.99, valid_loss: 6.593200206756592, valid_acc: 72.74, valid_fscore: 73.41, test_loss: 7.562300205230713, test_acc: 69.19, test_fscore: 69.77, time: 4.3 sec
epoch: 83, train_loss: 6.68779993057251, train_acc: 87.27, train_fscore: 87.18, valid_loss: 6.585700035095215, valid_acc: 73.64, valid_fscore: 74.19, test_loss: 7.566199779510498, test_acc: 69.5, test_fscore: 69.98, time: 4.48 sec
epoch: 84, train_loss: 6.701700210571289, train_acc: 87.27, train_fscore: 87.16, valid_loss: 6.561600208282471, valid_acc: 73.04, valid_fscore: 73.71, test_loss: 7.629700183868408, test_acc: 69.25, test_fscore: 69.69, time: 4.5 sec
epoch: 85, train_loss: 6.650199890136719, train_acc: 87.87, train_fscore: 87.79, valid_loss: 6.606800079345703, valid_acc: 72.74, valid_fscore: 73.16, test_loss: 7.581900119781494, test_acc: 69.44, test_fscore: 70.02, time: 4.36 sec
epoch: 86, train_loss: 6.6743998527526855, train_acc: 87.47, train_fscore: 87.4, valid_loss: 6.641200065612793, valid_acc: 73.19, valid_fscore: 73.75, test_loss: 7.632699966430664, test_acc: 69.19, test_fscore: 69.73, time: 4.14 sec
epoch: 87, train_loss: 6.631899833679199, train_acc: 88.26, train_fscore: 88.17, valid_loss: 6.621300220489502, valid_acc: 74.7, valid_fscore: 75.07, test_loss: 7.60260009765625, test_acc: 69.69, test_fscore: 70.15, time: 4.52 sec
epoch: 88, train_loss: 6.655600070953369, train_acc: 87.85, train_fscore: 87.78, valid_loss: 6.615799903869629, valid_acc: 73.64, valid_fscore: 74.11, test_loss: 7.573200225830078, test_acc: 70.06, test_fscore: 70.55, time: 4.38 sec
epoch: 89, train_loss: 6.618100166320801, train_acc: 88.13, train_fscore: 88.03, valid_loss: 6.644999980926514, valid_acc: 72.89, valid_fscore: 73.45, test_loss: 7.596700191497803, test_acc: 69.07, test_fscore: 69.6, time: 4.5 sec
epoch: 90, train_loss: 6.603700160980225, train_acc: 88.44, train_fscore: 88.36, valid_loss: 6.638000011444092, valid_acc: 73.95, valid_fscore: 74.36, test_loss: 7.618500232696533, test_acc: 69.93, test_fscore: 70.45, time: 4.16 sec
              precision    recall  f1-score   support

           0     0.4628    0.7778    0.5803     144.0
           1     0.8409    0.7551    0.7957     245.0
           2     0.7060    0.7005    0.7033     384.0
           3     0.6816    0.7176    0.6991     170.0
           4     0.8927    0.6120    0.7262     299.0
           5     0.6667    0.6929    0.6795     381.0

    accuracy                         0.6993    1623.0
   macro avg     0.7084    0.7093    0.6974    1623.0
weighted avg     0.7274    0.6993    0.7045    1623.0

[[112.   5.  13.   0.  13.   1.]
 [  2. 185.  24.   2.   0.  32.]
 [ 37.  17. 269.   6.   4.  51.]
 [  0.   0.   2. 122.   0.  46.]
 [ 90.   1.  23.   0. 183.   2.]
 [  1.  12.  50.  49.   5. 264.]]
epoch: 91, train_loss: 6.58050012588501, train_acc: 89.02, train_fscore: 88.95, valid_loss: 6.5914998054504395, valid_acc: 75.6, valid_fscore: 75.85, test_loss: 7.6417999267578125, test_acc: 69.87, test_fscore: 70.34, time: 4.6 sec
epoch: 92, train_loss: 6.579899787902832, train_acc: 88.4, train_fscore: 88.32, valid_loss: 6.703400135040283, valid_acc: 73.19, valid_fscore: 73.86, test_loss: 7.671899795532227, test_acc: 68.95, test_fscore: 69.45, time: 4.6 sec
epoch: 93, train_loss: 6.583199977874756, train_acc: 88.61, train_fscore: 88.55, valid_loss: 6.676599979400635, valid_acc: 72.89, valid_fscore: 73.21, test_loss: 7.5868000984191895, test_acc: 70.18, test_fscore: 70.67, time: 3.42 sec
epoch: 94, train_loss: 6.557300090789795, train_acc: 88.98, train_fscore: 88.89, valid_loss: 6.628200054168701, valid_acc: 74.4, valid_fscore: 74.74, test_loss: 7.68149995803833, test_acc: 70.12, test_fscore: 70.55, time: 4.23 sec
epoch: 95, train_loss: 6.573500156402588, train_acc: 88.81, train_fscore: 88.72, valid_loss: 6.677999973297119, valid_acc: 73.34, valid_fscore: 73.95, test_loss: 7.788899898529053, test_acc: 68.27, test_fscore: 68.81, time: 4.58 sec
epoch: 96, train_loss: 6.5447998046875, train_acc: 88.75, train_fscore: 88.71, valid_loss: 6.688000202178955, valid_acc: 72.74, valid_fscore: 73.15, test_loss: 7.66480016708374, test_acc: 70.12, test_fscore: 70.6, time: 4.38 sec
epoch: 97, train_loss: 6.531899929046631, train_acc: 89.49, train_fscore: 89.41, valid_loss: 6.7245001792907715, valid_acc: 74.4, valid_fscore: 74.74, test_loss: 7.638000011444092, test_acc: 70.67, test_fscore: 71.07, time: 4.63 sec
epoch: 98, train_loss: 6.5152997970581055, train_acc: 89.76, train_fscore: 89.67, valid_loss: 6.759500026702881, valid_acc: 73.95, valid_fscore: 74.56, test_loss: 7.68310022354126, test_acc: 68.7, test_fscore: 69.25, time: 3.98 sec
epoch: 99, train_loss: 6.512199878692627, train_acc: 89.82, train_fscore: 89.75, valid_loss: 6.709799766540527, valid_acc: 73.64, valid_fscore: 74.07, test_loss: 7.729599952697754, test_acc: 69.32, test_fscore: 69.81, time: 4.4 sec
epoch: 100, train_loss: 6.507599830627441, train_acc: 89.06, train_fscore: 88.99, valid_loss: 6.731599807739258, valid_acc: 73.19, valid_fscore: 73.67, test_loss: 7.739099979400635, test_acc: 69.32, test_fscore: 69.74, time: 4.53 sec
              precision    recall  f1-score   support

           0     0.4634    0.7917    0.5846     144.0
           1     0.8214    0.7510    0.7846     245.0
           2     0.6944    0.7161    0.7051     384.0
           3     0.6742    0.7059    0.6897     170.0
           4     0.8918    0.5786    0.7018     299.0
           5     0.6727    0.6798    0.6762     381.0

    accuracy                         0.6932    1623.0
   macro avg     0.7030    0.7039    0.6904    1623.0
weighted avg     0.7222    0.6932    0.6974    1623.0

[[114.   5.  12.   0.  12.   1.]
 [  2. 184.  26.   2.   0.  31.]
 [ 32.  19. 275.   6.   4.  48.]
 [  0.   1.   4. 120.   0.  45.]
 [ 98.   1.  26.   0. 173.   1.]
 [  0.  14.  53.  50.   5. 259.]]
epoch: 101, train_loss: 6.497600078582764, train_acc: 89.93, train_fscore: 89.88, valid_loss: 6.777100086212158, valid_acc: 73.64, valid_fscore: 74.03, test_loss: 7.662199974060059, test_acc: 70.18, test_fscore: 70.59, time: 4.33 sec
epoch: 102, train_loss: 6.520400047302246, train_acc: 89.45, train_fscore: 89.35, valid_loss: 6.782400131225586, valid_acc: 73.64, valid_fscore: 74.12, test_loss: 7.658899784088135, test_acc: 70.12, test_fscore: 70.59, time: 4.6 sec
epoch: 103, train_loss: 6.477099895477295, train_acc: 89.35, train_fscore: 89.27, valid_loss: 6.736700057983398, valid_acc: 73.64, valid_fscore: 74.19, test_loss: 7.773499965667725, test_acc: 69.25, test_fscore: 69.77, time: 4.05 sec
epoch: 104, train_loss: 6.478400230407715, train_acc: 90.21, train_fscore: 90.15, valid_loss: 6.738500118255615, valid_acc: 74.4, valid_fscore: 74.71, test_loss: 7.751100063323975, test_acc: 70.3, test_fscore: 70.69, time: 4.55 sec
epoch: 105, train_loss: 6.469600200653076, train_acc: 90.5, train_fscore: 90.43, valid_loss: 6.743000030517578, valid_acc: 74.25, valid_fscore: 74.52, test_loss: 7.600800037384033, test_acc: 70.98, test_fscore: 71.37, time: 4.63 sec
epoch: 106, train_loss: 6.419600009918213, train_acc: 90.38, train_fscore: 90.3, valid_loss: 6.766900062561035, valid_acc: 73.64, valid_fscore: 74.09, test_loss: 7.669600009918213, test_acc: 70.24, test_fscore: 70.71, time: 4.56 sec
epoch: 107, train_loss: 6.44920015335083, train_acc: 90.19, train_fscore: 90.12, valid_loss: 6.7941999435424805, valid_acc: 73.64, valid_fscore: 74.08, test_loss: 7.724299907684326, test_acc: 69.69, test_fscore: 70.14, time: 4.5 sec
epoch: 108, train_loss: 6.426000118255615, train_acc: 90.56, train_fscore: 90.49, valid_loss: 6.854700088500977, valid_acc: 74.4, valid_fscore: 74.73, test_loss: 7.742800235748291, test_acc: 70.79, test_fscore: 71.26, time: 4.59 sec
epoch: 109, train_loss: 6.406099796295166, train_acc: 90.94, train_fscore: 90.87, valid_loss: 6.759500026702881, valid_acc: 74.55, valid_fscore: 74.86, test_loss: 7.7210001945495605, test_acc: 69.99, test_fscore: 70.39, time: 4.57 sec
epoch: 110, train_loss: 6.417600154876709, train_acc: 90.46, train_fscore: 90.39, valid_loss: 6.809299945831299, valid_acc: 72.74, valid_fscore: 73.32, test_loss: 7.799799919128418, test_acc: 69.25, test_fscore: 69.65, time: 4.61 sec
              precision    recall  f1-score   support

           0     0.4667    0.7778    0.5833     144.0
           1     0.8311    0.7633    0.7957     245.0
           2     0.7060    0.7005    0.7033     384.0
           3     0.6631    0.7294    0.6947     170.0
           4     0.8895    0.5652    0.6912     299.0
           5     0.6575    0.6903    0.6735     381.0

    accuracy                         0.6925    1623.0
   macro avg     0.7023    0.7044    0.6903    1623.0
weighted avg     0.7216    0.6925    0.6965    1623.0

[[112.   6.  13.   0.  12.   1.]
 [  2. 187.  22.   1.   0.  33.]
 [ 28.  19. 269.   6.   4.  58.]
 [  0.   0.   2. 124.   0.  44.]
 [ 98.   2.  29.   0. 169.   1.]
 [  0.  11.  46.  56.   5. 263.]]
epoch: 111, train_loss: 6.414299964904785, train_acc: 90.65, train_fscore: 90.61, valid_loss: 6.846799850463867, valid_acc: 73.8, valid_fscore: 74.06, test_loss: 7.687900066375732, test_acc: 71.41, test_fscore: 71.8, time: 4.61 sec
epoch: 112, train_loss: 6.405399799346924, train_acc: 90.87, train_fscore: 90.8, valid_loss: 6.790800094604492, valid_acc: 74.25, valid_fscore: 74.39, test_loss: 7.643400192260742, test_acc: 71.53, test_fscore: 71.91, time: 4.14 sec
epoch: 113, train_loss: 6.360799789428711, train_acc: 91.12, train_fscore: 91.04, valid_loss: 6.794300079345703, valid_acc: 73.34, valid_fscore: 73.91, test_loss: 7.791299819946289, test_acc: 69.32, test_fscore: 69.79, time: 4.65 sec
epoch: 114, train_loss: 6.356800079345703, train_acc: 91.27, train_fscore: 91.24, valid_loss: 6.833700180053711, valid_acc: 73.64, valid_fscore: 74.04, test_loss: 7.767300128936768, test_acc: 70.3, test_fscore: 70.72, time: 4.5 sec
epoch: 115, train_loss: 6.359600067138672, train_acc: 91.41, train_fscore: 91.35, valid_loss: 6.834499835968018, valid_acc: 73.34, valid_fscore: 73.69, test_loss: 7.732100009918213, test_acc: 71.16, test_fscore: 71.51, time: 4.67 sec
epoch: 116, train_loss: 6.367099761962891, train_acc: 91.29, train_fscore: 91.23, valid_loss: 6.80109977722168, valid_acc: 73.34, valid_fscore: 73.68, test_loss: 7.74970006942749, test_acc: 70.49, test_fscore: 70.93, time: 4.61 sec
epoch: 117, train_loss: 6.339799880981445, train_acc: 91.33, train_fscore: 91.27, valid_loss: 6.82420015335083, valid_acc: 74.25, valid_fscore: 74.54, test_loss: 7.781599998474121, test_acc: 70.36, test_fscore: 70.78, time: 4.36 sec
epoch: 118, train_loss: 6.325500011444092, train_acc: 91.62, train_fscore: 91.56, valid_loss: 6.876699924468994, valid_acc: 73.34, valid_fscore: 73.76, test_loss: 7.803599834442139, test_acc: 70.18, test_fscore: 70.57, time: 4.51 sec
epoch: 119, train_loss: 6.303299903869629, train_acc: 91.95, train_fscore: 91.91, valid_loss: 6.8815999031066895, valid_acc: 73.95, valid_fscore: 74.23, test_loss: 7.764800071716309, test_acc: 70.61, test_fscore: 71.04, time: 4.54 sec
epoch: 120, train_loss: 6.305600166320801, train_acc: 91.45, train_fscore: 91.38, valid_loss: 6.878600120544434, valid_acc: 74.55, valid_fscore: 74.83, test_loss: 7.798500061035156, test_acc: 69.99, test_fscore: 70.43, time: 4.33 sec
              precision    recall  f1-score   support

           0     0.4764    0.7708    0.5889     144.0
           1     0.8386    0.7633    0.7991     245.0
           2     0.6960    0.7214    0.7084     384.0
           3     0.6685    0.7235    0.6949     170.0
           4     0.8810    0.6187    0.7269     299.0
           5     0.6747    0.6640    0.6693     381.0

    accuracy                         0.6999    1623.0
   macro avg     0.7058    0.7103    0.6979    1623.0
weighted avg     0.7242    0.6999    0.7043    1623.0

[[111.   5.  12.   0.  15.   1.]
 [  2. 187.  27.   2.   0.  27.]
 [ 32.  17. 277.   5.   5.  48.]
 [  0.   0.   2. 123.   0.  45.]
 [ 88.   0.  25.   0. 185.   1.]
 [  0.  14.  55.  54.   5. 253.]]
epoch: 121, train_loss: 6.326099872589111, train_acc: 91.66, train_fscore: 91.62, valid_loss: 6.882900238037109, valid_acc: 73.95, valid_fscore: 74.25, test_loss: 7.799499988555908, test_acc: 70.67, test_fscore: 71.07, time: 4.57 sec
epoch: 122, train_loss: 6.300099849700928, train_acc: 91.72, train_fscore: 91.65, valid_loss: 6.902100086212158, valid_acc: 74.7, valid_fscore: 74.94, test_loss: 7.791500091552734, test_acc: 70.67, test_fscore: 71.03, time: 4.57 sec
epoch: 123, train_loss: 6.287600040435791, train_acc: 92.15, train_fscore: 92.1, valid_loss: 6.9344000816345215, valid_acc: 73.8, valid_fscore: 74.22, test_loss: 7.815499782562256, test_acc: 69.87, test_fscore: 70.34, time: 3.74 sec
epoch: 124, train_loss: 6.28249979019165, train_acc: 92.05, train_fscore: 92.0, valid_loss: 6.940000057220459, valid_acc: 74.25, valid_fscore: 74.4, test_loss: 7.735099792480469, test_acc: 71.35, test_fscore: 71.68, time: 4.22 sec
epoch: 125, train_loss: 6.2795000076293945, train_acc: 91.99, train_fscore: 91.91, valid_loss: 6.948400020599365, valid_acc: 74.85, valid_fscore: 75.16, test_loss: 7.8333001136779785, test_acc: 70.36, test_fscore: 70.77, time: 4.47 sec
epoch: 126, train_loss: 6.272299766540527, train_acc: 92.46, train_fscore: 92.42, valid_loss: 6.945499897003174, valid_acc: 74.1, valid_fscore: 74.34, test_loss: 7.911399841308594, test_acc: 70.55, test_fscore: 70.91, time: 4.44 sec
epoch: 127, train_loss: 6.256499767303467, train_acc: 92.52, train_fscore: 92.47, valid_loss: 6.982900142669678, valid_acc: 74.25, valid_fscore: 74.41, test_loss: 7.852499961853027, test_acc: 71.41, test_fscore: 71.78, time: 4.25 sec
epoch: 128, train_loss: 6.239799976348877, train_acc: 92.83, train_fscore: 92.79, valid_loss: 7.005799770355225, valid_acc: 74.55, valid_fscore: 74.8, test_loss: 7.8165998458862305, test_acc: 71.29, test_fscore: 71.69, time: 4.62 sec
epoch: 129, train_loss: 6.22599983215332, train_acc: 92.62, train_fscore: 92.56, valid_loss: 7.020699977874756, valid_acc: 74.1, valid_fscore: 74.28, test_loss: 7.835299968719482, test_acc: 70.67, test_fscore: 71.05, time: 4.59 sec
epoch: 130, train_loss: 6.222400188446045, train_acc: 92.69, train_fscore: 92.66, valid_loss: 6.994200229644775, valid_acc: 73.34, valid_fscore: 73.67, test_loss: 7.941699981689453, test_acc: 70.3, test_fscore: 70.68, time: 4.37 sec
              precision    recall  f1-score   support

           0     0.5046    0.7569    0.6056     144.0
           1     0.8426    0.7429    0.7896     245.0
           2     0.6829    0.7292    0.7053     384.0
           3     0.6739    0.7294    0.7006     170.0
           4     0.8857    0.6221    0.7308     299.0
           5     0.6718    0.6824    0.6771     381.0

    accuracy                         0.7030    1623.0
   macro avg     0.7103    0.7105    0.7015    1623.0
weighted avg     0.7250    0.7030    0.7068    1623.0

[[109.   5.  16.   0.  13.   1.]
 [  2. 182.  28.   3.   0.  30.]
 [ 25.  17. 280.   4.   6.  52.]
 [  0.   0.   4. 124.   0.  42.]
 [ 80.   1.  30.   0. 186.   2.]
 [  0.  11.  52.  53.   5. 260.]]
epoch: 131, train_loss: 6.218699932098389, train_acc: 92.89, train_fscore: 92.85, valid_loss: 6.991600036621094, valid_acc: 72.74, valid_fscore: 73.16, test_loss: 7.928299903869629, test_acc: 69.19, test_fscore: 69.57, time: 4.66 sec
epoch: 132, train_loss: 6.2195000648498535, train_acc: 93.16, train_fscore: 93.11, valid_loss: 7.049600124359131, valid_acc: 73.49, valid_fscore: 73.46, test_loss: 7.793300151824951, test_acc: 71.16, test_fscore: 71.58, time: 4.53 sec
epoch: 133, train_loss: 6.211599826812744, train_acc: 92.65, train_fscore: 92.61, valid_loss: 7.052700042724609, valid_acc: 74.4, valid_fscore: 74.45, test_loss: 7.833099842071533, test_acc: 70.98, test_fscore: 71.32, time: 4.57 sec
epoch: 134, train_loss: 6.2144999504089355, train_acc: 92.67, train_fscore: 92.63, valid_loss: 7.002099990844727, valid_acc: 73.19, valid_fscore: 73.69, test_loss: 7.9517998695373535, test_acc: 69.81, test_fscore: 70.12, time: 4.52 sec
epoch: 135, train_loss: 6.204599857330322, train_acc: 92.75, train_fscore: 92.7, valid_loss: 7.017600059509277, valid_acc: 74.4, valid_fscore: 74.55, test_loss: 7.924099922180176, test_acc: 70.67, test_fscore: 71.05, time: 4.59 sec
epoch: 136, train_loss: 6.198299884796143, train_acc: 93.02, train_fscore: 92.98, valid_loss: 7.048900127410889, valid_acc: 75.0, valid_fscore: 75.02, test_loss: 7.943699836730957, test_acc: 70.43, test_fscore: 70.77, time: 4.54 sec
epoch: 137, train_loss: 6.2006001472473145, train_acc: 93.7, train_fscore: 93.66, valid_loss: 7.044600009918213, valid_acc: 73.95, valid_fscore: 74.3, test_loss: 7.989200115203857, test_acc: 69.99, test_fscore: 70.32, time: 4.54 sec
epoch: 138, train_loss: 6.185100078582764, train_acc: 93.35, train_fscore: 93.31, valid_loss: 7.106200218200684, valid_acc: 74.55, valid_fscore: 74.64, test_loss: 7.856500148773193, test_acc: 70.92, test_fscore: 71.26, time: 4.54 sec
epoch: 139, train_loss: 6.1774001121521, train_acc: 93.02, train_fscore: 92.97, valid_loss: 7.083099842071533, valid_acc: 73.95, valid_fscore: 74.09, test_loss: 7.909900188446045, test_acc: 69.81, test_fscore: 70.25, time: 3.68 sec
epoch: 140, train_loss: 6.173099994659424, train_acc: 93.35, train_fscore: 93.31, valid_loss: 7.048900127410889, valid_acc: 74.55, valid_fscore: 74.87, test_loss: 8.051199913024902, test_acc: 69.19, test_fscore: 69.58, time: 4.59 sec
              precision    recall  f1-score   support

           0     0.4571    0.7778    0.5758     144.0
           1     0.8348    0.7633    0.7974     245.0
           2     0.6900    0.7188    0.7041     384.0
           3     0.6685    0.7235    0.6949     170.0
           4     0.8783    0.5552    0.6803     299.0
           5     0.6798    0.6798    0.6798     381.0

    accuracy                         0.6919    1623.0
   macro avg     0.7014    0.7030    0.6887    1623.0
weighted avg     0.7212    0.6919    0.6958    1623.0

[[112.   5.  12.   0.  14.   1.]
 [  3. 187.  25.   2.   0.  28.]
 [ 33.  18. 276.   4.   4.  49.]
 [  0.   0.   5. 123.   0.  42.]
 [ 97.   2.  32.   0. 166.   2.]
 [  0.  12.  50.  55.   5. 259.]]
epoch: 141, train_loss: 6.1528000831604, train_acc: 93.51, train_fscore: 93.48, valid_loss: 7.114500045776367, valid_acc: 74.25, valid_fscore: 74.33, test_loss: 7.894000053405762, test_acc: 70.79, test_fscore: 71.13, time: 4.59 sec
epoch: 142, train_loss: 6.168399810791016, train_acc: 93.18, train_fscore: 93.13, valid_loss: 7.074900150299072, valid_acc: 73.95, valid_fscore: 74.06, test_loss: 7.864200115203857, test_acc: 70.36, test_fscore: 70.68, time: 4.47 sec
epoch: 143, train_loss: 6.131199836730957, train_acc: 93.96, train_fscore: 93.92, valid_loss: 7.090099811553955, valid_acc: 74.4, valid_fscore: 74.78, test_loss: 7.975399971008301, test_acc: 69.19, test_fscore: 69.59, time: 4.67 sec
epoch: 144, train_loss: 6.141300201416016, train_acc: 93.43, train_fscore: 93.4, valid_loss: 7.114699840545654, valid_acc: 73.8, valid_fscore: 73.9, test_loss: 7.898799896240234, test_acc: 70.43, test_fscore: 70.76, time: 4.6 sec
epoch: 145, train_loss: 6.114200115203857, train_acc: 93.49, train_fscore: 93.45, valid_loss: 7.099299907684326, valid_acc: 74.55, valid_fscore: 74.59, test_loss: 7.931000232696533, test_acc: 71.16, test_fscore: 71.42, time: 4.48 sec
epoch: 146, train_loss: 6.125199794769287, train_acc: 93.7, train_fscore: 93.65, valid_loss: 7.086699962615967, valid_acc: 73.49, valid_fscore: 73.87, test_loss: 8.01099967956543, test_acc: 70.12, test_fscore: 70.46, time: 4.62 sec
epoch: 147, train_loss: 6.126999855041504, train_acc: 93.92, train_fscore: 93.88, valid_loss: 7.1732001304626465, valid_acc: 74.1, valid_fscore: 74.23, test_loss: 7.981100082397461, test_acc: 70.06, test_fscore: 70.45, time: 4.4 sec
epoch: 148, train_loss: 6.118800163269043, train_acc: 94.25, train_fscore: 94.23, valid_loss: 7.192999839782715, valid_acc: 74.1, valid_fscore: 74.29, test_loss: 7.975100040435791, test_acc: 70.06, test_fscore: 70.43, time: 4.49 sec
epoch: 149, train_loss: 6.09630012512207, train_acc: 94.17, train_fscore: 94.13, valid_loss: 7.155399799346924, valid_acc: 74.7, valid_fscore: 74.9, test_loss: 8.017200469970703, test_acc: 69.44, test_fscore: 69.78, time: 3.59 sec
epoch: 150, train_loss: 6.109899997711182, train_acc: 93.66, train_fscore: 93.61, valid_loss: 7.182300090789795, valid_acc: 73.95, valid_fscore: 74.16, test_loss: 8.012499809265137, test_acc: 69.81, test_fscore: 70.17, time: 4.58 sec
              precision    recall  f1-score   support

           0     0.4953    0.7361    0.5922     144.0
           1     0.8194    0.7592    0.7881     245.0
           2     0.6974    0.6901    0.6937     384.0
           3     0.6798    0.7118    0.6954     170.0
           4     0.8584    0.6288    0.7259     299.0
           5     0.6593    0.7008    0.6794     381.0

    accuracy                         0.6981    1623.0
   macro avg     0.7016    0.7045    0.6958    1623.0
weighted avg     0.7167    0.6981    0.7017    1623.0

[[106.   5.  12.   0.  20.   1.]
 [  2. 186.  27.   2.   0.  28.]
 [ 29.  18. 265.   4.   6.  62.]
 [  0.   1.   3. 121.   0.  45.]
 [ 77.   2.  30.   0. 188.   2.]
 [  0.  15.  43.  51.   5. 267.]]
Best validation F-Score: 70.17
Test performance..
F-Score: 70.17
Accuracy: 69.81
Loss: 8.012499809265137
